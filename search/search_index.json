{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"rotalabs-comply","text":"<p>Comprehensive AI compliance and audit logging infrastructure for regulatory adherence.</p>"},{"location":"#what-is-rotalabs-comply","title":"What is rotalabs-comply?","text":"<p><code>rotalabs-comply</code> provides a complete toolkit for ensuring AI systems meet regulatory compliance requirements. It offers:</p> <ul> <li>Audit Logging -- Comprehensive logging of AI interactions with encryption, multiple storage backends (file, S3, memory), and configurable retention policies</li> <li>Compliance Frameworks -- Built-in support for EU AI Act, SOC2 Type II, HIPAA, GDPR, NIST AI RMF, ISO 42001, and MAS FEAT with extensible framework architecture</li> <li>Privacy-First Design -- Hash-only mode for privacy-preserving audit trails, or encrypted content storage when full records are needed</li> <li>Report Generation -- Automated compliance reports with executive summaries, risk assessments, and remediation recommendations</li> </ul>"},{"location":"#package-overview","title":"Package Overview","text":"<pre><code>rotalabs_comply/\n\u251c\u2500\u2500 core/              # Core types, configuration, and exceptions\n\u2502   \u251c\u2500\u2500 types          # RiskLevel, Framework, AuditEntry, ComplianceProfile\n\u2502   \u251c\u2500\u2500 config         # AuditConfig, StorageConfig\n\u2502   \u2514\u2500\u2500 exceptions     # ComplianceError hierarchy\n\u251c\u2500\u2500 audit/             # Audit logging infrastructure\n\u2502   \u251c\u2500\u2500 logger         # AuditLogger main interface\n\u2502   \u251c\u2500\u2500 encryption     # EncryptionManager, Fernet encryption\n\u2502   \u2514\u2500\u2500 storage        # FileStorage, MemoryStorage, S3Storage\n\u251c\u2500\u2500 frameworks/        # Compliance framework implementations\n\u2502   \u251c\u2500\u2500 base           # BaseFramework, ComplianceRule, ComplianceFramework\n\u2502   \u251c\u2500\u2500 eu_ai_act      # EU AI Act (2024) compliance checks\n\u2502   \u251c\u2500\u2500 soc2           # SOC2 Type II Trust Service Criteria\n\u2502   \u251c\u2500\u2500 hipaa          # HIPAA Security and Privacy Rules\n\u2502   \u251c\u2500\u2500 gdpr           # GDPR data protection compliance\n\u2502   \u251c\u2500\u2500 nist_ai_rmf    # NIST AI Risk Management Framework\n\u2502   \u251c\u2500\u2500 iso_42001      # ISO/IEC 42001:2023 AI Management System\n\u2502   \u2514\u2500\u2500 mas            # MAS FEAT AI governance for financial services\n\u251c\u2500\u2500 reports/           # Report generation\n\u2502   \u251c\u2500\u2500 generator      # ReportGenerator, ComplianceReport\n\u2502   \u2514\u2500\u2500 templates      # ReportTemplate, ReportSection, section generators\n\u2514\u2500\u2500 utils/             # Utility functions\n    \u2514\u2500\u2500 helpers        # Period formatting, statistics, JSON serialization\n</code></pre>"},{"location":"#supported-compliance-frameworks","title":"Supported Compliance Frameworks","text":"Framework Rules Description Categories EU AI Act 8 European Union AI regulation (2024) Transparency, oversight, risk management, documentation, security SOC2 Type II 10 AICPA Trust Service Criteria Security, availability, processing integrity, confidentiality, privacy HIPAA 8 Health data protection (US) Access control, audit, integrity, authentication, transmission, privacy GDPR 14 EU General Data Protection Regulation Data protection, legal basis, consent, transparency, data subject rights, security, accountability NIST AI RMF 15 NIST AI Risk Management Framework 1.0 Governance, context, risk identification, measurement, risk treatment ISO/IEC 42001 23 AI Management System standard (2023) Context, leadership, planning, support, operation, performance, improvement MAS FEAT 18 Singapore financial AI governance Fairness, ethics, accountability, transparency, model risk, data governance, operations"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#privacy-modes","title":"Privacy Modes","text":"<p>Choose the right privacy level for your compliance requirements:</p> <ul> <li>Hash-Only Mode (default): Store SHA-256 hashes of inputs/outputs for verification without exposing content</li> <li>Encrypted Mode: Store encrypted content when you need full audit trails with data protection</li> <li>Plaintext Mode: Store content as-is for internal development environments</li> </ul>"},{"location":"#storage-backends","title":"Storage Backends","text":"<p>Flexible storage options for different deployment scenarios:</p> <ul> <li>FileStorage: Local JSONL files with automatic rotation</li> <li>S3Storage: AWS S3 for cloud-native deployments with lifecycle management</li> <li>MemoryStorage: In-memory storage for testing and development</li> </ul>"},{"location":"#report-formats","title":"Report Formats","text":"<p>Generate compliance reports in multiple formats:</p> <ul> <li>Markdown: Human-readable documentation</li> <li>JSON: Machine-readable for integration</li> <li>HTML: Standalone reports for stakeholders</li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>Getting Started - Installation and first steps</li> <li>Core Concepts - Understanding compliance infrastructure</li> <li>API Reference - Detailed API documentation</li> <li>Tutorials - Step-by-step guides</li> </ul>"},{"location":"#use-cases","title":"Use Cases","text":""},{"location":"#enterprise-ai-governance","title":"Enterprise AI Governance","text":"<p>Track all AI interactions across your organization with centralized audit logging, ensuring consistent compliance with internal policies and external regulations.</p>"},{"location":"#healthcare-ai-applications","title":"Healthcare AI Applications","text":"<p>Meet HIPAA requirements for AI systems processing Protected Health Information (PHI) with encryption, access controls, and comprehensive audit trails.</p>"},{"location":"#eu-ai-act-compliance","title":"EU AI Act Compliance","text":"<p>Prepare for EU AI Act requirements with built-in checks for transparency, human oversight, risk management, and technical documentation.</p>"},{"location":"#soc2-audits","title":"SOC2 Audits","text":"<p>Demonstrate operational effectiveness of security controls for AI systems with audit logs and compliance reports suitable for SOC2 Type II audits.</p>"},{"location":"concepts/","title":"Core Concepts","text":"<p>This page explains the fundamental concepts behind <code>rotalabs-comply</code> and how the different components work together.</p>"},{"location":"concepts/#compliance-pipeline","title":"Compliance Pipeline","text":"<p>Every compliance workflow in <code>rotalabs-comply</code> follows a four-stage pipeline:</p> <pre><code>Audit Logging --&gt; Compliance Checking --&gt; Report Generation --&gt; Remediation\n</code></pre> <ol> <li> <p>Audit Logging -- Capture all AI system interactions with comprehensive metadata including inputs, outputs, safety checks, and performance metrics.</p> </li> <li> <p>Compliance Checking -- Evaluate audit entries against one or more regulatory frameworks to identify violations and risks.</p> </li> <li> <p>Report Generation -- Generate structured compliance reports with executive summaries, risk assessments, and prioritized recommendations.</p> </li> <li> <p>Remediation -- Address identified violations using the provided remediation guidance and update compliance posture.</p> </li> </ol>"},{"location":"concepts/#audit-logging","title":"Audit Logging","text":""},{"location":"concepts/#auditentry","title":"AuditEntry","text":"<p>An <code>AuditEntry</code> captures a single AI system interaction with all relevant compliance metadata:</p> Field Description <code>id</code> Unique identifier (UUID) <code>timestamp</code> When the interaction occurred <code>provider</code> AI provider (e.g., \"openai\", \"anthropic\") <code>model</code> Model identifier (e.g., \"gpt-4\", \"claude-3-opus\") <code>input_hash</code> SHA-256 hash of input content <code>output_hash</code> SHA-256 hash of output content <code>input_content</code> Actual input (if <code>store_content=True</code>, may be encrypted) <code>output_content</code> Actual output (if <code>store_content=True</code>, may be encrypted) <code>safety_passed</code> Whether all safety checks passed <code>detectors_triggered</code> List of safety detectors that flagged content <code>latency_ms</code> Response time in milliseconds <code>metadata</code> Custom key-value metadata"},{"location":"concepts/#privacy-modes","title":"Privacy Modes","text":"<p><code>rotalabs-comply</code> offers three privacy modes to balance audit completeness with data protection:</p> <pre><code>Hash-Only Mode (Default)\n\u251c\u2500\u2500 Stores SHA-256 hashes only\n\u251c\u2500\u2500 Content can be verified but not recovered\n\u2514\u2500\u2500 Maximum privacy protection\n\nEncrypted Mode\n\u251c\u2500\u2500 Stores Fernet-encrypted content\n\u251c\u2500\u2500 Content recoverable with encryption key\n\u2514\u2500\u2500 Balance of auditability and protection\n\nPlaintext Mode\n\u251c\u2500\u2500 Stores content as-is\n\u251c\u2500\u2500 No encryption overhead\n\u2514\u2500\u2500 Development/testing only\n</code></pre>"},{"location":"concepts/#content-hashing","title":"Content Hashing","text":"<p>When <code>store_content=False</code> (default), only SHA-256 hashes are stored:</p> <pre><code>from rotalabs_comply.audit import hash_content\n\n# Compute hash\ncontent = \"What is 2+2?\"\ncontent_hash = hash_content(content)\n# Returns: \"a0c2...\"\n\n# Later, verify content matches\nif hash_content(provided_content) == stored_hash:\n    print(\"Content verified\")\n</code></pre> <p>This allows verification that logged content matches original content without storing the actual data.</p>"},{"location":"concepts/#encryption","title":"Encryption","text":"<p>When encryption is enabled, content is protected using Fernet symmetric encryption:</p> <pre><code>from rotalabs_comply.audit import EncryptionManager, generate_key\n\n# Auto-generate key\nmanager = EncryptionManager()\n\n# Or use existing key\nkey = generate_key()\nmanager = EncryptionManager(key)\n\n# Encrypt/decrypt\nencrypted = manager.encrypt(\"sensitive data\")\ndecrypted = manager.decrypt(encrypted)\n\n# Important: Save the key securely!\nkey = manager.get_key()  # Store in secrets manager\n</code></pre> <p>Key Management</p> <p>The encryption key is the only way to recover encrypted content. Store it securely (e.g., AWS Secrets Manager, HashiCorp Vault) and never commit it to version control.</p>"},{"location":"concepts/#storage-backends","title":"Storage Backends","text":""},{"location":"concepts/#storagebackend-protocol","title":"StorageBackend Protocol","text":"<p>All storage backends implement the <code>StorageBackend</code> protocol:</p> <pre><code>class StorageBackend(Protocol):\n    async def write(self, entry: AuditEntry) -&gt; str: ...\n    async def read(self, entry_id: str) -&gt; AuditEntry | None: ...\n    async def list_entries(self, start: datetime, end: datetime) -&gt; List[AuditEntry]: ...\n    async def delete(self, entry_id: str) -&gt; bool: ...\n    async def count(self) -&gt; int: ...\n</code></pre>"},{"location":"concepts/#filestorage","title":"FileStorage","text":"<p>Local file storage using JSONL format with automatic rotation:</p> <ul> <li>File naming: <code>audit_YYYYMMDD.jsonl</code></li> <li>Rotation: When file exceeds <code>rotation_size_mb</code> (default: 100MB)</li> <li>Indexing: In-memory index for fast lookups</li> </ul> <pre><code>from rotalabs_comply.audit import FileStorage\n\nstorage = FileStorage(\n    path=\"/var/log/ai-audit\",\n    rotation_size_mb=100,\n)\n</code></pre>"},{"location":"concepts/#s3storage","title":"S3Storage","text":"<p>AWS S3 storage for cloud-native deployments:</p> <ul> <li>Key structure: <code>{prefix}{YYYY-MM-DD}/{entry_id}.json</code></li> <li>Lifecycle: Use S3 lifecycle policies for retention</li> <li>Pagination: Handles large result sets automatically</li> </ul> <pre><code>from rotalabs_comply.audit import S3Storage\n\nstorage = S3Storage(\n    bucket=\"my-audit-bucket\",\n    prefix=\"prod/audit/\",\n    region=\"us-west-2\",\n)\n</code></pre>"},{"location":"concepts/#memorystorage","title":"MemoryStorage","text":"<p>In-memory storage for testing and development:</p> <ul> <li>LRU eviction: Optional <code>max_entries</code> limit</li> <li>No persistence: Data lost when process ends</li> <li>Fast operations: No I/O overhead</li> </ul> <pre><code>from rotalabs_comply.audit import MemoryStorage\n\nstorage = MemoryStorage(max_entries=10000)\n</code></pre>"},{"location":"concepts/#compliance-frameworks","title":"Compliance Frameworks","text":""},{"location":"concepts/#framework-architecture","title":"Framework Architecture","text":"<p>Each compliance framework consists of:</p> <ol> <li>Rules -- Individual compliance requirements with severity, category, and check logic</li> <li>Check Function -- Evaluates audit entries against rules</li> <li>Remediation Guidance -- Recommendations for addressing violations</li> </ol> <pre><code>Framework\n\u251c\u2500\u2500 Rules\n\u2502   \u251c\u2500\u2500 Rule 1 (severity, category, check_fn, remediation)\n\u2502   \u251c\u2500\u2500 Rule 2\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 check(entry, profile) -&gt; ComplianceCheckResult\n\u2514\u2500\u2500 get_rule(rule_id) -&gt; ComplianceRule\n</code></pre>"},{"location":"concepts/#complianceprofile","title":"ComplianceProfile","text":"<p>A <code>ComplianceProfile</code> configures how compliance checks are performed:</p> Field Description <code>profile_id</code> Unique identifier <code>name</code> Human-readable name <code>enabled_frameworks</code> List of frameworks to evaluate <code>enabled_categories</code> Rule categories to include (empty = all) <code>min_severity</code> Minimum severity to report <code>excluded_rules</code> Specific rules to skip <code>system_classification</code> Classification of the AI system <pre><code>from rotalabs_comply.frameworks.base import ComplianceProfile, RiskLevel\n\nprofile = ComplianceProfile(\n    profile_id=\"healthcare-ai\",\n    name=\"Healthcare AI System\",\n    enabled_frameworks=[\"HIPAA\", \"SOC2\"],\n    min_severity=RiskLevel.MEDIUM,\n    system_classification=\"high_risk\",\n)\n</code></pre>"},{"location":"concepts/#risklevel","title":"RiskLevel","text":"<p>Violations are classified by severity:</p> Level Weight Response Time <code>CRITICAL</code> 10 Immediate action required <code>HIGH</code> 5 Address within 24-48 hours <code>MEDIUM</code> 2 Address within 1-2 weeks <code>LOW</code> 1 Address during regular reviews <code>INFO</code> 0.5 Informational, no action required"},{"location":"concepts/#built-in-frameworks","title":"Built-in Frameworks","text":""},{"location":"concepts/#eu-ai-act","title":"EU AI Act","text":"<p>The European Union AI Act (2024) framework includes checks for:</p> <ul> <li>Transparency -- Users informed of AI interaction</li> <li>Human Oversight -- Documented oversight for high-risk operations</li> <li>Risk Management -- Risk assessment documentation</li> <li>Technical Documentation -- Documentation references</li> <li>Data Governance -- Training data documentation</li> <li>Robustness -- Error handling</li> <li>Accuracy Monitoring -- Performance monitoring</li> <li>Cybersecurity -- Security validation</li> </ul>"},{"location":"concepts/#soc2-type-ii","title":"SOC2 Type II","text":"<p>AICPA Trust Service Criteria implementation:</p> <ul> <li>Security (CC) -- Access controls, monitoring, incident response</li> <li>Availability (A) -- SLA monitoring, recovery objectives</li> <li>Processing Integrity (PI) -- Input validation</li> <li>Confidentiality (C) -- Data classification</li> <li>Privacy (P) -- Privacy notices for personal data</li> </ul>"},{"location":"concepts/#hipaa","title":"HIPAA","text":"<p>Health Insurance Portability and Accountability Act:</p> <ul> <li>Access Control -- Unique user identification, encryption</li> <li>Audit Controls -- Comprehensive logging</li> <li>Integrity Controls -- Data integrity verification</li> <li>Authentication -- Strong authentication, MFA for high-risk</li> <li>Transmission Security -- Encrypted transmission</li> <li>Privacy -- Minimum necessary, de-identification</li> </ul>"},{"location":"concepts/#compliance-check-results","title":"Compliance Check Results","text":""},{"location":"concepts/#compliancecheckresult","title":"ComplianceCheckResult","text":"<p>The result of evaluating an audit entry against a framework:</p> Field Description <code>entry_id</code> ID of the checked entry <code>framework</code> Framework name <code>framework_version</code> Framework version <code>timestamp</code> When check was performed <code>violations</code> List of <code>ComplianceViolation</code> objects <code>rules_checked</code> Total rules evaluated <code>rules_passed</code> Rules that passed <code>is_compliant</code> True if no violations"},{"location":"concepts/#complianceviolation","title":"ComplianceViolation","text":"<p>Details about a specific rule violation:</p> Field Description <code>rule_id</code> Rule identifier <code>rule_name</code> Human-readable name <code>severity</code> <code>RiskLevel</code> of violation <code>description</code> What the rule requires <code>evidence</code> Specific evidence from the entry <code>remediation</code> How to fix the violation <code>entry_id</code> Entry that triggered violation <code>category</code> Rule category <code>framework</code> Framework name"},{"location":"concepts/#report-generation","title":"Report Generation","text":""},{"location":"concepts/#compliancereport","title":"ComplianceReport","text":"<p>A complete compliance report with all sections:</p> Field Description <code>id</code> Unique report identifier <code>title</code> Report title <code>framework</code> Framework (or \"Multiple\") <code>period_start</code> / <code>period_end</code> Analysis period <code>generated_at</code> Generation timestamp <code>profile</code> <code>ComplianceProfile</code> used <code>sections</code> List of <code>ReportSection</code> objects <code>total_entries</code> Entries analyzed <code>violations_count</code> Violations found <code>compliance_score</code> Score from 0.0 to 1.0 <code>status</code> \"compliant\", \"non_compliant\", or \"needs_review\""},{"location":"concepts/#compliance-scoring","title":"Compliance Scoring","text":"<p>The compliance score is calculated using weighted penalties:</p> <pre><code>Score = 1.0 - (Total Penalty / Max Possible Penalty)\n\nWhere:\n- Critical violation: 10 points penalty\n- High violation: 5 points penalty\n- Medium violation: 2 points penalty\n- Low violation: 1 point penalty\n- Info violation: 0.5 points penalty\n</code></pre>"},{"location":"concepts/#status-determination","title":"Status Determination","text":"Score Critical Violations Status Any &gt; 0 <code>non_compliant</code> &gt;= 95% 0 <code>compliant</code> &gt;= 80% 0 <code>needs_review</code> &lt; 80% 0 <code>non_compliant</code>"},{"location":"concepts/#report-sections","title":"Report Sections","text":"<p>Standard sections generated for each report:</p> <ol> <li>Executive Summary -- Key metrics, overall status, period overview</li> <li>Risk Assessment -- Severity distribution, category breakdown, priority findings</li> <li>Compliance Matrix -- Rule-by-rule pass/fail summary per framework</li> <li>Metrics Summary -- Volume, safety rates, latency percentiles</li> <li>Recommendations -- Prioritized actions (immediate, short-term, long-term)</li> <li>Audit Summary -- Daily volumes, peak activity, failure patterns</li> </ol>"},{"location":"concepts/#export-formats","title":"Export Formats","text":"Format Method Use Case Markdown <code>export_markdown()</code> Documentation, README files JSON <code>export_json()</code> API responses, data integration HTML <code>export_html()</code> Standalone reports, stakeholder sharing"},{"location":"concepts/#custom-frameworks","title":"Custom Frameworks","text":"<p>Extend <code>BaseFramework</code> to create custom compliance frameworks:</p> <pre><code>from rotalabs_comply.frameworks.base import (\n    BaseFramework,\n    ComplianceRule,\n    ComplianceViolation,\n    RiskLevel,\n)\n\nclass MyCustomFramework(BaseFramework):\n    def __init__(self):\n        rules = [\n            ComplianceRule(\n                rule_id=\"CUSTOM-001\",\n                name=\"Custom Requirement\",\n                description=\"Description of the requirement\",\n                severity=RiskLevel.MEDIUM,\n                category=\"custom\",\n                remediation=\"How to fix violations\",\n            ),\n        ]\n        super().__init__(\n            name=\"My Custom Framework\",\n            version=\"1.0\",\n            rules=rules,\n        )\n\n    def _check_rule(self, entry, rule):\n        # Implement rule checking logic\n        if rule.rule_id == \"CUSTOM-001\":\n            if not entry.metadata.get(\"custom_field\"):\n                return self._create_violation(\n                    entry, rule, \"custom_field not set\"\n                )\n        return None\n\n    def _create_violation(self, entry, rule, evidence):\n        return ComplianceViolation(\n            rule_id=rule.rule_id,\n            rule_name=rule.name,\n            severity=rule.severity,\n            description=rule.description,\n            evidence=evidence,\n            remediation=rule.remediation,\n            entry_id=entry.entry_id,\n            category=rule.category,\n            framework=self._name,\n        )\n</code></pre>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#installation","title":"Installation","text":""},{"location":"getting-started/#basic-installation","title":"Basic Installation","text":"<pre><code>pip install rotalabs-comply\n</code></pre>"},{"location":"getting-started/#with-optional-dependencies","title":"With Optional Dependencies","text":"<pre><code># AWS S3 storage backend\npip install rotalabs-comply[s3]\n\n# All optional dependencies\npip install rotalabs-comply[all]\n\n# Development dependencies\npip install rotalabs-comply[dev]\n</code></pre>"},{"location":"getting-started/#core-dependencies","title":"Core Dependencies","text":"<p>The base package requires:</p> <ul> <li><code>pydantic&gt;=2.0.0</code> - Data validation and settings management</li> <li><code>cryptography&gt;=41.0.0</code> - Fernet encryption for audit logs</li> <li><code>aiofiles&gt;=23.0.0</code> - Async file operations</li> </ul> <p>Optional dependencies:</p> <ul> <li><code>boto3&gt;=1.26.0</code> - AWS S3 storage backend (with <code>[s3]</code> extra)</li> </ul>"},{"location":"getting-started/#basic-usage","title":"Basic Usage","text":""},{"location":"getting-started/#1-set-up-audit-logging","title":"1. Set Up Audit Logging","text":"<pre><code>import asyncio\nfrom rotalabs_comply import AuditLogger, EncryptionManager\n\nasync def main():\n    # Create an encrypted audit logger\n    encryption = EncryptionManager()\n    logger = AuditLogger(\n        storage=\"/var/log/ai-audit\",\n        encryption=encryption,\n        store_content=True,  # Store encrypted content\n        retention_days=365,\n    )\n\n    # Log an AI interaction\n    entry_id = await logger.log(\n        input=\"What is the capital of France?\",\n        output=\"The capital of France is Paris.\",\n        provider=\"openai\",\n        model=\"gpt-4\",\n        safety_passed=True,\n        latency_ms=245.5,\n        input_tokens=8,\n        output_tokens=7,\n        metadata={\"session_id\": \"abc123\"},\n    )\n\n    print(f\"Logged entry: {entry_id}\")\n\n    # Retrieve the entry\n    entry = await logger.get_entry(entry_id)\n    if entry and entry.input_content:\n        # Decrypt content if needed\n        original_input = logger.decrypt_content(entry.input_content)\n        print(f\"Original input: {original_input}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"getting-started/#2-check-compliance-against-frameworks","title":"2. Check Compliance Against Frameworks","text":"<pre><code>import asyncio\nfrom datetime import datetime\nfrom rotalabs_comply.frameworks.base import AuditEntry, ComplianceProfile, RiskLevel\nfrom rotalabs_comply.frameworks.eu_ai_act import EUAIActFramework\n\nasync def main():\n    # Create an audit entry to check\n    entry = AuditEntry(\n        entry_id=\"test-001\",\n        timestamp=datetime.utcnow(),\n        event_type=\"inference\",\n        actor=\"user@example.com\",\n        action=\"AI response generation\",\n        risk_level=RiskLevel.HIGH,\n        user_notified=True,  # Required for EU AI Act transparency\n        human_oversight=True,  # Required for high-risk operations\n        metadata={\n            \"risk_assessment_documented\": True,\n            \"accuracy_monitored\": True,\n            \"security_validated\": True,\n        },\n    )\n\n    # Create a compliance profile\n    profile = ComplianceProfile(\n        profile_id=\"prod-profile\",\n        name=\"Production AI System\",\n        enabled_frameworks=[\"EU AI Act\"],\n        min_severity=RiskLevel.LOW,\n    )\n\n    # Check compliance\n    framework = EUAIActFramework()\n    result = await framework.check(entry, profile)\n\n    print(f\"Compliant: {result.is_compliant}\")\n    print(f\"Rules checked: {result.rules_checked}\")\n    print(f\"Rules passed: {result.rules_passed}\")\n\n    if result.violations:\n        print(\"\\nViolations found:\")\n        for violation in result.violations:\n            print(f\"  - [{violation.severity.value.upper()}] {violation.rule_name}\")\n            print(f\"    Evidence: {violation.evidence}\")\n            print(f\"    Remediation: {violation.remediation}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"getting-started/#3-generate-compliance-reports","title":"3. Generate Compliance Reports","text":"<pre><code>import asyncio\nfrom datetime import datetime, timedelta\nfrom rotalabs_comply import AuditLogger, ReportGenerator\nfrom rotalabs_comply.audit import MemoryStorage\nfrom rotalabs_comply.frameworks.base import ComplianceProfile\nfrom rotalabs_comply.frameworks.eu_ai_act import EUAIActFramework\nfrom rotalabs_comply.frameworks.soc2 import SOC2Framework\n\nasync def main():\n    # Set up storage and logger\n    storage = MemoryStorage()\n    logger = AuditLogger(storage)\n\n    # Log some test entries\n    for i in range(10):\n        await logger.log(\n            input=f\"Test input {i}\",\n            output=f\"Test output {i}\",\n            provider=\"openai\",\n            model=\"gpt-4\",\n            safety_passed=True,\n            latency_ms=100 + i * 10,\n        )\n\n    # Create report generator with frameworks\n    generator = ReportGenerator(\n        audit_logger=storage,\n        frameworks={\n            \"eu_ai_act\": EUAIActFramework(),\n            \"soc2\": SOC2Framework(),\n        },\n    )\n\n    # Create compliance profile\n    profile = ComplianceProfile(\n        profile_id=\"test\",\n        name=\"Test Environment\",\n        enabled_frameworks=[\"eu_ai_act\", \"soc2\"],\n    )\n\n    # Generate report\n    end = datetime.utcnow()\n    start = end - timedelta(days=30)\n\n    report = await generator.generate(\n        period_start=start,\n        period_end=end,\n        profile=profile,\n    )\n\n    # Export as Markdown\n    markdown = generator.export_markdown(report)\n    print(markdown)\n\n    # Or export as HTML\n    html = generator.export_html(report)\n    with open(\"compliance_report.html\", \"w\") as f:\n        f.write(html)\n\n    print(f\"\\nReport generated: {report.title}\")\n    print(f\"Compliance Score: {report.compliance_score:.2%}\")\n    print(f\"Status: {report.status}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"getting-started/#privacy-mode-selection","title":"Privacy Mode Selection","text":"<p>Choose the appropriate privacy mode for your use case:</p> Hash-Only (Default)Encrypted ContentPlaintext Content <pre><code># Only stores SHA-256 hashes of content\nlogger = AuditLogger(\n    storage=\"/var/log/audit\",\n    store_content=False,  # Default\n)\n</code></pre> <p>Best for: Maximum privacy, content verification without storage</p> <pre><code># Stores encrypted content with Fernet encryption\nencryption = EncryptionManager()\nlogger = AuditLogger(\n    storage=\"/var/log/audit\",\n    encryption=encryption,\n    store_content=True,\n)\n\n# Save the key securely!\nkey = encryption.get_key()\n</code></pre> <p>Best for: Full audit trails with data protection</p> <pre><code># Stores content as-is (no encryption)\nlogger = AuditLogger(\n    storage=\"/var/log/audit\",\n    store_content=True,\n    encryption=None,\n)\n</code></pre> <p>Best for: Development/testing environments only</p>"},{"location":"getting-started/#storage-backend-selection","title":"Storage Backend Selection","text":"File StorageS3 StorageMemory Storage <pre><code>from rotalabs_comply import AuditLogger\n\nlogger = AuditLogger(\n    storage=\"/var/log/ai-audit\",  # Directory path\n)\n</code></pre> <ul> <li>JSONL format with automatic date-based files</li> <li>Automatic rotation when files exceed size limit</li> <li>Good for single-server deployments</li> </ul> <pre><code>from rotalabs_comply.audit import S3Storage, AuditLogger\n\nstorage = S3Storage(\n    bucket=\"my-audit-bucket\",\n    prefix=\"prod/audit-logs/\",\n    region=\"us-west-2\",\n)\nlogger = AuditLogger(storage)\n</code></pre> <ul> <li>Requires <code>boto3</code> (<code>pip install rotalabs-comply[s3]</code>)</li> <li>Uses S3 lifecycle policies for retention</li> <li>Best for cloud-native deployments</li> </ul> <pre><code>from rotalabs_comply.audit import MemoryStorage, AuditLogger\n\nstorage = MemoryStorage(max_entries=10000)\nlogger = AuditLogger(storage)\n</code></pre> <ul> <li>Data lost when process ends</li> <li>Good for testing and development</li> <li>Optional entry limit to prevent memory issues</li> </ul>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Read Core Concepts to understand compliance infrastructure</li> <li>Follow Audit Logging Tutorial for detailed walkthrough</li> <li>See API Reference for full documentation</li> </ul>"},{"location":"api/audit/","title":"Audit Module","text":"<p>Audit logging infrastructure including the main logger, encryption utilities, and storage backends.</p>"},{"location":"api/audit/#auditlogger","title":"AuditLogger","text":"<p>Main audit logging interface for AI compliance.</p>"},{"location":"api/audit/#rotalabs_comply.audit.logger.AuditLogger","title":"AuditLogger","text":"<p>Main audit logging interface for AI compliance.</p> <p>The AuditLogger provides a high-level interface for recording AI interactions, including inputs, outputs, safety evaluations, and performance metrics. It supports optional encryption of content and configurable retention policies.</p> <p>Parameters:</p> Name Type Description Default <code>storage</code> <code>Union[StorageBackend, str]</code> <p>Either a StorageBackend instance or a file path string. If a string is provided, FileStorage is automatically created.</p> required <code>encryption</code> <code>EncryptionManager | None</code> <p>Optional EncryptionManager for encrypting stored content.</p> <code>None</code> <code>store_content</code> <code>bool</code> <p>If True, stores actual content. If False, only stores content hashes for privacy (default: False).</p> <code>False</code> <code>retention_days</code> <code>int</code> <p>Number of days to retain entries before cleanup (default: 365).</p> <code>365</code> <p>Attributes:</p> Name Type Description <code>storage</code> <code>StorageBackend</code> <p>The underlying storage backend.</p> <code>encryption</code> <p>The encryption manager (if provided).</p> <code>store_content</code> <p>Whether to store actual content.</p> <code>retention_days</code> <p>Retention period in days.</p> Example <p>Basic usage with file storage:</p> <p>logger = AuditLogger(\"/var/log/audit\") entry_id = await logger.log( ...     input=\"What is 2+2?\", ...     output=\"4\", ...     provider=\"openai\", ...     model=\"gpt-4\", ... )</p> <p>With encryption and content storage:</p> <p>from rotalabs_comply.audit import EncryptionManager encryption = EncryptionManager() logger = AuditLogger( ...     \"/var/log/audit\", ...     encryption=encryption, ...     store_content=True, ... ) entry_id = await logger.log( ...     input=\"Sensitive question\", ...     output=\"Sensitive answer\", ...     safety_passed=True, ... )</p> <p>With custom storage backend:</p> <p>from rotalabs_comply.audit import MemoryStorage storage = MemoryStorage(max_entries=10000) logger = AuditLogger(storage)</p> Source code in <code>src/rotalabs_comply/audit/logger.py</code> <pre><code>class AuditLogger:\n    \"\"\"\n    Main audit logging interface for AI compliance.\n\n    The AuditLogger provides a high-level interface for recording AI interactions,\n    including inputs, outputs, safety evaluations, and performance metrics. It\n    supports optional encryption of content and configurable retention policies.\n\n    Args:\n        storage: Either a StorageBackend instance or a file path string.\n            If a string is provided, FileStorage is automatically created.\n        encryption: Optional EncryptionManager for encrypting stored content.\n        store_content: If True, stores actual content. If False, only stores\n            content hashes for privacy (default: False).\n        retention_days: Number of days to retain entries before cleanup\n            (default: 365).\n\n    Attributes:\n        storage: The underlying storage backend.\n        encryption: The encryption manager (if provided).\n        store_content: Whether to store actual content.\n        retention_days: Retention period in days.\n\n    Example:\n        Basic usage with file storage:\n\n        &gt;&gt;&gt; logger = AuditLogger(\"/var/log/audit\")\n        &gt;&gt;&gt; entry_id = await logger.log(\n        ...     input=\"What is 2+2?\",\n        ...     output=\"4\",\n        ...     provider=\"openai\",\n        ...     model=\"gpt-4\",\n        ... )\n\n        With encryption and content storage:\n\n        &gt;&gt;&gt; from rotalabs_comply.audit import EncryptionManager\n        &gt;&gt;&gt; encryption = EncryptionManager()\n        &gt;&gt;&gt; logger = AuditLogger(\n        ...     \"/var/log/audit\",\n        ...     encryption=encryption,\n        ...     store_content=True,\n        ... )\n        &gt;&gt;&gt; entry_id = await logger.log(\n        ...     input=\"Sensitive question\",\n        ...     output=\"Sensitive answer\",\n        ...     safety_passed=True,\n        ... )\n\n        With custom storage backend:\n\n        &gt;&gt;&gt; from rotalabs_comply.audit import MemoryStorage\n        &gt;&gt;&gt; storage = MemoryStorage(max_entries=10000)\n        &gt;&gt;&gt; logger = AuditLogger(storage)\n    \"\"\"\n\n    def __init__(\n        self,\n        storage: Union[StorageBackend, str],\n        encryption: EncryptionManager | None = None,\n        store_content: bool = False,\n        retention_days: int = 365,\n    ) -&gt; None:\n        \"\"\"\n        Initialize the audit logger.\n\n        Args:\n            storage: StorageBackend instance or file path string.\n            encryption: Optional encryption manager for content encryption.\n            store_content: Whether to store actual content (default: False).\n            retention_days: Days to retain entries (default: 365).\n        \"\"\"\n        if isinstance(storage, str):\n            self.storage: StorageBackend = FileStorage(storage)\n        else:\n            self.storage = storage\n\n        self.encryption = encryption\n        self.store_content = store_content\n        self.retention_days = retention_days\n\n    def _prepare_content(\n        self, content: str\n    ) -&gt; tuple[str | None, str]:\n        \"\"\"\n        Prepare content for storage.\n\n        Returns tuple of (stored_content, content_hash).\n        If store_content is False, stored_content will be None.\n        If encryption is enabled, stored_content will be encrypted.\n        \"\"\"\n        content_hash = hash_content(content)\n\n        if not self.store_content:\n            return None, content_hash\n\n        if self.encryption:\n            stored_content = self.encryption.encrypt(content)\n        else:\n            stored_content = content\n\n        return stored_content, content_hash\n\n    async def log(\n        self,\n        input: str,\n        output: str,\n        provider: str | None = None,\n        model: str | None = None,\n        conversation_id: str | None = None,\n        safety_passed: bool = True,\n        detectors_triggered: List[str] | None = None,\n        block_reason: str | None = None,\n        alerts: List[str] | None = None,\n        latency_ms: float = 0.0,\n        input_tokens: int | None = None,\n        output_tokens: int | None = None,\n        metadata: Dict[str, Any] | None = None,\n    ) -&gt; str:\n        \"\"\"\n        Log an AI interaction.\n\n        Creates an audit entry for the interaction and stores it in the\n        configured storage backend.\n\n        Args:\n            input: The user input or prompt.\n            output: The AI-generated output or response.\n            provider: The AI provider (e.g., \"openai\", \"anthropic\").\n            model: The model identifier (e.g., \"gpt-4\", \"claude-3-opus\").\n            conversation_id: Optional ID to link related interactions.\n            safety_passed: Whether the interaction passed safety checks\n                (default: True).\n            detectors_triggered: List of safety detector names that triggered.\n            block_reason: Reason for blocking, if the request was blocked.\n            alerts: List of alert messages generated.\n            latency_ms: Time taken to process the request in milliseconds\n                (default: 0.0).\n            input_tokens: Number of tokens in the input.\n            output_tokens: Number of tokens in the output.\n            metadata: Additional custom metadata dictionary.\n\n        Returns:\n            str: The unique entry ID for this audit log entry.\n\n        Example:\n            &gt;&gt;&gt; entry_id = await logger.log(\n            ...     input=\"Tell me a joke\",\n            ...     output=\"Why did the chicken...\",\n            ...     provider=\"anthropic\",\n            ...     model=\"claude-3-opus\",\n            ...     safety_passed=True,\n            ...     latency_ms=250.5,\n            ...     input_tokens=5,\n            ...     output_tokens=20,\n            ...     metadata={\"session_id\": \"abc123\"},\n            ... )\n        \"\"\"\n        entry_id = create_entry_id()\n        timestamp = datetime.utcnow().isoformat()\n\n        input_content, input_hash = self._prepare_content(input)\n        output_content, output_hash = self._prepare_content(output)\n\n        entry = AuditEntry(\n            id=entry_id,\n            timestamp=timestamp,\n            input_hash=input_hash,\n            output_hash=output_hash,\n            input_content=input_content,\n            output_content=output_content,\n            provider=provider,\n            model=model,\n            conversation_id=conversation_id,\n            safety_passed=safety_passed,\n            detectors_triggered=detectors_triggered or [],\n            block_reason=block_reason,\n            alerts=alerts or [],\n            latency_ms=latency_ms,\n            input_tokens=input_tokens,\n            output_tokens=output_tokens,\n            metadata=metadata or {},\n        )\n\n        await self.storage.write(entry)\n        return entry_id\n\n    async def get_entry(self, entry_id: str) -&gt; AuditEntry | None:\n        \"\"\"\n        Retrieve an audit entry by ID.\n\n        If encryption is enabled and store_content is True, the content\n        will still be encrypted in the returned entry. Use the encryption\n        manager to decrypt if needed.\n\n        Args:\n            entry_id: The unique identifier of the entry.\n\n        Returns:\n            AuditEntry | None: The entry if found, None otherwise.\n\n        Example:\n            &gt;&gt;&gt; entry = await logger.get_entry(\"abc-123-def\")\n            &gt;&gt;&gt; if entry:\n            ...     print(f\"Safety passed: {entry.safety_passed}\")\n        \"\"\"\n        return await self.storage.read(entry_id)\n\n    async def get_entries(\n        self, start: datetime, end: datetime\n    ) -&gt; List[AuditEntry]:\n        \"\"\"\n        Retrieve all audit entries within a time range.\n\n        Args:\n            start: Start of the time range (inclusive).\n            end: End of the time range (inclusive).\n\n        Returns:\n            List[AuditEntry]: All entries within the specified time range.\n\n        Example:\n            &gt;&gt;&gt; from datetime import datetime, timedelta\n            &gt;&gt;&gt; end = datetime.utcnow()\n            &gt;&gt;&gt; start = end - timedelta(days=7)\n            &gt;&gt;&gt; entries = await logger.get_entries(start, end)\n            &gt;&gt;&gt; print(f\"Found {len(entries)} entries in the last week\")\n        \"\"\"\n        return await self.storage.list_entries(start, end)\n\n    async def cleanup_expired(self) -&gt; int:\n        \"\"\"\n        Delete entries older than the retention period.\n\n        Removes all entries with timestamps older than `retention_days` from\n        the current time.\n\n        Returns:\n            int: Number of entries deleted.\n\n        Example:\n            &gt;&gt;&gt; # Delete entries older than retention_days\n            &gt;&gt;&gt; deleted_count = await logger.cleanup_expired()\n            &gt;&gt;&gt; print(f\"Cleaned up {deleted_count} expired entries\")\n\n        Note:\n            This operation may be slow for large datasets. Consider running\n            during off-peak hours or using storage-native lifecycle policies\n            (e.g., S3 lifecycle rules) for better performance.\n        \"\"\"\n        cutoff = datetime.utcnow() - timedelta(days=self.retention_days)\n        start = datetime(1970, 1, 1)  # Unix epoch\n\n        expired_entries = await self.storage.list_entries(start, cutoff)\n\n        deleted_count = 0\n        for entry in expired_entries:\n            if await self.storage.delete(entry.id):\n                deleted_count += 1\n\n        return deleted_count\n\n    def decrypt_content(self, encrypted_content: str) -&gt; str:\n        \"\"\"\n        Decrypt encrypted content from an audit entry.\n\n        Convenience method for decrypting content stored in audit entries\n        when encryption is enabled.\n\n        Args:\n            encrypted_content: The encrypted content string from an AuditEntry.\n\n        Returns:\n            str: The decrypted original content.\n\n        Raises:\n            ValueError: If no encryption manager is configured.\n            cryptography.fernet.InvalidToken: If decryption fails.\n\n        Example:\n            &gt;&gt;&gt; entry = await logger.get_entry(\"abc-123\")\n            &gt;&gt;&gt; if entry and entry.input_content:\n            ...     original_input = logger.decrypt_content(entry.input_content)\n        \"\"\"\n        if not self.encryption:\n            raise ValueError(\n                \"No encryption manager configured. \"\n                \"Cannot decrypt content without the original encryption key.\"\n            )\n        return self.encryption.decrypt(encrypted_content)\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.logger.AuditLogger.__init__","title":"__init__","text":"<pre><code>__init__(\n    storage: Union[StorageBackend, str],\n    encryption: EncryptionManager | None = None,\n    store_content: bool = False,\n    retention_days: int = 365,\n) -&gt; None\n</code></pre> <p>Initialize the audit logger.</p> <p>Parameters:</p> Name Type Description Default <code>storage</code> <code>Union[StorageBackend, str]</code> <p>StorageBackend instance or file path string.</p> required <code>encryption</code> <code>EncryptionManager | None</code> <p>Optional encryption manager for content encryption.</p> <code>None</code> <code>store_content</code> <code>bool</code> <p>Whether to store actual content (default: False).</p> <code>False</code> <code>retention_days</code> <code>int</code> <p>Days to retain entries (default: 365).</p> <code>365</code> Source code in <code>src/rotalabs_comply/audit/logger.py</code> <pre><code>def __init__(\n    self,\n    storage: Union[StorageBackend, str],\n    encryption: EncryptionManager | None = None,\n    store_content: bool = False,\n    retention_days: int = 365,\n) -&gt; None:\n    \"\"\"\n    Initialize the audit logger.\n\n    Args:\n        storage: StorageBackend instance or file path string.\n        encryption: Optional encryption manager for content encryption.\n        store_content: Whether to store actual content (default: False).\n        retention_days: Days to retain entries (default: 365).\n    \"\"\"\n    if isinstance(storage, str):\n        self.storage: StorageBackend = FileStorage(storage)\n    else:\n        self.storage = storage\n\n    self.encryption = encryption\n    self.store_content = store_content\n    self.retention_days = retention_days\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.logger.AuditLogger.log","title":"log  <code>async</code>","text":"<pre><code>log(\n    input: str,\n    output: str,\n    provider: str | None = None,\n    model: str | None = None,\n    conversation_id: str | None = None,\n    safety_passed: bool = True,\n    detectors_triggered: List[str] | None = None,\n    block_reason: str | None = None,\n    alerts: List[str] | None = None,\n    latency_ms: float = 0.0,\n    input_tokens: int | None = None,\n    output_tokens: int | None = None,\n    metadata: Dict[str, Any] | None = None,\n) -&gt; str\n</code></pre> <p>Log an AI interaction.</p> <p>Creates an audit entry for the interaction and stores it in the configured storage backend.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>str</code> <p>The user input or prompt.</p> required <code>output</code> <code>str</code> <p>The AI-generated output or response.</p> required <code>provider</code> <code>str | None</code> <p>The AI provider (e.g., \"openai\", \"anthropic\").</p> <code>None</code> <code>model</code> <code>str | None</code> <p>The model identifier (e.g., \"gpt-4\", \"claude-3-opus\").</p> <code>None</code> <code>conversation_id</code> <code>str | None</code> <p>Optional ID to link related interactions.</p> <code>None</code> <code>safety_passed</code> <code>bool</code> <p>Whether the interaction passed safety checks (default: True).</p> <code>True</code> <code>detectors_triggered</code> <code>List[str] | None</code> <p>List of safety detector names that triggered.</p> <code>None</code> <code>block_reason</code> <code>str | None</code> <p>Reason for blocking, if the request was blocked.</p> <code>None</code> <code>alerts</code> <code>List[str] | None</code> <p>List of alert messages generated.</p> <code>None</code> <code>latency_ms</code> <code>float</code> <p>Time taken to process the request in milliseconds (default: 0.0).</p> <code>0.0</code> <code>input_tokens</code> <code>int | None</code> <p>Number of tokens in the input.</p> <code>None</code> <code>output_tokens</code> <code>int | None</code> <p>Number of tokens in the output.</p> <code>None</code> <code>metadata</code> <code>Dict[str, Any] | None</code> <p>Additional custom metadata dictionary.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The unique entry ID for this audit log entry.</p> Example <p>entry_id = await logger.log( ...     input=\"Tell me a joke\", ...     output=\"Why did the chicken...\", ...     provider=\"anthropic\", ...     model=\"claude-3-opus\", ...     safety_passed=True, ...     latency_ms=250.5, ...     input_tokens=5, ...     output_tokens=20, ...     metadata={\"session_id\": \"abc123\"}, ... )</p> Source code in <code>src/rotalabs_comply/audit/logger.py</code> <pre><code>async def log(\n    self,\n    input: str,\n    output: str,\n    provider: str | None = None,\n    model: str | None = None,\n    conversation_id: str | None = None,\n    safety_passed: bool = True,\n    detectors_triggered: List[str] | None = None,\n    block_reason: str | None = None,\n    alerts: List[str] | None = None,\n    latency_ms: float = 0.0,\n    input_tokens: int | None = None,\n    output_tokens: int | None = None,\n    metadata: Dict[str, Any] | None = None,\n) -&gt; str:\n    \"\"\"\n    Log an AI interaction.\n\n    Creates an audit entry for the interaction and stores it in the\n    configured storage backend.\n\n    Args:\n        input: The user input or prompt.\n        output: The AI-generated output or response.\n        provider: The AI provider (e.g., \"openai\", \"anthropic\").\n        model: The model identifier (e.g., \"gpt-4\", \"claude-3-opus\").\n        conversation_id: Optional ID to link related interactions.\n        safety_passed: Whether the interaction passed safety checks\n            (default: True).\n        detectors_triggered: List of safety detector names that triggered.\n        block_reason: Reason for blocking, if the request was blocked.\n        alerts: List of alert messages generated.\n        latency_ms: Time taken to process the request in milliseconds\n            (default: 0.0).\n        input_tokens: Number of tokens in the input.\n        output_tokens: Number of tokens in the output.\n        metadata: Additional custom metadata dictionary.\n\n    Returns:\n        str: The unique entry ID for this audit log entry.\n\n    Example:\n        &gt;&gt;&gt; entry_id = await logger.log(\n        ...     input=\"Tell me a joke\",\n        ...     output=\"Why did the chicken...\",\n        ...     provider=\"anthropic\",\n        ...     model=\"claude-3-opus\",\n        ...     safety_passed=True,\n        ...     latency_ms=250.5,\n        ...     input_tokens=5,\n        ...     output_tokens=20,\n        ...     metadata={\"session_id\": \"abc123\"},\n        ... )\n    \"\"\"\n    entry_id = create_entry_id()\n    timestamp = datetime.utcnow().isoformat()\n\n    input_content, input_hash = self._prepare_content(input)\n    output_content, output_hash = self._prepare_content(output)\n\n    entry = AuditEntry(\n        id=entry_id,\n        timestamp=timestamp,\n        input_hash=input_hash,\n        output_hash=output_hash,\n        input_content=input_content,\n        output_content=output_content,\n        provider=provider,\n        model=model,\n        conversation_id=conversation_id,\n        safety_passed=safety_passed,\n        detectors_triggered=detectors_triggered or [],\n        block_reason=block_reason,\n        alerts=alerts or [],\n        latency_ms=latency_ms,\n        input_tokens=input_tokens,\n        output_tokens=output_tokens,\n        metadata=metadata or {},\n    )\n\n    await self.storage.write(entry)\n    return entry_id\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.logger.AuditLogger.get_entry","title":"get_entry  <code>async</code>","text":"<pre><code>get_entry(entry_id: str) -&gt; AuditEntry | None\n</code></pre> <p>Retrieve an audit entry by ID.</p> <p>If encryption is enabled and store_content is True, the content will still be encrypted in the returned entry. Use the encryption manager to decrypt if needed.</p> <p>Parameters:</p> Name Type Description Default <code>entry_id</code> <code>str</code> <p>The unique identifier of the entry.</p> required <p>Returns:</p> Type Description <code>AuditEntry | None</code> <p>AuditEntry | None: The entry if found, None otherwise.</p> Example <p>entry = await logger.get_entry(\"abc-123-def\") if entry: ...     print(f\"Safety passed: {entry.safety_passed}\")</p> Source code in <code>src/rotalabs_comply/audit/logger.py</code> <pre><code>async def get_entry(self, entry_id: str) -&gt; AuditEntry | None:\n    \"\"\"\n    Retrieve an audit entry by ID.\n\n    If encryption is enabled and store_content is True, the content\n    will still be encrypted in the returned entry. Use the encryption\n    manager to decrypt if needed.\n\n    Args:\n        entry_id: The unique identifier of the entry.\n\n    Returns:\n        AuditEntry | None: The entry if found, None otherwise.\n\n    Example:\n        &gt;&gt;&gt; entry = await logger.get_entry(\"abc-123-def\")\n        &gt;&gt;&gt; if entry:\n        ...     print(f\"Safety passed: {entry.safety_passed}\")\n    \"\"\"\n    return await self.storage.read(entry_id)\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.logger.AuditLogger.get_entries","title":"get_entries  <code>async</code>","text":"<pre><code>get_entries(\n    start: datetime, end: datetime\n) -&gt; List[AuditEntry]\n</code></pre> <p>Retrieve all audit entries within a time range.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>datetime</code> <p>Start of the time range (inclusive).</p> required <code>end</code> <code>datetime</code> <p>End of the time range (inclusive).</p> required <p>Returns:</p> Type Description <code>List[AuditEntry]</code> <p>List[AuditEntry]: All entries within the specified time range.</p> Example <p>from datetime import datetime, timedelta end = datetime.utcnow() start = end - timedelta(days=7) entries = await logger.get_entries(start, end) print(f\"Found {len(entries)} entries in the last week\")</p> Source code in <code>src/rotalabs_comply/audit/logger.py</code> <pre><code>async def get_entries(\n    self, start: datetime, end: datetime\n) -&gt; List[AuditEntry]:\n    \"\"\"\n    Retrieve all audit entries within a time range.\n\n    Args:\n        start: Start of the time range (inclusive).\n        end: End of the time range (inclusive).\n\n    Returns:\n        List[AuditEntry]: All entries within the specified time range.\n\n    Example:\n        &gt;&gt;&gt; from datetime import datetime, timedelta\n        &gt;&gt;&gt; end = datetime.utcnow()\n        &gt;&gt;&gt; start = end - timedelta(days=7)\n        &gt;&gt;&gt; entries = await logger.get_entries(start, end)\n        &gt;&gt;&gt; print(f\"Found {len(entries)} entries in the last week\")\n    \"\"\"\n    return await self.storage.list_entries(start, end)\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.logger.AuditLogger.cleanup_expired","title":"cleanup_expired  <code>async</code>","text":"<pre><code>cleanup_expired() -&gt; int\n</code></pre> <p>Delete entries older than the retention period.</p> <p>Removes all entries with timestamps older than <code>retention_days</code> from the current time.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Number of entries deleted.</p> Example Note <p>This operation may be slow for large datasets. Consider running during off-peak hours or using storage-native lifecycle policies (e.g., S3 lifecycle rules) for better performance.</p> Source code in <code>src/rotalabs_comply/audit/logger.py</code> <pre><code>async def cleanup_expired(self) -&gt; int:\n    \"\"\"\n    Delete entries older than the retention period.\n\n    Removes all entries with timestamps older than `retention_days` from\n    the current time.\n\n    Returns:\n        int: Number of entries deleted.\n\n    Example:\n        &gt;&gt;&gt; # Delete entries older than retention_days\n        &gt;&gt;&gt; deleted_count = await logger.cleanup_expired()\n        &gt;&gt;&gt; print(f\"Cleaned up {deleted_count} expired entries\")\n\n    Note:\n        This operation may be slow for large datasets. Consider running\n        during off-peak hours or using storage-native lifecycle policies\n        (e.g., S3 lifecycle rules) for better performance.\n    \"\"\"\n    cutoff = datetime.utcnow() - timedelta(days=self.retention_days)\n    start = datetime(1970, 1, 1)  # Unix epoch\n\n    expired_entries = await self.storage.list_entries(start, cutoff)\n\n    deleted_count = 0\n    for entry in expired_entries:\n        if await self.storage.delete(entry.id):\n            deleted_count += 1\n\n    return deleted_count\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.logger.AuditLogger.cleanup_expired--delete-entries-older-than-retention_days","title":"Delete entries older than retention_days","text":"<p>deleted_count = await logger.cleanup_expired() print(f\"Cleaned up {deleted_count} expired entries\")</p>"},{"location":"api/audit/#rotalabs_comply.audit.logger.AuditLogger.decrypt_content","title":"decrypt_content","text":"<pre><code>decrypt_content(encrypted_content: str) -&gt; str\n</code></pre> <p>Decrypt encrypted content from an audit entry.</p> <p>Convenience method for decrypting content stored in audit entries when encryption is enabled.</p> <p>Parameters:</p> Name Type Description Default <code>encrypted_content</code> <code>str</code> <p>The encrypted content string from an AuditEntry.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The decrypted original content.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no encryption manager is configured.</p> <code>InvalidToken</code> <p>If decryption fails.</p> Example <p>entry = await logger.get_entry(\"abc-123\") if entry and entry.input_content: ...     original_input = logger.decrypt_content(entry.input_content)</p> Source code in <code>src/rotalabs_comply/audit/logger.py</code> <pre><code>def decrypt_content(self, encrypted_content: str) -&gt; str:\n    \"\"\"\n    Decrypt encrypted content from an audit entry.\n\n    Convenience method for decrypting content stored in audit entries\n    when encryption is enabled.\n\n    Args:\n        encrypted_content: The encrypted content string from an AuditEntry.\n\n    Returns:\n        str: The decrypted original content.\n\n    Raises:\n        ValueError: If no encryption manager is configured.\n        cryptography.fernet.InvalidToken: If decryption fails.\n\n    Example:\n        &gt;&gt;&gt; entry = await logger.get_entry(\"abc-123\")\n        &gt;&gt;&gt; if entry and entry.input_content:\n        ...     original_input = logger.decrypt_content(entry.input_content)\n    \"\"\"\n    if not self.encryption:\n        raise ValueError(\n            \"No encryption manager configured. \"\n            \"Cannot decrypt content without the original encryption key.\"\n        )\n    return self.encryption.decrypt(encrypted_content)\n</code></pre>"},{"location":"api/audit/#constructor","title":"Constructor","text":"<pre><code>AuditLogger(\n    storage: Union[StorageBackend, str],\n    encryption: Optional[EncryptionManager] = None,\n    store_content: bool = False,\n    retention_days: int = 365,\n)\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>storage</code> <code>Union[StorageBackend, str]</code> Required Storage backend or file path <code>encryption</code> <code>Optional[EncryptionManager]</code> <code>None</code> Encryption manager for content <code>store_content</code> <code>bool</code> <code>False</code> Store actual content vs hashes <code>retention_days</code> <code>int</code> <code>365</code> Days to retain entries"},{"location":"api/audit/#methods","title":"Methods","text":""},{"location":"api/audit/#log","title":"log","text":"<pre><code>async def log(\n    input: str,\n    output: str,\n    provider: Optional[str] = None,\n    model: Optional[str] = None,\n    conversation_id: Optional[str] = None,\n    safety_passed: bool = True,\n    detectors_triggered: Optional[List[str]] = None,\n    block_reason: Optional[str] = None,\n    alerts: Optional[List[str]] = None,\n    latency_ms: float = 0.0,\n    input_tokens: Optional[int] = None,\n    output_tokens: Optional[int] = None,\n    metadata: Optional[Dict[str, Any]] = None,\n) -&gt; str\n</code></pre> <p>Log an AI interaction and return the entry ID.</p> <p>Example:</p> <pre><code>entry_id = await logger.log(\n    input=\"Tell me a joke\",\n    output=\"Why did the chicken...\",\n    provider=\"anthropic\",\n    model=\"claude-3-opus\",\n    safety_passed=True,\n    latency_ms=250.5,\n    metadata={\"session_id\": \"abc123\"},\n)\n</code></pre>"},{"location":"api/audit/#get_entry","title":"get_entry","text":"<pre><code>async def get_entry(entry_id: str) -&gt; Optional[AuditEntry]\n</code></pre> <p>Retrieve an audit entry by ID.</p> <p>Example:</p> <pre><code>entry = await logger.get_entry(\"abc-123-def\")\nif entry:\n    print(f\"Safety passed: {entry.safety_passed}\")\n</code></pre>"},{"location":"api/audit/#get_entries","title":"get_entries","text":"<pre><code>async def get_entries(start: datetime, end: datetime) -&gt; List[AuditEntry]\n</code></pre> <p>Retrieve all entries within a time range.</p> <p>Example:</p> <pre><code>from datetime import datetime, timedelta\n\nend = datetime.utcnow()\nstart = end - timedelta(days=7)\nentries = await logger.get_entries(start, end)\n</code></pre>"},{"location":"api/audit/#cleanup_expired","title":"cleanup_expired","text":"<pre><code>async def cleanup_expired() -&gt; int\n</code></pre> <p>Delete entries older than the retention period. Returns count of deleted entries.</p> <p>Example:</p> <pre><code>deleted = await logger.cleanup_expired()\nprint(f\"Cleaned up {deleted} expired entries\")\n</code></pre>"},{"location":"api/audit/#decrypt_content","title":"decrypt_content","text":"<pre><code>def decrypt_content(encrypted_content: str) -&gt; str\n</code></pre> <p>Decrypt encrypted content from an audit entry.</p> <p>Raises:</p> <ul> <li><code>ValueError</code>: If no encryption manager is configured</li> <li><code>cryptography.fernet.InvalidToken</code>: If decryption fails</li> </ul> <p>Example:</p> <pre><code>entry = await logger.get_entry(\"abc-123\")\nif entry and entry.input_content:\n    original = logger.decrypt_content(entry.input_content)\n</code></pre>"},{"location":"api/audit/#encryption","title":"Encryption","text":""},{"location":"api/audit/#encryptionmanager","title":"EncryptionManager","text":"<p>High-level encryption manager for string data.</p>"},{"location":"api/audit/#rotalabs_comply.audit.encryption.EncryptionManager","title":"EncryptionManager","text":"<p>High-level encryption manager for string data.</p> <p>Provides a convenient interface for encrypting and decrypting string data, with automatic key generation if not provided.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>bytes | None</code> <p>Optional Fernet encryption key. If not provided, a new key is generated.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>_key</code> <p>The encryption key (kept private).</p> <code>_fernet</code> <p>The Fernet cipher instance.</p> Example <p>manager = EncryptionManager() encrypted = manager.encrypt(\"sensitive data\") manager.decrypt(encrypted) 'sensitive data'</p> Source code in <code>src/rotalabs_comply/audit/encryption.py</code> <pre><code>class EncryptionManager:\n    \"\"\"\n    High-level encryption manager for string data.\n\n    Provides a convenient interface for encrypting and decrypting string data,\n    with automatic key generation if not provided.\n\n    Args:\n        key: Optional Fernet encryption key. If not provided, a new key is generated.\n\n    Attributes:\n        _key: The encryption key (kept private).\n        _fernet: The Fernet cipher instance.\n\n    Example:\n        &gt;&gt;&gt; manager = EncryptionManager()\n        &gt;&gt;&gt; encrypted = manager.encrypt(\"sensitive data\")\n        &gt;&gt;&gt; manager.decrypt(encrypted)\n        'sensitive data'\n\n        &gt;&gt;&gt; # Use existing key\n        &gt;&gt;&gt; key = generate_key()\n        &gt;&gt;&gt; manager = EncryptionManager(key)\n        &gt;&gt;&gt; manager.get_key() == key\n        True\n    \"\"\"\n\n    def __init__(self, key: bytes | None = None) -&gt; None:\n        \"\"\"\n        Initialize the encryption manager.\n\n        Args:\n            key: Optional Fernet encryption key. If None, generates a new key.\n        \"\"\"\n        self._key = key if key is not None else generate_key()\n        self._fernet = Fernet(self._key)\n\n    def encrypt(self, data: str) -&gt; str:\n        \"\"\"\n        Encrypt a string and return base64-encoded result.\n\n        Args:\n            data: The string to encrypt.\n\n        Returns:\n            str: Base64-encoded encrypted string, safe for storage in JSON.\n\n        Example:\n            &gt;&gt;&gt; manager = EncryptionManager()\n            &gt;&gt;&gt; encrypted = manager.encrypt(\"secret\")\n            &gt;&gt;&gt; isinstance(encrypted, str)\n            True\n        \"\"\"\n        encrypted_bytes = self._fernet.encrypt(data.encode(\"utf-8\"))\n        return base64.urlsafe_b64encode(encrypted_bytes).decode(\"ascii\")\n\n    def decrypt(self, data: str) -&gt; str:\n        \"\"\"\n        Decrypt a base64-encoded encrypted string.\n\n        Args:\n            data: The base64-encoded encrypted string (from encrypt()).\n\n        Returns:\n            str: The original decrypted string.\n\n        Raises:\n            cryptography.fernet.InvalidToken: If decryption fails.\n\n        Example:\n            &gt;&gt;&gt; manager = EncryptionManager()\n            &gt;&gt;&gt; encrypted = manager.encrypt(\"secret\")\n            &gt;&gt;&gt; manager.decrypt(encrypted)\n            'secret'\n        \"\"\"\n        encrypted_bytes = base64.urlsafe_b64decode(data.encode(\"ascii\"))\n        decrypted_bytes = self._fernet.decrypt(encrypted_bytes)\n        return decrypted_bytes.decode(\"utf-8\")\n\n    def get_key(self) -&gt; bytes:\n        \"\"\"\n        Get the encryption key.\n\n        Returns:\n            bytes: The Fernet encryption key. Store this securely!\n\n        Warning:\n            The encryption key must be stored securely. If lost, encrypted\n            data cannot be recovered.\n\n        Example:\n            &gt;&gt;&gt; manager = EncryptionManager()\n            &gt;&gt;&gt; key = manager.get_key()\n            &gt;&gt;&gt; len(key)\n            44\n        \"\"\"\n        return self._key\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.encryption.EncryptionManager--use-existing-key","title":"Use existing key","text":"<p>key = generate_key() manager = EncryptionManager(key) manager.get_key() == key True</p>"},{"location":"api/audit/#rotalabs_comply.audit.encryption.EncryptionManager.__init__","title":"__init__","text":"<pre><code>__init__(key: bytes | None = None) -&gt; None\n</code></pre> <p>Initialize the encryption manager.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>bytes | None</code> <p>Optional Fernet encryption key. If None, generates a new key.</p> <code>None</code> Source code in <code>src/rotalabs_comply/audit/encryption.py</code> <pre><code>def __init__(self, key: bytes | None = None) -&gt; None:\n    \"\"\"\n    Initialize the encryption manager.\n\n    Args:\n        key: Optional Fernet encryption key. If None, generates a new key.\n    \"\"\"\n    self._key = key if key is not None else generate_key()\n    self._fernet = Fernet(self._key)\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.encryption.EncryptionManager.encrypt","title":"encrypt","text":"<pre><code>encrypt(data: str) -&gt; str\n</code></pre> <p>Encrypt a string and return base64-encoded result.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str</code> <p>The string to encrypt.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>Base64-encoded encrypted string, safe for storage in JSON.</p> Example <p>manager = EncryptionManager() encrypted = manager.encrypt(\"secret\") isinstance(encrypted, str) True</p> Source code in <code>src/rotalabs_comply/audit/encryption.py</code> <pre><code>def encrypt(self, data: str) -&gt; str:\n    \"\"\"\n    Encrypt a string and return base64-encoded result.\n\n    Args:\n        data: The string to encrypt.\n\n    Returns:\n        str: Base64-encoded encrypted string, safe for storage in JSON.\n\n    Example:\n        &gt;&gt;&gt; manager = EncryptionManager()\n        &gt;&gt;&gt; encrypted = manager.encrypt(\"secret\")\n        &gt;&gt;&gt; isinstance(encrypted, str)\n        True\n    \"\"\"\n    encrypted_bytes = self._fernet.encrypt(data.encode(\"utf-8\"))\n    return base64.urlsafe_b64encode(encrypted_bytes).decode(\"ascii\")\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.encryption.EncryptionManager.decrypt","title":"decrypt","text":"<pre><code>decrypt(data: str) -&gt; str\n</code></pre> <p>Decrypt a base64-encoded encrypted string.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>str</code> <p>The base64-encoded encrypted string (from encrypt()).</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The original decrypted string.</p> <p>Raises:</p> Type Description <code>InvalidToken</code> <p>If decryption fails.</p> Example <p>manager = EncryptionManager() encrypted = manager.encrypt(\"secret\") manager.decrypt(encrypted) 'secret'</p> Source code in <code>src/rotalabs_comply/audit/encryption.py</code> <pre><code>def decrypt(self, data: str) -&gt; str:\n    \"\"\"\n    Decrypt a base64-encoded encrypted string.\n\n    Args:\n        data: The base64-encoded encrypted string (from encrypt()).\n\n    Returns:\n        str: The original decrypted string.\n\n    Raises:\n        cryptography.fernet.InvalidToken: If decryption fails.\n\n    Example:\n        &gt;&gt;&gt; manager = EncryptionManager()\n        &gt;&gt;&gt; encrypted = manager.encrypt(\"secret\")\n        &gt;&gt;&gt; manager.decrypt(encrypted)\n        'secret'\n    \"\"\"\n    encrypted_bytes = base64.urlsafe_b64decode(data.encode(\"ascii\"))\n    decrypted_bytes = self._fernet.decrypt(encrypted_bytes)\n    return decrypted_bytes.decode(\"utf-8\")\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.encryption.EncryptionManager.get_key","title":"get_key","text":"<pre><code>get_key() -&gt; bytes\n</code></pre> <p>Get the encryption key.</p> <p>Returns:</p> Name Type Description <code>bytes</code> <code>bytes</code> <p>The Fernet encryption key. Store this securely!</p> Warning <p>The encryption key must be stored securely. If lost, encrypted data cannot be recovered.</p> Example <p>manager = EncryptionManager() key = manager.get_key() len(key) 44</p> Source code in <code>src/rotalabs_comply/audit/encryption.py</code> <pre><code>def get_key(self) -&gt; bytes:\n    \"\"\"\n    Get the encryption key.\n\n    Returns:\n        bytes: The Fernet encryption key. Store this securely!\n\n    Warning:\n        The encryption key must be stored securely. If lost, encrypted\n        data cannot be recovered.\n\n    Example:\n        &gt;&gt;&gt; manager = EncryptionManager()\n        &gt;&gt;&gt; key = manager.get_key()\n        &gt;&gt;&gt; len(key)\n        44\n    \"\"\"\n    return self._key\n</code></pre>"},{"location":"api/audit/#constructor_1","title":"Constructor","text":"<pre><code>EncryptionManager(key: Optional[bytes] = None)\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>key</code> <code>Optional[bytes]</code> Auto-gen Fernet encryption key"},{"location":"api/audit/#methods_1","title":"Methods","text":""},{"location":"api/audit/#encrypt","title":"encrypt","text":"<pre><code>def encrypt(data: str) -&gt; str\n</code></pre> <p>Encrypt a string and return base64-encoded result.</p>"},{"location":"api/audit/#decrypt","title":"decrypt","text":"<pre><code>def decrypt(data: str) -&gt; str\n</code></pre> <p>Decrypt a base64-encoded encrypted string.</p>"},{"location":"api/audit/#get_key","title":"get_key","text":"<pre><code>def get_key() -&gt; bytes\n</code></pre> <p>Get the encryption key. Store this securely!</p> <p>Example:</p> <pre><code>from rotalabs_comply import EncryptionManager\n\nmanager = EncryptionManager()\nencrypted = manager.encrypt(\"sensitive data\")\ndecrypted = manager.decrypt(encrypted)\n\n# Save key securely\nkey = manager.get_key()\n</code></pre>"},{"location":"api/audit/#helper-functions","title":"Helper Functions","text":""},{"location":"api/audit/#generate_key","title":"generate_key","text":"<pre><code>def generate_key() -&gt; bytes\n</code></pre> <p>Generate a new Fernet encryption key.</p> <p>Example:</p> <pre><code>from rotalabs_comply import generate_key\n\nkey = generate_key()\nprint(len(key))  # 44\n</code></pre>"},{"location":"api/audit/#encrypt_1","title":"encrypt","text":"<pre><code>def encrypt(data: bytes, key: bytes) -&gt; bytes\n</code></pre> <p>Encrypt raw bytes using Fernet symmetric encryption.</p>"},{"location":"api/audit/#decrypt_1","title":"decrypt","text":"<pre><code>def decrypt(data: bytes, key: bytes) -&gt; bytes\n</code></pre> <p>Decrypt data that was encrypted with Fernet.</p>"},{"location":"api/audit/#hash_content","title":"hash_content","text":"<pre><code>def hash_content(content: str) -&gt; str\n</code></pre> <p>Compute SHA-256 hash of string content.</p> <p>Example:</p> <pre><code>from rotalabs_comply import hash_content\n\ncontent_hash = hash_content(\"hello world\")\n# Returns: 'b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9'\n</code></pre>"},{"location":"api/audit/#storage-backends","title":"Storage Backends","text":""},{"location":"api/audit/#storagebackend-protocol","title":"StorageBackend Protocol","text":"<p>Protocol defining the interface for audit log storage backends.</p> <p>Required Methods:</p> Method Signature Description <code>write</code> <code>async (entry: AuditEntry) -&gt; str</code> Write entry, return ID <code>read</code> <code>async (entry_id: str) -&gt; Optional[AuditEntry]</code> Read entry by ID <code>list_entries</code> <code>async (start: datetime, end: datetime) -&gt; List[AuditEntry]</code> List entries in range <code>delete</code> <code>async (entry_id: str) -&gt; bool</code> Delete entry, return success <code>count</code> <code>async () -&gt; int</code> Count total entries"},{"location":"api/audit/#rotalabs_comply.audit.storage.StorageBackend","title":"StorageBackend","text":"<p>Protocol defining the interface for audit log storage backends.</p> <p>All storage backends must implement these async methods to support writing, reading, listing, deleting, and counting audit entries.</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>@runtime_checkable\nclass StorageBackend(Protocol):\n    \"\"\"\n    Protocol defining the interface for audit log storage backends.\n\n    All storage backends must implement these async methods to support\n    writing, reading, listing, deleting, and counting audit entries.\n    \"\"\"\n\n    @abstractmethod\n    async def write(self, entry: AuditEntry) -&gt; str:\n        \"\"\"\n        Write an audit entry to storage.\n\n        Args:\n            entry: The audit entry to store.\n\n        Returns:\n            str: The entry ID (same as entry.id).\n        \"\"\"\n        ...\n\n    @abstractmethod\n    async def read(self, entry_id: str) -&gt; AuditEntry | None:\n        \"\"\"\n        Read an audit entry by ID.\n\n        Args:\n            entry_id: The unique identifier of the entry.\n\n        Returns:\n            AuditEntry | None: The entry if found, None otherwise.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    async def list_entries(\n        self, start: datetime, end: datetime\n    ) -&gt; List[AuditEntry]:\n        \"\"\"\n        List all entries within a time range.\n\n        Args:\n            start: Start of the time range (inclusive).\n            end: End of the time range (inclusive).\n\n        Returns:\n            List[AuditEntry]: Entries within the specified time range.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    async def delete(self, entry_id: str) -&gt; bool:\n        \"\"\"\n        Delete an entry by ID.\n\n        Args:\n            entry_id: The unique identifier of the entry to delete.\n\n        Returns:\n            bool: True if the entry was deleted, False if not found.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    async def count(self) -&gt; int:\n        \"\"\"\n        Count total number of entries in storage.\n\n        Returns:\n            int: Total number of stored entries.\n        \"\"\"\n        ...\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.StorageBackend.write","title":"write  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>write(entry: AuditEntry) -&gt; str\n</code></pre> <p>Write an audit entry to storage.</p> <p>Parameters:</p> Name Type Description Default <code>entry</code> <code>AuditEntry</code> <p>The audit entry to store.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The entry ID (same as entry.id).</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>@abstractmethod\nasync def write(self, entry: AuditEntry) -&gt; str:\n    \"\"\"\n    Write an audit entry to storage.\n\n    Args:\n        entry: The audit entry to store.\n\n    Returns:\n        str: The entry ID (same as entry.id).\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.StorageBackend.read","title":"read  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>read(entry_id: str) -&gt; AuditEntry | None\n</code></pre> <p>Read an audit entry by ID.</p> <p>Parameters:</p> Name Type Description Default <code>entry_id</code> <code>str</code> <p>The unique identifier of the entry.</p> required <p>Returns:</p> Type Description <code>AuditEntry | None</code> <p>AuditEntry | None: The entry if found, None otherwise.</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>@abstractmethod\nasync def read(self, entry_id: str) -&gt; AuditEntry | None:\n    \"\"\"\n    Read an audit entry by ID.\n\n    Args:\n        entry_id: The unique identifier of the entry.\n\n    Returns:\n        AuditEntry | None: The entry if found, None otherwise.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.StorageBackend.list_entries","title":"list_entries  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>list_entries(\n    start: datetime, end: datetime\n) -&gt; List[AuditEntry]\n</code></pre> <p>List all entries within a time range.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>datetime</code> <p>Start of the time range (inclusive).</p> required <code>end</code> <code>datetime</code> <p>End of the time range (inclusive).</p> required <p>Returns:</p> Type Description <code>List[AuditEntry]</code> <p>List[AuditEntry]: Entries within the specified time range.</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>@abstractmethod\nasync def list_entries(\n    self, start: datetime, end: datetime\n) -&gt; List[AuditEntry]:\n    \"\"\"\n    List all entries within a time range.\n\n    Args:\n        start: Start of the time range (inclusive).\n        end: End of the time range (inclusive).\n\n    Returns:\n        List[AuditEntry]: Entries within the specified time range.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.StorageBackend.delete","title":"delete  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>delete(entry_id: str) -&gt; bool\n</code></pre> <p>Delete an entry by ID.</p> <p>Parameters:</p> Name Type Description Default <code>entry_id</code> <code>str</code> <p>The unique identifier of the entry to delete.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the entry was deleted, False if not found.</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>@abstractmethod\nasync def delete(self, entry_id: str) -&gt; bool:\n    \"\"\"\n    Delete an entry by ID.\n\n    Args:\n        entry_id: The unique identifier of the entry to delete.\n\n    Returns:\n        bool: True if the entry was deleted, False if not found.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.StorageBackend.count","title":"count  <code>abstractmethod</code> <code>async</code>","text":"<pre><code>count() -&gt; int\n</code></pre> <p>Count total number of entries in storage.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Total number of stored entries.</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>@abstractmethod\nasync def count(self) -&gt; int:\n    \"\"\"\n    Count total number of entries in storage.\n\n    Returns:\n        int: Total number of stored entries.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/audit/#filestorage","title":"FileStorage","text":"<p>File-based storage backend using JSONL format.</p>"},{"location":"api/audit/#rotalabs_comply.audit.storage.FileStorage","title":"FileStorage","text":"<p>File-based storage backend using JSONL format.</p> <p>Stores audit entries as JSON Lines files with automatic rotation when files exceed the configured size limit.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Directory path for storing audit files.</p> required <code>rotation_size_mb</code> <code>int</code> <p>Maximum file size in MB before rotation (default: 100).</p> <code>100</code> <p>Attributes:</p> Name Type Description <code>path</code> <p>The storage directory path.</p> <code>rotation_size_bytes</code> <p>Maximum file size in bytes.</p> Example <p>storage = FileStorage(\"/var/log/audit\") entry_id = await storage.write(entry) retrieved = await storage.read(entry_id)</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>class FileStorage:\n    \"\"\"\n    File-based storage backend using JSONL format.\n\n    Stores audit entries as JSON Lines files with automatic rotation\n    when files exceed the configured size limit.\n\n    Args:\n        path: Directory path for storing audit files.\n        rotation_size_mb: Maximum file size in MB before rotation (default: 100).\n\n    Attributes:\n        path: The storage directory path.\n        rotation_size_bytes: Maximum file size in bytes.\n\n    Example:\n        &gt;&gt;&gt; storage = FileStorage(\"/var/log/audit\")\n        &gt;&gt;&gt; entry_id = await storage.write(entry)\n        &gt;&gt;&gt; retrieved = await storage.read(entry_id)\n    \"\"\"\n\n    def __init__(self, path: str, rotation_size_mb: int = 100) -&gt; None:\n        \"\"\"\n        Initialize file storage.\n\n        Args:\n            path: Directory path for storing audit files.\n            rotation_size_mb: Maximum file size in MB before rotation.\n        \"\"\"\n        self.path = Path(path)\n        self.rotation_size_bytes = rotation_size_mb * 1024 * 1024\n        self._entry_index: Dict[str, str] = {}  # entry_id -&gt; filename\n\n    def _get_current_filename(self) -&gt; str:\n        \"\"\"Get the current audit file name based on date.\"\"\"\n        date_str = datetime.utcnow().strftime(\"%Y%m%d\")\n        return f\"audit_{date_str}.jsonl\"\n\n    def _get_current_filepath(self) -&gt; Path:\n        \"\"\"Get the full path to the current audit file.\"\"\"\n        return self.path / self._get_current_filename()\n\n    async def _ensure_directory(self) -&gt; None:\n        \"\"\"Ensure the storage directory exists.\"\"\"\n        if not self.path.exists():\n            os.makedirs(self.path, exist_ok=True)\n\n    async def _should_rotate(self, filepath: Path) -&gt; bool:\n        \"\"\"Check if the file should be rotated based on size.\"\"\"\n        if not filepath.exists():\n            return False\n        try:\n            stat = await aiofiles.os.stat(filepath)\n            return stat.st_size &gt;= self.rotation_size_bytes\n        except FileNotFoundError:\n            return False\n\n    async def _rotate_file(self, filepath: Path) -&gt; None:\n        \"\"\"Rotate the file by adding a sequence number.\"\"\"\n        if not filepath.exists():\n            return\n\n        base = filepath.stem\n        suffix = filepath.suffix\n        counter = 1\n\n        while True:\n            new_name = f\"{base}_{counter:03d}{suffix}\"\n            new_path = self.path / new_name\n            if not new_path.exists():\n                os.rename(filepath, new_path)\n                break\n            counter += 1\n\n    async def write(self, entry: AuditEntry) -&gt; str:\n        \"\"\"\n        Write an audit entry to a JSONL file.\n\n        Auto-rotates the file if it exceeds the configured size limit.\n\n        Args:\n            entry: The audit entry to store.\n\n        Returns:\n            str: The entry ID.\n        \"\"\"\n        await self._ensure_directory()\n        filepath = self._get_current_filepath()\n\n        if await self._should_rotate(filepath):\n            await self._rotate_file(filepath)\n\n        entry_json = json.dumps(entry.to_dict())\n\n        async with aiofiles.open(filepath, \"a\", encoding=\"utf-8\") as f:\n            await f.write(entry_json + \"\\n\")\n\n        self._entry_index[entry.id] = str(filepath)\n        return entry.id\n\n    async def read(self, entry_id: str) -&gt; AuditEntry | None:\n        \"\"\"\n        Read an audit entry by ID.\n\n        Searches through all JSONL files if the entry is not in the index.\n\n        Args:\n            entry_id: The unique identifier of the entry.\n\n        Returns:\n            AuditEntry | None: The entry if found, None otherwise.\n        \"\"\"\n        await self._ensure_directory()\n\n        # Check index first\n        if entry_id in self._entry_index:\n            filepath = Path(self._entry_index[entry_id])\n            if filepath.exists():\n                async with aiofiles.open(filepath, \"r\", encoding=\"utf-8\") as f:\n                    async for line in f:\n                        line = line.strip()\n                        if line:\n                            data = json.loads(line)\n                            if data.get(\"id\") == entry_id:\n                                return AuditEntry.from_dict(data)\n\n        # Search all files\n        for filepath in sorted(self.path.glob(\"audit_*.jsonl\")):\n            async with aiofiles.open(filepath, \"r\", encoding=\"utf-8\") as f:\n                async for line in f:\n                    line = line.strip()\n                    if line:\n                        data = json.loads(line)\n                        if data.get(\"id\") == entry_id:\n                            self._entry_index[entry_id] = str(filepath)\n                            return AuditEntry.from_dict(data)\n\n        return None\n\n    async def list_entries(\n        self, start: datetime, end: datetime\n    ) -&gt; List[AuditEntry]:\n        \"\"\"\n        List all entries within a time range.\n\n        Args:\n            start: Start of the time range (inclusive).\n            end: End of the time range (inclusive).\n\n        Returns:\n            List[AuditEntry]: Entries within the specified time range.\n        \"\"\"\n        await self._ensure_directory()\n        entries: List[AuditEntry] = []\n\n        for filepath in sorted(self.path.glob(\"audit_*.jsonl\")):\n            async with aiofiles.open(filepath, \"r\", encoding=\"utf-8\") as f:\n                async for line in f:\n                    line = line.strip()\n                    if line:\n                        data = json.loads(line)\n                        timestamp = datetime.fromisoformat(data[\"timestamp\"])\n                        if start &lt;= timestamp &lt;= end:\n                            entries.append(AuditEntry.from_dict(data))\n\n        return entries\n\n    async def delete(self, entry_id: str) -&gt; bool:\n        \"\"\"\n        Delete an entry by ID.\n\n        Note: This rewrites the file without the deleted entry, which may be\n        slow for large files. Consider using retention policies instead.\n\n        Args:\n            entry_id: The unique identifier of the entry to delete.\n\n        Returns:\n            bool: True if the entry was deleted, False if not found.\n        \"\"\"\n        await self._ensure_directory()\n        deleted = False\n\n        for filepath in sorted(self.path.glob(\"audit_*.jsonl\")):\n            lines_to_keep: List[str] = []\n            found_in_file = False\n\n            async with aiofiles.open(filepath, \"r\", encoding=\"utf-8\") as f:\n                async for line in f:\n                    line = line.strip()\n                    if line:\n                        data = json.loads(line)\n                        if data.get(\"id\") == entry_id:\n                            found_in_file = True\n                            deleted = True\n                        else:\n                            lines_to_keep.append(line)\n\n            if found_in_file:\n                async with aiofiles.open(filepath, \"w\", encoding=\"utf-8\") as f:\n                    for line in lines_to_keep:\n                        await f.write(line + \"\\n\")\n\n                if entry_id in self._entry_index:\n                    del self._entry_index[entry_id]\n                break\n\n        return deleted\n\n    async def count(self) -&gt; int:\n        \"\"\"\n        Count total number of entries in storage.\n\n        Returns:\n            int: Total number of stored entries.\n        \"\"\"\n        await self._ensure_directory()\n        total = 0\n\n        for filepath in self.path.glob(\"audit_*.jsonl\"):\n            async with aiofiles.open(filepath, \"r\", encoding=\"utf-8\") as f:\n                async for line in f:\n                    if line.strip():\n                        total += 1\n\n        return total\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.FileStorage.__init__","title":"__init__","text":"<pre><code>__init__(path: str, rotation_size_mb: int = 100) -&gt; None\n</code></pre> <p>Initialize file storage.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Directory path for storing audit files.</p> required <code>rotation_size_mb</code> <code>int</code> <p>Maximum file size in MB before rotation.</p> <code>100</code> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>def __init__(self, path: str, rotation_size_mb: int = 100) -&gt; None:\n    \"\"\"\n    Initialize file storage.\n\n    Args:\n        path: Directory path for storing audit files.\n        rotation_size_mb: Maximum file size in MB before rotation.\n    \"\"\"\n    self.path = Path(path)\n    self.rotation_size_bytes = rotation_size_mb * 1024 * 1024\n    self._entry_index: Dict[str, str] = {}  # entry_id -&gt; filename\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.FileStorage.write","title":"write  <code>async</code>","text":"<pre><code>write(entry: AuditEntry) -&gt; str\n</code></pre> <p>Write an audit entry to a JSONL file.</p> <p>Auto-rotates the file if it exceeds the configured size limit.</p> <p>Parameters:</p> Name Type Description Default <code>entry</code> <code>AuditEntry</code> <p>The audit entry to store.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The entry ID.</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>async def write(self, entry: AuditEntry) -&gt; str:\n    \"\"\"\n    Write an audit entry to a JSONL file.\n\n    Auto-rotates the file if it exceeds the configured size limit.\n\n    Args:\n        entry: The audit entry to store.\n\n    Returns:\n        str: The entry ID.\n    \"\"\"\n    await self._ensure_directory()\n    filepath = self._get_current_filepath()\n\n    if await self._should_rotate(filepath):\n        await self._rotate_file(filepath)\n\n    entry_json = json.dumps(entry.to_dict())\n\n    async with aiofiles.open(filepath, \"a\", encoding=\"utf-8\") as f:\n        await f.write(entry_json + \"\\n\")\n\n    self._entry_index[entry.id] = str(filepath)\n    return entry.id\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.FileStorage.read","title":"read  <code>async</code>","text":"<pre><code>read(entry_id: str) -&gt; AuditEntry | None\n</code></pre> <p>Read an audit entry by ID.</p> <p>Searches through all JSONL files if the entry is not in the index.</p> <p>Parameters:</p> Name Type Description Default <code>entry_id</code> <code>str</code> <p>The unique identifier of the entry.</p> required <p>Returns:</p> Type Description <code>AuditEntry | None</code> <p>AuditEntry | None: The entry if found, None otherwise.</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>async def read(self, entry_id: str) -&gt; AuditEntry | None:\n    \"\"\"\n    Read an audit entry by ID.\n\n    Searches through all JSONL files if the entry is not in the index.\n\n    Args:\n        entry_id: The unique identifier of the entry.\n\n    Returns:\n        AuditEntry | None: The entry if found, None otherwise.\n    \"\"\"\n    await self._ensure_directory()\n\n    # Check index first\n    if entry_id in self._entry_index:\n        filepath = Path(self._entry_index[entry_id])\n        if filepath.exists():\n            async with aiofiles.open(filepath, \"r\", encoding=\"utf-8\") as f:\n                async for line in f:\n                    line = line.strip()\n                    if line:\n                        data = json.loads(line)\n                        if data.get(\"id\") == entry_id:\n                            return AuditEntry.from_dict(data)\n\n    # Search all files\n    for filepath in sorted(self.path.glob(\"audit_*.jsonl\")):\n        async with aiofiles.open(filepath, \"r\", encoding=\"utf-8\") as f:\n            async for line in f:\n                line = line.strip()\n                if line:\n                    data = json.loads(line)\n                    if data.get(\"id\") == entry_id:\n                        self._entry_index[entry_id] = str(filepath)\n                        return AuditEntry.from_dict(data)\n\n    return None\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.FileStorage.list_entries","title":"list_entries  <code>async</code>","text":"<pre><code>list_entries(\n    start: datetime, end: datetime\n) -&gt; List[AuditEntry]\n</code></pre> <p>List all entries within a time range.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>datetime</code> <p>Start of the time range (inclusive).</p> required <code>end</code> <code>datetime</code> <p>End of the time range (inclusive).</p> required <p>Returns:</p> Type Description <code>List[AuditEntry]</code> <p>List[AuditEntry]: Entries within the specified time range.</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>async def list_entries(\n    self, start: datetime, end: datetime\n) -&gt; List[AuditEntry]:\n    \"\"\"\n    List all entries within a time range.\n\n    Args:\n        start: Start of the time range (inclusive).\n        end: End of the time range (inclusive).\n\n    Returns:\n        List[AuditEntry]: Entries within the specified time range.\n    \"\"\"\n    await self._ensure_directory()\n    entries: List[AuditEntry] = []\n\n    for filepath in sorted(self.path.glob(\"audit_*.jsonl\")):\n        async with aiofiles.open(filepath, \"r\", encoding=\"utf-8\") as f:\n            async for line in f:\n                line = line.strip()\n                if line:\n                    data = json.loads(line)\n                    timestamp = datetime.fromisoformat(data[\"timestamp\"])\n                    if start &lt;= timestamp &lt;= end:\n                        entries.append(AuditEntry.from_dict(data))\n\n    return entries\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.FileStorage.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(entry_id: str) -&gt; bool\n</code></pre> <p>Delete an entry by ID.</p> <p>Note: This rewrites the file without the deleted entry, which may be slow for large files. Consider using retention policies instead.</p> <p>Parameters:</p> Name Type Description Default <code>entry_id</code> <code>str</code> <p>The unique identifier of the entry to delete.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the entry was deleted, False if not found.</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>async def delete(self, entry_id: str) -&gt; bool:\n    \"\"\"\n    Delete an entry by ID.\n\n    Note: This rewrites the file without the deleted entry, which may be\n    slow for large files. Consider using retention policies instead.\n\n    Args:\n        entry_id: The unique identifier of the entry to delete.\n\n    Returns:\n        bool: True if the entry was deleted, False if not found.\n    \"\"\"\n    await self._ensure_directory()\n    deleted = False\n\n    for filepath in sorted(self.path.glob(\"audit_*.jsonl\")):\n        lines_to_keep: List[str] = []\n        found_in_file = False\n\n        async with aiofiles.open(filepath, \"r\", encoding=\"utf-8\") as f:\n            async for line in f:\n                line = line.strip()\n                if line:\n                    data = json.loads(line)\n                    if data.get(\"id\") == entry_id:\n                        found_in_file = True\n                        deleted = True\n                    else:\n                        lines_to_keep.append(line)\n\n        if found_in_file:\n            async with aiofiles.open(filepath, \"w\", encoding=\"utf-8\") as f:\n                for line in lines_to_keep:\n                    await f.write(line + \"\\n\")\n\n            if entry_id in self._entry_index:\n                del self._entry_index[entry_id]\n            break\n\n    return deleted\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.FileStorage.count","title":"count  <code>async</code>","text":"<pre><code>count() -&gt; int\n</code></pre> <p>Count total number of entries in storage.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Total number of stored entries.</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>async def count(self) -&gt; int:\n    \"\"\"\n    Count total number of entries in storage.\n\n    Returns:\n        int: Total number of stored entries.\n    \"\"\"\n    await self._ensure_directory()\n    total = 0\n\n    for filepath in self.path.glob(\"audit_*.jsonl\"):\n        async with aiofiles.open(filepath, \"r\", encoding=\"utf-8\") as f:\n            async for line in f:\n                if line.strip():\n                    total += 1\n\n    return total\n</code></pre>"},{"location":"api/audit/#constructor_2","title":"Constructor","text":"<pre><code>FileStorage(path: str, rotation_size_mb: int = 100)\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>path</code> <code>str</code> Required Directory for audit files <code>rotation_size_mb</code> <code>int</code> <code>100</code> Max file size before rotation <p>File Structure:</p> <pre><code>{path}/\n\u251c\u2500\u2500 audit_20260128.jsonl\n\u251c\u2500\u2500 audit_20260128_001.jsonl  # Rotated\n\u251c\u2500\u2500 audit_20260129.jsonl\n\u2514\u2500\u2500 ...\n</code></pre> <p>Example:</p> <pre><code>from rotalabs_comply.audit import FileStorage\n\nstorage = FileStorage(\"/var/log/audit\", rotation_size_mb=50)\nentry_id = await storage.write(entry)\n</code></pre>"},{"location":"api/audit/#memorystorage","title":"MemoryStorage","text":"<p>In-memory storage backend for testing and development.</p>"},{"location":"api/audit/#rotalabs_comply.audit.storage.MemoryStorage","title":"MemoryStorage","text":"<p>In-memory storage backend for testing and development.</p> <p>Stores entries in a dictionary. Data is lost when the process ends.</p> <p>Parameters:</p> Name Type Description Default <code>max_entries</code> <code>int | None</code> <p>Optional maximum number of entries to store. When exceeded, oldest entries are removed.</p> <code>None</code> Example <p>storage = MemoryStorage(max_entries=1000) entry_id = await storage.write(entry) count = await storage.count()</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>class MemoryStorage:\n    \"\"\"\n    In-memory storage backend for testing and development.\n\n    Stores entries in a dictionary. Data is lost when the process ends.\n\n    Args:\n        max_entries: Optional maximum number of entries to store.\n            When exceeded, oldest entries are removed.\n\n    Example:\n        &gt;&gt;&gt; storage = MemoryStorage(max_entries=1000)\n        &gt;&gt;&gt; entry_id = await storage.write(entry)\n        &gt;&gt;&gt; count = await storage.count()\n    \"\"\"\n\n    def __init__(self, max_entries: int | None = None) -&gt; None:\n        \"\"\"\n        Initialize memory storage.\n\n        Args:\n            max_entries: Optional maximum number of entries to store.\n        \"\"\"\n        self.max_entries = max_entries\n        self._entries: Dict[str, AuditEntry] = {}\n        self._insertion_order: List[str] = []\n\n    async def write(self, entry: AuditEntry) -&gt; str:\n        \"\"\"\n        Write an audit entry to memory.\n\n        If max_entries is set and exceeded, removes the oldest entry.\n\n        Args:\n            entry: The audit entry to store.\n\n        Returns:\n            str: The entry ID.\n        \"\"\"\n        if (\n            self.max_entries\n            and len(self._entries) &gt;= self.max_entries\n            and entry.id not in self._entries\n        ):\n            # Remove oldest entry\n            oldest_id = self._insertion_order.pop(0)\n            del self._entries[oldest_id]\n\n        self._entries[entry.id] = entry\n        if entry.id not in self._insertion_order:\n            self._insertion_order.append(entry.id)\n\n        return entry.id\n\n    async def read(self, entry_id: str) -&gt; AuditEntry | None:\n        \"\"\"\n        Read an audit entry by ID.\n\n        Args:\n            entry_id: The unique identifier of the entry.\n\n        Returns:\n            AuditEntry | None: The entry if found, None otherwise.\n        \"\"\"\n        return self._entries.get(entry_id)\n\n    async def list_entries(\n        self, start: datetime, end: datetime\n    ) -&gt; List[AuditEntry]:\n        \"\"\"\n        List all entries within a time range.\n\n        Args:\n            start: Start of the time range (inclusive).\n            end: End of the time range (inclusive).\n\n        Returns:\n            List[AuditEntry]: Entries within the specified time range.\n        \"\"\"\n        entries: List[AuditEntry] = []\n        for entry in self._entries.values():\n            timestamp = datetime.fromisoformat(entry.timestamp)\n            if start &lt;= timestamp &lt;= end:\n                entries.append(entry)\n        return entries\n\n    async def delete(self, entry_id: str) -&gt; bool:\n        \"\"\"\n        Delete an entry by ID.\n\n        Args:\n            entry_id: The unique identifier of the entry to delete.\n\n        Returns:\n            bool: True if the entry was deleted, False if not found.\n        \"\"\"\n        if entry_id in self._entries:\n            del self._entries[entry_id]\n            self._insertion_order.remove(entry_id)\n            return True\n        return False\n\n    async def count(self) -&gt; int:\n        \"\"\"\n        Count total number of entries in storage.\n\n        Returns:\n            int: Total number of stored entries.\n        \"\"\"\n        return len(self._entries)\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.MemoryStorage.__init__","title":"__init__","text":"<pre><code>__init__(max_entries: int | None = None) -&gt; None\n</code></pre> <p>Initialize memory storage.</p> <p>Parameters:</p> Name Type Description Default <code>max_entries</code> <code>int | None</code> <p>Optional maximum number of entries to store.</p> <code>None</code> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>def __init__(self, max_entries: int | None = None) -&gt; None:\n    \"\"\"\n    Initialize memory storage.\n\n    Args:\n        max_entries: Optional maximum number of entries to store.\n    \"\"\"\n    self.max_entries = max_entries\n    self._entries: Dict[str, AuditEntry] = {}\n    self._insertion_order: List[str] = []\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.MemoryStorage.write","title":"write  <code>async</code>","text":"<pre><code>write(entry: AuditEntry) -&gt; str\n</code></pre> <p>Write an audit entry to memory.</p> <p>If max_entries is set and exceeded, removes the oldest entry.</p> <p>Parameters:</p> Name Type Description Default <code>entry</code> <code>AuditEntry</code> <p>The audit entry to store.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The entry ID.</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>async def write(self, entry: AuditEntry) -&gt; str:\n    \"\"\"\n    Write an audit entry to memory.\n\n    If max_entries is set and exceeded, removes the oldest entry.\n\n    Args:\n        entry: The audit entry to store.\n\n    Returns:\n        str: The entry ID.\n    \"\"\"\n    if (\n        self.max_entries\n        and len(self._entries) &gt;= self.max_entries\n        and entry.id not in self._entries\n    ):\n        # Remove oldest entry\n        oldest_id = self._insertion_order.pop(0)\n        del self._entries[oldest_id]\n\n    self._entries[entry.id] = entry\n    if entry.id not in self._insertion_order:\n        self._insertion_order.append(entry.id)\n\n    return entry.id\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.MemoryStorage.read","title":"read  <code>async</code>","text":"<pre><code>read(entry_id: str) -&gt; AuditEntry | None\n</code></pre> <p>Read an audit entry by ID.</p> <p>Parameters:</p> Name Type Description Default <code>entry_id</code> <code>str</code> <p>The unique identifier of the entry.</p> required <p>Returns:</p> Type Description <code>AuditEntry | None</code> <p>AuditEntry | None: The entry if found, None otherwise.</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>async def read(self, entry_id: str) -&gt; AuditEntry | None:\n    \"\"\"\n    Read an audit entry by ID.\n\n    Args:\n        entry_id: The unique identifier of the entry.\n\n    Returns:\n        AuditEntry | None: The entry if found, None otherwise.\n    \"\"\"\n    return self._entries.get(entry_id)\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.MemoryStorage.list_entries","title":"list_entries  <code>async</code>","text":"<pre><code>list_entries(\n    start: datetime, end: datetime\n) -&gt; List[AuditEntry]\n</code></pre> <p>List all entries within a time range.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>datetime</code> <p>Start of the time range (inclusive).</p> required <code>end</code> <code>datetime</code> <p>End of the time range (inclusive).</p> required <p>Returns:</p> Type Description <code>List[AuditEntry]</code> <p>List[AuditEntry]: Entries within the specified time range.</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>async def list_entries(\n    self, start: datetime, end: datetime\n) -&gt; List[AuditEntry]:\n    \"\"\"\n    List all entries within a time range.\n\n    Args:\n        start: Start of the time range (inclusive).\n        end: End of the time range (inclusive).\n\n    Returns:\n        List[AuditEntry]: Entries within the specified time range.\n    \"\"\"\n    entries: List[AuditEntry] = []\n    for entry in self._entries.values():\n        timestamp = datetime.fromisoformat(entry.timestamp)\n        if start &lt;= timestamp &lt;= end:\n            entries.append(entry)\n    return entries\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.MemoryStorage.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(entry_id: str) -&gt; bool\n</code></pre> <p>Delete an entry by ID.</p> <p>Parameters:</p> Name Type Description Default <code>entry_id</code> <code>str</code> <p>The unique identifier of the entry to delete.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the entry was deleted, False if not found.</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>async def delete(self, entry_id: str) -&gt; bool:\n    \"\"\"\n    Delete an entry by ID.\n\n    Args:\n        entry_id: The unique identifier of the entry to delete.\n\n    Returns:\n        bool: True if the entry was deleted, False if not found.\n    \"\"\"\n    if entry_id in self._entries:\n        del self._entries[entry_id]\n        self._insertion_order.remove(entry_id)\n        return True\n    return False\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.MemoryStorage.count","title":"count  <code>async</code>","text":"<pre><code>count() -&gt; int\n</code></pre> <p>Count total number of entries in storage.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Total number of stored entries.</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>async def count(self) -&gt; int:\n    \"\"\"\n    Count total number of entries in storage.\n\n    Returns:\n        int: Total number of stored entries.\n    \"\"\"\n    return len(self._entries)\n</code></pre>"},{"location":"api/audit/#constructor_3","title":"Constructor","text":"<pre><code>MemoryStorage(max_entries: Optional[int] = None)\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>max_entries</code> <code>Optional[int]</code> <code>None</code> Max entries (LRU eviction) <p>Example:</p> <pre><code>from rotalabs_comply.audit import MemoryStorage\n\nstorage = MemoryStorage(max_entries=1000)\ncount = await storage.count()\n</code></pre> <p>Data Persistence</p> <p>Data is lost when the process ends. Use only for testing.</p>"},{"location":"api/audit/#s3storage","title":"S3Storage","text":"<p>AWS S3 storage backend for audit logs.</p>"},{"location":"api/audit/#rotalabs_comply.audit.storage.S3Storage","title":"S3Storage","text":"<p>AWS S3 storage backend for audit logs.</p> <p>Stores each audit entry as a separate JSON file in S3, organized by date for easy querying and lifecycle management.</p> <p>Requires boto3 to be installed (optional dependency).</p> <p>Parameters:</p> Name Type Description Default <code>bucket</code> <code>str</code> <p>S3 bucket name.</p> required <code>prefix</code> <code>str</code> <p>Key prefix for audit files (default: \"audit/\").</p> <code>'audit/'</code> <code>region</code> <code>str | None</code> <p>AWS region (optional, uses default if not specified).</p> <code>None</code> File structure <p>{prefix}{YYYY-MM-DD}/{entry_id}.json</p> Example <p>storage = S3Storage(\"my-audit-bucket\", prefix=\"logs/audit/\") entry_id = await storage.write(entry)</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>class S3Storage:\n    \"\"\"\n    AWS S3 storage backend for audit logs.\n\n    Stores each audit entry as a separate JSON file in S3, organized\n    by date for easy querying and lifecycle management.\n\n    Requires boto3 to be installed (optional dependency).\n\n    Args:\n        bucket: S3 bucket name.\n        prefix: Key prefix for audit files (default: \"audit/\").\n        region: AWS region (optional, uses default if not specified).\n\n    File structure:\n        {prefix}{YYYY-MM-DD}/{entry_id}.json\n\n    Example:\n        &gt;&gt;&gt; storage = S3Storage(\"my-audit-bucket\", prefix=\"logs/audit/\")\n        &gt;&gt;&gt; entry_id = await storage.write(entry)\n        # Stored at: s3://my-audit-bucket/logs/audit/2024-01-15/abc123.json\n    \"\"\"\n\n    def __init__(\n        self,\n        bucket: str,\n        prefix: str = \"audit/\",\n        region: str | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize S3 storage.\n\n        Args:\n            bucket: S3 bucket name.\n            prefix: Key prefix for audit files.\n            region: AWS region (optional).\n        \"\"\"\n        self.bucket = bucket\n        self.prefix = prefix.rstrip(\"/\") + \"/\" if prefix else \"\"\n        self.region = region\n        self._client = None\n\n    def _get_client(self):\n        \"\"\"Lazy-load boto3 client.\"\"\"\n        if self._client is None:\n            try:\n                import boto3\n            except ImportError:\n                raise ImportError(\n                    \"boto3 is required for S3Storage. \"\n                    \"Install it with: pip install boto3\"\n                )\n\n            if self.region:\n                self._client = boto3.client(\"s3\", region_name=self.region)\n            else:\n                self._client = boto3.client(\"s3\")\n        return self._client\n\n    def _get_key(self, entry: AuditEntry) -&gt; str:\n        \"\"\"Get the S3 key for an entry.\"\"\"\n        timestamp = datetime.fromisoformat(entry.timestamp)\n        date_str = timestamp.strftime(\"%Y-%m-%d\")\n        return f\"{self.prefix}{date_str}/{entry.id}.json\"\n\n    def _get_key_from_id(self, entry_id: str, date_str: str) -&gt; str:\n        \"\"\"Get the S3 key from entry ID and date.\"\"\"\n        return f\"{self.prefix}{date_str}/{entry_id}.json\"\n\n    async def write(self, entry: AuditEntry) -&gt; str:\n        \"\"\"\n        Write an audit entry to S3.\n\n        Args:\n            entry: The audit entry to store.\n\n        Returns:\n            str: The entry ID.\n        \"\"\"\n        client = self._get_client()\n        key = self._get_key(entry)\n        body = json.dumps(entry.to_dict())\n\n        client.put_object(\n            Bucket=self.bucket,\n            Key=key,\n            Body=body.encode(\"utf-8\"),\n            ContentType=\"application/json\",\n        )\n\n        return entry.id\n\n    async def read(self, entry_id: str) -&gt; AuditEntry | None:\n        \"\"\"\n        Read an audit entry by ID.\n\n        Note: This searches through date prefixes which may be slow.\n        Consider maintaining an index for production use.\n\n        Args:\n            entry_id: The unique identifier of the entry.\n\n        Returns:\n            AuditEntry | None: The entry if found, None otherwise.\n        \"\"\"\n        client = self._get_client()\n\n        # List all date prefixes\n        paginator = client.get_paginator(\"list_objects_v2\")\n\n        for page in paginator.paginate(\n            Bucket=self.bucket, Prefix=self.prefix, Delimiter=\"/\"\n        ):\n            for prefix_info in page.get(\"CommonPrefixes\", []):\n                date_prefix = prefix_info[\"Prefix\"]\n                key = f\"{date_prefix}{entry_id}.json\"\n\n                try:\n                    response = client.get_object(Bucket=self.bucket, Key=key)\n                    body = response[\"Body\"].read().decode(\"utf-8\")\n                    data = json.loads(body)\n                    return AuditEntry.from_dict(data)\n                except client.exceptions.NoSuchKey:\n                    continue\n\n        return None\n\n    async def list_entries(\n        self, start: datetime, end: datetime\n    ) -&gt; List[AuditEntry]:\n        \"\"\"\n        List all entries within a time range.\n\n        Args:\n            start: Start of the time range (inclusive).\n            end: End of the time range (inclusive).\n\n        Returns:\n            List[AuditEntry]: Entries within the specified time range.\n        \"\"\"\n        client = self._get_client()\n        entries: List[AuditEntry] = []\n\n        # Generate date range\n        current_date = start.date()\n        end_date = end.date()\n\n        while current_date &lt;= end_date:\n            date_str = current_date.strftime(\"%Y-%m-%d\")\n            date_prefix = f\"{self.prefix}{date_str}/\"\n\n            paginator = client.get_paginator(\"list_objects_v2\")\n\n            for page in paginator.paginate(\n                Bucket=self.bucket, Prefix=date_prefix\n            ):\n                for obj in page.get(\"Contents\", []):\n                    response = client.get_object(\n                        Bucket=self.bucket, Key=obj[\"Key\"]\n                    )\n                    body = response[\"Body\"].read().decode(\"utf-8\")\n                    data = json.loads(body)\n                    entry = AuditEntry.from_dict(data)\n\n                    timestamp = datetime.fromisoformat(entry.timestamp)\n                    if start &lt;= timestamp &lt;= end:\n                        entries.append(entry)\n\n            current_date = current_date.replace(\n                day=current_date.day + 1\n            ) if current_date.day &lt; 28 else (\n                current_date.replace(month=current_date.month + 1, day=1)\n                if current_date.month &lt; 12\n                else current_date.replace(year=current_date.year + 1, month=1, day=1)\n            )\n\n        return entries\n\n    async def delete(self, entry_id: str) -&gt; bool:\n        \"\"\"\n        Delete an entry by ID.\n\n        Args:\n            entry_id: The unique identifier of the entry to delete.\n\n        Returns:\n            bool: True if the entry was deleted, False if not found.\n        \"\"\"\n        client = self._get_client()\n\n        # Find the entry first\n        paginator = client.get_paginator(\"list_objects_v2\")\n\n        for page in paginator.paginate(\n            Bucket=self.bucket, Prefix=self.prefix, Delimiter=\"/\"\n        ):\n            for prefix_info in page.get(\"CommonPrefixes\", []):\n                date_prefix = prefix_info[\"Prefix\"]\n                key = f\"{date_prefix}{entry_id}.json\"\n\n                try:\n                    client.head_object(Bucket=self.bucket, Key=key)\n                    client.delete_object(Bucket=self.bucket, Key=key)\n                    return True\n                except client.exceptions.ClientError:\n                    continue\n\n        return False\n\n    async def count(self) -&gt; int:\n        \"\"\"\n        Count total number of entries in storage.\n\n        Returns:\n            int: Total number of stored entries.\n        \"\"\"\n        client = self._get_client()\n        total = 0\n\n        paginator = client.get_paginator(\"list_objects_v2\")\n\n        for page in paginator.paginate(Bucket=self.bucket, Prefix=self.prefix):\n            for obj in page.get(\"Contents\", []):\n                if obj[\"Key\"].endswith(\".json\"):\n                    total += 1\n\n        return total\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.S3Storage--stored-at-s3my-audit-bucketlogsaudit2024-01-15abc123json","title":"Stored at: s3://my-audit-bucket/logs/audit/2024-01-15/abc123.json","text":""},{"location":"api/audit/#rotalabs_comply.audit.storage.S3Storage.__init__","title":"__init__","text":"<pre><code>__init__(\n    bucket: str,\n    prefix: str = \"audit/\",\n    region: str | None = None,\n) -&gt; None\n</code></pre> <p>Initialize S3 storage.</p> <p>Parameters:</p> Name Type Description Default <code>bucket</code> <code>str</code> <p>S3 bucket name.</p> required <code>prefix</code> <code>str</code> <p>Key prefix for audit files.</p> <code>'audit/'</code> <code>region</code> <code>str | None</code> <p>AWS region (optional).</p> <code>None</code> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>def __init__(\n    self,\n    bucket: str,\n    prefix: str = \"audit/\",\n    region: str | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize S3 storage.\n\n    Args:\n        bucket: S3 bucket name.\n        prefix: Key prefix for audit files.\n        region: AWS region (optional).\n    \"\"\"\n    self.bucket = bucket\n    self.prefix = prefix.rstrip(\"/\") + \"/\" if prefix else \"\"\n    self.region = region\n    self._client = None\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.S3Storage.write","title":"write  <code>async</code>","text":"<pre><code>write(entry: AuditEntry) -&gt; str\n</code></pre> <p>Write an audit entry to S3.</p> <p>Parameters:</p> Name Type Description Default <code>entry</code> <code>AuditEntry</code> <p>The audit entry to store.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The entry ID.</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>async def write(self, entry: AuditEntry) -&gt; str:\n    \"\"\"\n    Write an audit entry to S3.\n\n    Args:\n        entry: The audit entry to store.\n\n    Returns:\n        str: The entry ID.\n    \"\"\"\n    client = self._get_client()\n    key = self._get_key(entry)\n    body = json.dumps(entry.to_dict())\n\n    client.put_object(\n        Bucket=self.bucket,\n        Key=key,\n        Body=body.encode(\"utf-8\"),\n        ContentType=\"application/json\",\n    )\n\n    return entry.id\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.S3Storage.read","title":"read  <code>async</code>","text":"<pre><code>read(entry_id: str) -&gt; AuditEntry | None\n</code></pre> <p>Read an audit entry by ID.</p> <p>Note: This searches through date prefixes which may be slow. Consider maintaining an index for production use.</p> <p>Parameters:</p> Name Type Description Default <code>entry_id</code> <code>str</code> <p>The unique identifier of the entry.</p> required <p>Returns:</p> Type Description <code>AuditEntry | None</code> <p>AuditEntry | None: The entry if found, None otherwise.</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>async def read(self, entry_id: str) -&gt; AuditEntry | None:\n    \"\"\"\n    Read an audit entry by ID.\n\n    Note: This searches through date prefixes which may be slow.\n    Consider maintaining an index for production use.\n\n    Args:\n        entry_id: The unique identifier of the entry.\n\n    Returns:\n        AuditEntry | None: The entry if found, None otherwise.\n    \"\"\"\n    client = self._get_client()\n\n    # List all date prefixes\n    paginator = client.get_paginator(\"list_objects_v2\")\n\n    for page in paginator.paginate(\n        Bucket=self.bucket, Prefix=self.prefix, Delimiter=\"/\"\n    ):\n        for prefix_info in page.get(\"CommonPrefixes\", []):\n            date_prefix = prefix_info[\"Prefix\"]\n            key = f\"{date_prefix}{entry_id}.json\"\n\n            try:\n                response = client.get_object(Bucket=self.bucket, Key=key)\n                body = response[\"Body\"].read().decode(\"utf-8\")\n                data = json.loads(body)\n                return AuditEntry.from_dict(data)\n            except client.exceptions.NoSuchKey:\n                continue\n\n    return None\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.S3Storage.list_entries","title":"list_entries  <code>async</code>","text":"<pre><code>list_entries(\n    start: datetime, end: datetime\n) -&gt; List[AuditEntry]\n</code></pre> <p>List all entries within a time range.</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>datetime</code> <p>Start of the time range (inclusive).</p> required <code>end</code> <code>datetime</code> <p>End of the time range (inclusive).</p> required <p>Returns:</p> Type Description <code>List[AuditEntry]</code> <p>List[AuditEntry]: Entries within the specified time range.</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>async def list_entries(\n    self, start: datetime, end: datetime\n) -&gt; List[AuditEntry]:\n    \"\"\"\n    List all entries within a time range.\n\n    Args:\n        start: Start of the time range (inclusive).\n        end: End of the time range (inclusive).\n\n    Returns:\n        List[AuditEntry]: Entries within the specified time range.\n    \"\"\"\n    client = self._get_client()\n    entries: List[AuditEntry] = []\n\n    # Generate date range\n    current_date = start.date()\n    end_date = end.date()\n\n    while current_date &lt;= end_date:\n        date_str = current_date.strftime(\"%Y-%m-%d\")\n        date_prefix = f\"{self.prefix}{date_str}/\"\n\n        paginator = client.get_paginator(\"list_objects_v2\")\n\n        for page in paginator.paginate(\n            Bucket=self.bucket, Prefix=date_prefix\n        ):\n            for obj in page.get(\"Contents\", []):\n                response = client.get_object(\n                    Bucket=self.bucket, Key=obj[\"Key\"]\n                )\n                body = response[\"Body\"].read().decode(\"utf-8\")\n                data = json.loads(body)\n                entry = AuditEntry.from_dict(data)\n\n                timestamp = datetime.fromisoformat(entry.timestamp)\n                if start &lt;= timestamp &lt;= end:\n                    entries.append(entry)\n\n        current_date = current_date.replace(\n            day=current_date.day + 1\n        ) if current_date.day &lt; 28 else (\n            current_date.replace(month=current_date.month + 1, day=1)\n            if current_date.month &lt; 12\n            else current_date.replace(year=current_date.year + 1, month=1, day=1)\n        )\n\n    return entries\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.S3Storage.delete","title":"delete  <code>async</code>","text":"<pre><code>delete(entry_id: str) -&gt; bool\n</code></pre> <p>Delete an entry by ID.</p> <p>Parameters:</p> Name Type Description Default <code>entry_id</code> <code>str</code> <p>The unique identifier of the entry to delete.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the entry was deleted, False if not found.</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>async def delete(self, entry_id: str) -&gt; bool:\n    \"\"\"\n    Delete an entry by ID.\n\n    Args:\n        entry_id: The unique identifier of the entry to delete.\n\n    Returns:\n        bool: True if the entry was deleted, False if not found.\n    \"\"\"\n    client = self._get_client()\n\n    # Find the entry first\n    paginator = client.get_paginator(\"list_objects_v2\")\n\n    for page in paginator.paginate(\n        Bucket=self.bucket, Prefix=self.prefix, Delimiter=\"/\"\n    ):\n        for prefix_info in page.get(\"CommonPrefixes\", []):\n            date_prefix = prefix_info[\"Prefix\"]\n            key = f\"{date_prefix}{entry_id}.json\"\n\n            try:\n                client.head_object(Bucket=self.bucket, Key=key)\n                client.delete_object(Bucket=self.bucket, Key=key)\n                return True\n            except client.exceptions.ClientError:\n                continue\n\n    return False\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.S3Storage.count","title":"count  <code>async</code>","text":"<pre><code>count() -&gt; int\n</code></pre> <p>Count total number of entries in storage.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Total number of stored entries.</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>async def count(self) -&gt; int:\n    \"\"\"\n    Count total number of entries in storage.\n\n    Returns:\n        int: Total number of stored entries.\n    \"\"\"\n    client = self._get_client()\n    total = 0\n\n    paginator = client.get_paginator(\"list_objects_v2\")\n\n    for page in paginator.paginate(Bucket=self.bucket, Prefix=self.prefix):\n        for obj in page.get(\"Contents\", []):\n            if obj[\"Key\"].endswith(\".json\"):\n                total += 1\n\n    return total\n</code></pre>"},{"location":"api/audit/#constructor_4","title":"Constructor","text":"<pre><code>S3Storage(\n    bucket: str,\n    prefix: str = \"audit/\",\n    region: Optional[str] = None,\n)\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>bucket</code> <code>str</code> Required S3 bucket name <code>prefix</code> <code>str</code> <code>\"audit/\"</code> Key prefix for files <code>region</code> <code>Optional[str]</code> <code>None</code> AWS region <p>Key Structure:</p> <pre><code>s3://{bucket}/{prefix}{YYYY-MM-DD}/{entry_id}.json\n</code></pre> <p>Example:</p> <pre><code>from rotalabs_comply.audit import S3Storage\n\nstorage = S3Storage(\n    bucket=\"my-audit-bucket\",\n    prefix=\"prod/audit/\",\n    region=\"us-west-2\",\n)\n</code></pre> <p>Dependency</p> <p>Requires <code>boto3</code>. Install with <code>pip install rotalabs-comply[s3]</code>.</p>"},{"location":"api/audit/#auditentry-storage","title":"AuditEntry (Storage)","text":"<p>Dataclass representing a single audit log entry in storage.</p> <p>Attributes:</p> Attribute Type Description <code>id</code> <code>str</code> Unique identifier <code>timestamp</code> <code>str</code> ISO format timestamp <code>input_hash</code> <code>str</code> SHA-256 of input <code>output_hash</code> <code>str</code> SHA-256 of output <code>input_content</code> <code>Optional[str]</code> Input content (if stored) <code>output_content</code> <code>Optional[str]</code> Output content (if stored) <code>provider</code> <code>Optional[str]</code> AI provider <code>model</code> <code>Optional[str]</code> Model identifier <code>conversation_id</code> <code>Optional[str]</code> Conversation ID <code>safety_passed</code> <code>bool</code> Safety check result <code>detectors_triggered</code> <code>List[str]</code> Triggered detectors <code>block_reason</code> <code>Optional[str]</code> Block reason <code>alerts</code> <code>List[str]</code> Alert messages <code>latency_ms</code> <code>float</code> Response latency <code>input_tokens</code> <code>Optional[int]</code> Input token count <code>output_tokens</code> <code>Optional[int]</code> Output token count <code>metadata</code> <code>Dict[str, Any]</code> Custom metadata <p>Methods:</p> Method Description <code>to_dict()</code> Convert to dictionary <code>from_dict(data)</code> Create from dictionary"},{"location":"api/audit/#rotalabs_comply.audit.storage.AuditEntry","title":"AuditEntry  <code>dataclass</code>","text":"<p>Represents a single audit log entry.</p> <p>Captures all relevant information about an AI interaction including inputs, outputs, safety evaluations, and performance metrics.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Unique identifier for this entry.</p> <code>timestamp</code> <code>str</code> <p>When the interaction occurred (ISO format).</p> <code>input_hash</code> <code>str</code> <p>SHA-256 hash of the input content.</p> <code>output_hash</code> <code>str</code> <p>SHA-256 hash of the output content.</p> <code>input_content</code> <code>str | None</code> <p>Actual input content (if store_content=True, may be encrypted).</p> <code>output_content</code> <code>str | None</code> <p>Actual output content (if store_content=True, may be encrypted).</p> <code>provider</code> <code>str | None</code> <p>The AI provider (e.g., \"openai\", \"anthropic\").</p> <code>model</code> <code>str | None</code> <p>The model identifier (e.g., \"gpt-4\", \"claude-3-opus\").</p> <code>conversation_id</code> <code>str | None</code> <p>Optional ID linking related interactions.</p> <code>safety_passed</code> <code>bool</code> <p>Whether the interaction passed all safety checks.</p> <code>detectors_triggered</code> <code>List[str]</code> <p>List of safety detector names that triggered.</p> <code>block_reason</code> <code>str | None</code> <p>Reason for blocking, if the request was blocked.</p> <code>alerts</code> <code>List[str]</code> <p>List of alert messages generated.</p> <code>latency_ms</code> <code>float</code> <p>Time taken to process the request in milliseconds.</p> <code>input_tokens</code> <code>int | None</code> <p>Number of tokens in the input.</p> <code>output_tokens</code> <code>int | None</code> <p>Number of tokens in the output.</p> <code>metadata</code> <code>Dict[str, Any]</code> <p>Additional custom metadata.</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>@dataclass\nclass AuditEntry:\n    \"\"\"\n    Represents a single audit log entry.\n\n    Captures all relevant information about an AI interaction including\n    inputs, outputs, safety evaluations, and performance metrics.\n\n    Attributes:\n        id: Unique identifier for this entry.\n        timestamp: When the interaction occurred (ISO format).\n        input_hash: SHA-256 hash of the input content.\n        output_hash: SHA-256 hash of the output content.\n        input_content: Actual input content (if store_content=True, may be encrypted).\n        output_content: Actual output content (if store_content=True, may be encrypted).\n        provider: The AI provider (e.g., \"openai\", \"anthropic\").\n        model: The model identifier (e.g., \"gpt-4\", \"claude-3-opus\").\n        conversation_id: Optional ID linking related interactions.\n        safety_passed: Whether the interaction passed all safety checks.\n        detectors_triggered: List of safety detector names that triggered.\n        block_reason: Reason for blocking, if the request was blocked.\n        alerts: List of alert messages generated.\n        latency_ms: Time taken to process the request in milliseconds.\n        input_tokens: Number of tokens in the input.\n        output_tokens: Number of tokens in the output.\n        metadata: Additional custom metadata.\n    \"\"\"\n\n    id: str\n    timestamp: str\n    input_hash: str\n    output_hash: str\n    input_content: str | None = None\n    output_content: str | None = None\n    provider: str | None = None\n    model: str | None = None\n    conversation_id: str | None = None\n    safety_passed: bool = True\n    detectors_triggered: List[str] = field(default_factory=list)\n    block_reason: str | None = None\n    alerts: List[str] = field(default_factory=list)\n    latency_ms: float = 0.0\n    input_tokens: int | None = None\n    output_tokens: int | None = None\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n    def to_dict(self) -&gt; Dict[str, Any]:\n        \"\"\"Convert entry to dictionary for serialization.\"\"\"\n        return asdict(self)\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -&gt; \"AuditEntry\":\n        \"\"\"Create entry from dictionary.\"\"\"\n        return cls(**data)\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.AuditEntry.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert entry to dictionary for serialization.</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>def to_dict(self) -&gt; Dict[str, Any]:\n    \"\"\"Convert entry to dictionary for serialization.\"\"\"\n    return asdict(self)\n</code></pre>"},{"location":"api/audit/#rotalabs_comply.audit.storage.AuditEntry.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data: Dict[str, Any]) -&gt; 'AuditEntry'\n</code></pre> <p>Create entry from dictionary.</p> Source code in <code>src/rotalabs_comply/audit/storage.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: Dict[str, Any]) -&gt; \"AuditEntry\":\n    \"\"\"Create entry from dictionary.\"\"\"\n    return cls(**data)\n</code></pre>"},{"location":"api/audit/#helper-functions_1","title":"Helper Functions","text":""},{"location":"api/audit/#create_entry_id","title":"create_entry_id","text":"<pre><code>def create_entry_id() -&gt; str\n</code></pre> <p>Generate a unique entry ID (UUID v4).</p> <p>Example:</p> <pre><code>from rotalabs_comply.audit.storage import create_entry_id\n\nentry_id = create_entry_id()\n# Returns: \"550e8400-e29b-41d4-a716-446655440000\"\n</code></pre>"},{"location":"api/core/","title":"Core Types","text":"<p>Core data models, enumerations, configuration classes, and exceptions for rotalabs-comply.</p>"},{"location":"api/core/#enumerations","title":"Enumerations","text":""},{"location":"api/core/#risklevel","title":"RiskLevel","text":"<p>Risk severity levels for compliance classification.</p> Level Value Description <code>LOW</code> <code>\"low\"</code> Minor risk with minimal compliance impact <code>MEDIUM</code> <code>\"medium\"</code> Moderate risk requiring attention <code>HIGH</code> <code>\"high\"</code> Significant risk requiring immediate action <code>CRITICAL</code> <code>\"critical\"</code> Severe risk with potential regulatory consequences <p>Example:</p> <pre><code>from rotalabs_comply import RiskLevel\n\nlevel = RiskLevel.HIGH\nprint(level.value)  # \"high\"\n</code></pre>"},{"location":"api/core/#rotalabs_comply.core.types.RiskLevel","title":"RiskLevel","text":"<p>Risk severity levels for compliance classification.</p> <p>These levels are used to categorize the severity of compliance violations and to set risk thresholds for AI systems.</p> <p>Attributes:</p> Name Type Description <code>LOW</code> <p>Minor risk with minimal compliance impact.</p> <code>MEDIUM</code> <p>Moderate risk requiring attention.</p> <code>HIGH</code> <p>Significant risk requiring immediate action.</p> <code>CRITICAL</code> <p>Severe risk with potential regulatory consequences.</p> Source code in <code>src/rotalabs_comply/core/types.py</code> <pre><code>class RiskLevel(str, Enum):\n    \"\"\"\n    Risk severity levels for compliance classification.\n\n    These levels are used to categorize the severity of compliance\n    violations and to set risk thresholds for AI systems.\n\n    Attributes:\n        LOW: Minor risk with minimal compliance impact.\n        MEDIUM: Moderate risk requiring attention.\n        HIGH: Significant risk requiring immediate action.\n        CRITICAL: Severe risk with potential regulatory consequences.\n    \"\"\"\n\n    LOW = \"low\"\n    MEDIUM = \"medium\"\n    HIGH = \"high\"\n    CRITICAL = \"critical\"\n</code></pre>"},{"location":"api/core/#rotalabs_comply.core.types.RiskLevel.LOW","title":"LOW  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>LOW = 'low'\n</code></pre>"},{"location":"api/core/#rotalabs_comply.core.types.RiskLevel.MEDIUM","title":"MEDIUM  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MEDIUM = 'medium'\n</code></pre>"},{"location":"api/core/#rotalabs_comply.core.types.RiskLevel.HIGH","title":"HIGH  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>HIGH = 'high'\n</code></pre>"},{"location":"api/core/#rotalabs_comply.core.types.RiskLevel.CRITICAL","title":"CRITICAL  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>CRITICAL = 'critical'\n</code></pre>"},{"location":"api/core/#framework","title":"Framework","text":"<p>Supported regulatory compliance frameworks.</p> Framework Value Description <code>EU_AI_ACT</code> <code>\"eu_ai_act\"</code> European Union AI Act requirements <code>SOC2</code> <code>\"soc2\"</code> Service Organization Control 2 standards <code>HIPAA</code> <code>\"hipaa\"</code> Health Insurance Portability and Accountability Act <code>GDPR</code> <code>\"gdpr\"</code> General Data Protection Regulation <code>NIST_AI_RMF</code> <code>\"nist_ai_rmf\"</code> NIST AI Risk Management Framework <code>ISO_42001</code> <code>\"iso_42001\"</code> ISO/IEC 42001 AI Management System <p>Example:</p> <pre><code>from rotalabs_comply import Framework\n\nframeworks = [Framework.EU_AI_ACT, Framework.HIPAA]\n</code></pre>"},{"location":"api/core/#rotalabs_comply.core.types.Framework","title":"Framework","text":"<p>Supported regulatory compliance frameworks.</p> <p>Each framework represents a set of compliance requirements that can be validated against AI system operations.</p> <p>Attributes:</p> Name Type Description <code>EU_AI_ACT</code> <p>European Union AI Act requirements.</p> <code>SOC2</code> <p>Service Organization Control 2 security standards.</p> <code>HIPAA</code> <p>Health Insurance Portability and Accountability Act.</p> <code>GDPR</code> <p>General Data Protection Regulation.</p> <code>NIST_AI_RMF</code> <p>NIST AI Risk Management Framework.</p> <code>ISO_42001</code> <p>ISO/IEC 42001 AI Management System standard.</p> <code>MAS</code> <p>Monetary Authority of Singapore FEAT principles.</p> Source code in <code>src/rotalabs_comply/core/types.py</code> <pre><code>class Framework(str, Enum):\n    \"\"\"\n    Supported regulatory compliance frameworks.\n\n    Each framework represents a set of compliance requirements\n    that can be validated against AI system operations.\n\n    Attributes:\n        EU_AI_ACT: European Union AI Act requirements.\n        SOC2: Service Organization Control 2 security standards.\n        HIPAA: Health Insurance Portability and Accountability Act.\n        GDPR: General Data Protection Regulation.\n        NIST_AI_RMF: NIST AI Risk Management Framework.\n        ISO_42001: ISO/IEC 42001 AI Management System standard.\n        MAS: Monetary Authority of Singapore FEAT principles.\n    \"\"\"\n\n    EU_AI_ACT = \"eu_ai_act\"\n    SOC2 = \"soc2\"\n    HIPAA = \"hipaa\"\n    GDPR = \"gdpr\"\n    NIST_AI_RMF = \"nist_ai_rmf\"\n    ISO_42001 = \"iso_42001\"\n    MAS = \"mas\"\n</code></pre>"},{"location":"api/core/#data-models","title":"Data Models","text":""},{"location":"api/core/#auditentry","title":"AuditEntry","text":"<p>A single audit log entry capturing an AI system interaction.</p> <p>Attributes:</p> Attribute Type Description <code>id</code> <code>str</code> Unique identifier (UUID, auto-generated) <code>timestamp</code> <code>datetime</code> When the interaction occurred <code>provider</code> <code>Optional[str]</code> AI provider name (e.g., \"openai\") <code>model</code> <code>Optional[str]</code> Model identifier (e.g., \"gpt-4\") <code>conversation_id</code> <code>Optional[str]</code> ID linking related interactions <code>input_hash</code> <code>str</code> SHA-256 hash of input content <code>output_hash</code> <code>str</code> SHA-256 hash of output content <code>input_content</code> <code>Optional[str]</code> Actual input (if stored, may be encrypted) <code>output_content</code> <code>Optional[str]</code> Actual output (if stored, may be encrypted) <code>safety_passed</code> <code>bool</code> Whether all safety checks passed <code>detectors_triggered</code> <code>List[str]</code> Safety detectors that flagged content <code>block_reason</code> <code>Optional[str]</code> Reason if interaction was blocked <code>alerts</code> <code>List[str]</code> Alert messages generated <code>latency_ms</code> <code>float</code> Response time in milliseconds <code>input_tokens</code> <code>Optional[int]</code> Number of input tokens <code>output_tokens</code> <code>Optional[int]</code> Number of output tokens <code>metadata</code> <code>Dict[str, Any]</code> Additional custom metadata <p>Example:</p> <pre><code>from rotalabs_comply import AuditEntry\n\nentry = AuditEntry(\n    provider=\"openai\",\n    model=\"gpt-4\",\n    input_hash=\"abc123...\",\n    output_hash=\"def456...\",\n    safety_passed=True,\n    latency_ms=245.5,\n)\n</code></pre>"},{"location":"api/core/#rotalabs_comply.core.types.AuditEntry","title":"AuditEntry","text":"<p>A single audit log entry capturing an AI system interaction.</p> <p>This model captures comprehensive information about AI model invocations, including input/output data (or hashes for privacy), safety checks, and performance metrics.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Unique identifier for this audit entry (UUID).</p> <code>timestamp</code> <code>datetime</code> <p>When the interaction occurred.</p> <code>provider</code> <code>Optional[str]</code> <p>AI provider name (e.g., \"openai\", \"anthropic\").</p> <code>model</code> <code>Optional[str]</code> <p>Model identifier (e.g., \"gpt-4\", \"claude-3-opus\").</p> <code>conversation_id</code> <code>Optional[str]</code> <p>Optional ID linking related interactions.</p> <code>input_hash</code> <code>str</code> <p>SHA-256 hash of the input content.</p> <code>output_hash</code> <code>str</code> <p>SHA-256 hash of the output content.</p> <code>input_content</code> <code>Optional[str]</code> <p>Actual input text (only if store_content enabled).</p> <code>output_content</code> <code>Optional[str]</code> <p>Actual output text (only if store_content enabled).</p> <code>safety_passed</code> <code>bool</code> <p>Whether all safety checks passed.</p> <code>detectors_triggered</code> <code>List[str]</code> <p>List of detector names that flagged content.</p> <code>block_reason</code> <code>Optional[str]</code> <p>Reason if the interaction was blocked.</p> <code>alerts</code> <code>List[str]</code> <p>List of alert messages generated.</p> <code>latency_ms</code> <code>float</code> <p>Response time in milliseconds.</p> <code>input_tokens</code> <code>Optional[int]</code> <p>Number of input tokens (if available).</p> <code>output_tokens</code> <code>Optional[int]</code> <p>Number of output tokens (if available).</p> <code>metadata</code> <code>Dict[str, Any]</code> <p>Additional custom metadata.</p> Example <p>entry = AuditEntry( ...     provider=\"openai\", ...     model=\"gpt-4\", ...     input_hash=\"abc123...\", ...     output_hash=\"def456...\", ...     safety_passed=True, ...     detectors_triggered=[], ...     latency_ms=245.5, ... )</p> Source code in <code>src/rotalabs_comply/core/types.py</code> <pre><code>class AuditEntry(BaseModel):\n    \"\"\"\n    A single audit log entry capturing an AI system interaction.\n\n    This model captures comprehensive information about AI model invocations,\n    including input/output data (or hashes for privacy), safety checks,\n    and performance metrics.\n\n    Attributes:\n        id: Unique identifier for this audit entry (UUID).\n        timestamp: When the interaction occurred.\n        provider: AI provider name (e.g., \"openai\", \"anthropic\").\n        model: Model identifier (e.g., \"gpt-4\", \"claude-3-opus\").\n        conversation_id: Optional ID linking related interactions.\n        input_hash: SHA-256 hash of the input content.\n        output_hash: SHA-256 hash of the output content.\n        input_content: Actual input text (only if store_content enabled).\n        output_content: Actual output text (only if store_content enabled).\n        safety_passed: Whether all safety checks passed.\n        detectors_triggered: List of detector names that flagged content.\n        block_reason: Reason if the interaction was blocked.\n        alerts: List of alert messages generated.\n        latency_ms: Response time in milliseconds.\n        input_tokens: Number of input tokens (if available).\n        output_tokens: Number of output tokens (if available).\n        metadata: Additional custom metadata.\n\n    Example:\n        &gt;&gt;&gt; entry = AuditEntry(\n        ...     provider=\"openai\",\n        ...     model=\"gpt-4\",\n        ...     input_hash=\"abc123...\",\n        ...     output_hash=\"def456...\",\n        ...     safety_passed=True,\n        ...     detectors_triggered=[],\n        ...     latency_ms=245.5,\n        ... )\n    \"\"\"\n\n    model_config = ConfigDict(\n        populate_by_name=True,\n        use_enum_values=True,\n        validate_default=True,\n    )\n\n    id: str = Field(\n        default_factory=lambda: str(uuid4()),\n        description=\"Unique identifier for this audit entry\",\n    )\n    timestamp: datetime = Field(\n        default_factory=datetime.utcnow,\n        description=\"When the interaction occurred\",\n    )\n    provider: Optional[str] = Field(\n        default=None,\n        description=\"AI provider name (e.g., 'openai', 'anthropic')\",\n    )\n    model: Optional[str] = Field(\n        default=None,\n        description=\"Model identifier (e.g., 'gpt-4', 'claude-3-opus')\",\n    )\n    conversation_id: Optional[str] = Field(\n        default=None,\n        description=\"Optional ID linking related interactions\",\n    )\n    input_hash: str = Field(\n        ...,\n        description=\"SHA-256 hash of the input content\",\n    )\n    output_hash: str = Field(\n        ...,\n        description=\"SHA-256 hash of the output content\",\n    )\n    input_content: Optional[str] = Field(\n        default=None,\n        description=\"Actual input text (only if store_content enabled)\",\n    )\n    output_content: Optional[str] = Field(\n        default=None,\n        description=\"Actual output text (only if store_content enabled)\",\n    )\n    safety_passed: bool = Field(\n        ...,\n        description=\"Whether all safety checks passed\",\n    )\n    detectors_triggered: List[str] = Field(\n        default_factory=list,\n        description=\"List of detector names that flagged content\",\n    )\n    block_reason: Optional[str] = Field(\n        default=None,\n        description=\"Reason if the interaction was blocked\",\n    )\n    alerts: List[str] = Field(\n        default_factory=list,\n        description=\"List of alert messages generated\",\n    )\n    latency_ms: float = Field(\n        ...,\n        ge=0,\n        description=\"Response time in milliseconds\",\n    )\n    input_tokens: Optional[int] = Field(\n        default=None,\n        ge=0,\n        description=\"Number of input tokens (if available)\",\n    )\n    output_tokens: Optional[int] = Field(\n        default=None,\n        ge=0,\n        description=\"Number of output tokens (if available)\",\n    )\n    metadata: Dict[str, Any] = Field(\n        default_factory=dict,\n        description=\"Additional custom metadata\",\n    )\n</code></pre>"},{"location":"api/core/#complianceprofile","title":"ComplianceProfile","text":"<p>Configuration profile defining compliance requirements.</p> <p>Attributes:</p> Attribute Type Default Description <code>frameworks</code> <code>List[Framework]</code> <code>[]</code> Regulatory frameworks to comply with <code>risk_level</code> <code>RiskLevel</code> <code>MEDIUM</code> Maximum acceptable risk level <code>required_documentation</code> <code>bool</code> <code>True</code> Whether comprehensive docs required <code>data_retention_days</code> <code>int</code> <code>365</code> Days to retain audit data <code>encrypt_audit_logs</code> <code>bool</code> <code>True</code> Whether to encrypt stored logs <code>store_content</code> <code>bool</code> <code>False</code> Store content vs just hashes <code>custom_policies</code> <code>Dict[str, Any]</code> <code>{}</code> Custom policy configurations <p>Example:</p> <pre><code>from rotalabs_comply import ComplianceProfile, Framework, RiskLevel\n\nprofile = ComplianceProfile(\n    frameworks=[Framework.GDPR, Framework.EU_AI_ACT],\n    risk_level=RiskLevel.MEDIUM,\n    data_retention_days=365,\n    store_content=False,\n)\n</code></pre>"},{"location":"api/core/#rotalabs_comply.core.types.ComplianceProfile","title":"ComplianceProfile","text":"<p>Configuration profile defining compliance requirements.</p> <p>This model specifies which regulatory frameworks apply, risk tolerance, documentation requirements, and data handling policies for an AI system.</p> <p>Attributes:</p> Name Type Description <code>frameworks</code> <code>List[Framework]</code> <p>List of regulatory frameworks to comply with.</p> <code>risk_level</code> <code>RiskLevel</code> <p>Maximum acceptable risk level.</p> <code>required_documentation</code> <code>bool</code> <p>Whether comprehensive docs are required.</p> <code>data_retention_days</code> <code>int</code> <p>How long to retain audit data.</p> <code>encrypt_audit_logs</code> <code>bool</code> <p>Whether to encrypt stored audit logs.</p> <code>store_content</code> <code>bool</code> <p>Whether to store actual content vs just hashes.</p> <code>custom_policies</code> <code>Dict[str, Any]</code> <p>Additional custom policy configurations.</p> Example <p>profile = ComplianceProfile( ...     frameworks=[Framework.GDPR, Framework.EU_AI_ACT], ...     risk_level=RiskLevel.MEDIUM, ...     data_retention_days=365, ...     store_content=False,  # Privacy mode ... )</p> Source code in <code>src/rotalabs_comply/core/types.py</code> <pre><code>class ComplianceProfile(BaseModel):\n    \"\"\"\n    Configuration profile defining compliance requirements.\n\n    This model specifies which regulatory frameworks apply, risk tolerance,\n    documentation requirements, and data handling policies for an AI system.\n\n    Attributes:\n        frameworks: List of regulatory frameworks to comply with.\n        risk_level: Maximum acceptable risk level.\n        required_documentation: Whether comprehensive docs are required.\n        data_retention_days: How long to retain audit data.\n        encrypt_audit_logs: Whether to encrypt stored audit logs.\n        store_content: Whether to store actual content vs just hashes.\n        custom_policies: Additional custom policy configurations.\n\n    Example:\n        &gt;&gt;&gt; profile = ComplianceProfile(\n        ...     frameworks=[Framework.GDPR, Framework.EU_AI_ACT],\n        ...     risk_level=RiskLevel.MEDIUM,\n        ...     data_retention_days=365,\n        ...     store_content=False,  # Privacy mode\n        ... )\n    \"\"\"\n\n    model_config = ConfigDict(\n        populate_by_name=True,\n        use_enum_values=True,\n        validate_default=True,\n    )\n\n    frameworks: List[Framework] = Field(\n        default_factory=list,\n        description=\"List of regulatory frameworks to comply with\",\n    )\n    risk_level: RiskLevel = Field(\n        default=RiskLevel.MEDIUM,\n        description=\"Maximum acceptable risk level\",\n    )\n    required_documentation: bool = Field(\n        default=True,\n        description=\"Whether comprehensive documentation is required\",\n    )\n    data_retention_days: int = Field(\n        default=365,\n        ge=1,\n        description=\"How long to retain audit data in days\",\n    )\n    encrypt_audit_logs: bool = Field(\n        default=True,\n        description=\"Whether to encrypt stored audit logs\",\n    )\n    store_content: bool = Field(\n        default=False,\n        description=\"Whether to store actual content vs just hashes\",\n    )\n    custom_policies: Dict[str, Any] = Field(\n        default_factory=dict,\n        description=\"Additional custom policy configurations\",\n    )\n</code></pre>"},{"location":"api/core/#complianceviolation","title":"ComplianceViolation","text":"<p>A single compliance violation detected during checking.</p> <p>Attributes:</p> Attribute Type Description <code>framework</code> <code>Framework</code> The framework that was violated <code>rule_id</code> <code>str</code> Identifier of the violated rule <code>severity</code> <code>RiskLevel</code> Severity of the violation <code>description</code> <code>str</code> Human-readable description <code>evidence</code> <code>Dict[str, Any]</code> Data supporting the finding <code>remediation</code> <code>str</code> Recommended fix steps <code>timestamp</code> <code>datetime</code> When violation was detected <p>Example:</p> <pre><code>from rotalabs_comply import ComplianceViolation, Framework, RiskLevel\n\nviolation = ComplianceViolation(\n    framework=Framework.GDPR,\n    rule_id=\"GDPR-ART13-1\",\n    severity=RiskLevel.HIGH,\n    description=\"Personal data processed without consent record\",\n    evidence={\"field\": \"user_email\"},\n    remediation=\"Implement consent tracking mechanism\",\n)\n</code></pre>"},{"location":"api/core/#rotalabs_comply.core.types.ComplianceViolation","title":"ComplianceViolation","text":"<p>A single compliance violation detected during checking.</p> <p>This model captures details about a specific compliance rule violation, including the framework, severity, and recommended remediation steps.</p> <p>Attributes:</p> Name Type Description <code>framework</code> <code>Framework</code> <p>The regulatory framework that was violated.</p> <code>rule_id</code> <code>str</code> <p>Identifier of the specific rule that was violated.</p> <code>severity</code> <code>RiskLevel</code> <p>How severe the violation is.</p> <code>description</code> <code>str</code> <p>Human-readable description of the violation.</p> <code>evidence</code> <code>Dict[str, Any]</code> <p>Data supporting the violation finding.</p> <code>remediation</code> <code>str</code> <p>Recommended steps to fix the violation.</p> <code>timestamp</code> <code>datetime</code> <p>When the violation was detected.</p> Example <p>violation = ComplianceViolation( ...     framework=Framework.GDPR, ...     rule_id=\"GDPR-ART13-1\", ...     severity=RiskLevel.HIGH, ...     description=\"Personal data processed without consent record\", ...     evidence={\"field\": \"user_email\", \"record_id\": \"123\"}, ...     remediation=\"Implement consent tracking mechanism\", ... )</p> Source code in <code>src/rotalabs_comply/core/types.py</code> <pre><code>class ComplianceViolation(BaseModel):\n    \"\"\"\n    A single compliance violation detected during checking.\n\n    This model captures details about a specific compliance rule violation,\n    including the framework, severity, and recommended remediation steps.\n\n    Attributes:\n        framework: The regulatory framework that was violated.\n        rule_id: Identifier of the specific rule that was violated.\n        severity: How severe the violation is.\n        description: Human-readable description of the violation.\n        evidence: Data supporting the violation finding.\n        remediation: Recommended steps to fix the violation.\n        timestamp: When the violation was detected.\n\n    Example:\n        &gt;&gt;&gt; violation = ComplianceViolation(\n        ...     framework=Framework.GDPR,\n        ...     rule_id=\"GDPR-ART13-1\",\n        ...     severity=RiskLevel.HIGH,\n        ...     description=\"Personal data processed without consent record\",\n        ...     evidence={\"field\": \"user_email\", \"record_id\": \"123\"},\n        ...     remediation=\"Implement consent tracking mechanism\",\n        ... )\n    \"\"\"\n\n    model_config = ConfigDict(\n        populate_by_name=True,\n        use_enum_values=True,\n        validate_default=True,\n    )\n\n    framework: Framework = Field(\n        ...,\n        description=\"The regulatory framework that was violated\",\n    )\n    rule_id: str = Field(\n        ...,\n        description=\"Identifier of the specific rule that was violated\",\n    )\n    severity: RiskLevel = Field(\n        ...,\n        description=\"How severe the violation is\",\n    )\n    description: str = Field(\n        ...,\n        description=\"Human-readable description of the violation\",\n    )\n    evidence: Dict[str, Any] = Field(\n        default_factory=dict,\n        description=\"Data supporting the violation finding\",\n    )\n    remediation: str = Field(\n        ...,\n        description=\"Recommended steps to fix the violation\",\n    )\n    timestamp: datetime = Field(\n        default_factory=datetime.utcnow,\n        description=\"When the violation was detected\",\n    )\n</code></pre>"},{"location":"api/core/#compliancecheckresult","title":"ComplianceCheckResult","text":"<p>Result of a compliance check against a regulatory framework.</p> <p>Attributes:</p> Attribute Type Description <code>passed</code> <code>bool</code> Whether check passed (no critical violations) <code>framework</code> <code>Framework</code> Framework checked against <code>violations</code> <code>List[ComplianceViolation]</code> Violations found <code>warnings</code> <code>List[str]</code> Non-critical issues <code>recommendations</code> <code>List[str]</code> Improvement suggestions <code>checked_at</code> <code>datetime</code> When check was performed <p>Example:</p> <pre><code>from rotalabs_comply import ComplianceCheckResult, Framework\n\nresult = ComplianceCheckResult(\n    passed=False,\n    framework=Framework.SOC2,\n    violations=[violation],\n    warnings=[\"Audit log rotation not configured\"],\n    recommendations=[\"Enable encryption for audit logs\"],\n)\n</code></pre>"},{"location":"api/core/#rotalabs_comply.core.types.ComplianceCheckResult","title":"ComplianceCheckResult","text":"<p>Result of a compliance check against a regulatory framework.</p> <p>This model captures the outcome of validating an AI system's operations against compliance requirements, including any violations found.</p> <p>Attributes:</p> Name Type Description <code>passed</code> <code>bool</code> <p>Whether the check passed (no critical violations).</p> <code>framework</code> <code>Framework</code> <p>The framework that was checked against.</p> <code>violations</code> <code>List[ComplianceViolation]</code> <p>List of compliance violations found.</p> <code>warnings</code> <code>List[str]</code> <p>Non-critical issues that should be addressed.</p> <code>recommendations</code> <code>List[str]</code> <p>Suggestions for improving compliance posture.</p> <code>checked_at</code> <code>datetime</code> <p>When the compliance check was performed.</p> Example <p>result = ComplianceCheckResult( ...     passed=False, ...     framework=Framework.SOC2, ...     violations=[violation], ...     warnings=[\"Audit log rotation not configured\"], ...     recommendations=[\"Enable encryption for audit logs\"], ... )</p> Source code in <code>src/rotalabs_comply/core/types.py</code> <pre><code>class ComplianceCheckResult(BaseModel):\n    \"\"\"\n    Result of a compliance check against a regulatory framework.\n\n    This model captures the outcome of validating an AI system's operations\n    against compliance requirements, including any violations found.\n\n    Attributes:\n        passed: Whether the check passed (no critical violations).\n        framework: The framework that was checked against.\n        violations: List of compliance violations found.\n        warnings: Non-critical issues that should be addressed.\n        recommendations: Suggestions for improving compliance posture.\n        checked_at: When the compliance check was performed.\n\n    Example:\n        &gt;&gt;&gt; result = ComplianceCheckResult(\n        ...     passed=False,\n        ...     framework=Framework.SOC2,\n        ...     violations=[violation],\n        ...     warnings=[\"Audit log rotation not configured\"],\n        ...     recommendations=[\"Enable encryption for audit logs\"],\n        ... )\n    \"\"\"\n\n    model_config = ConfigDict(\n        populate_by_name=True,\n        use_enum_values=True,\n        validate_default=True,\n    )\n\n    passed: bool = Field(\n        ...,\n        description=\"Whether the check passed (no critical violations)\",\n    )\n    framework: Framework = Field(\n        ...,\n        description=\"The framework that was checked against\",\n    )\n    violations: List[ComplianceViolation] = Field(\n        default_factory=list,\n        description=\"List of compliance violations found\",\n    )\n    warnings: List[str] = Field(\n        default_factory=list,\n        description=\"Non-critical issues that should be addressed\",\n    )\n    recommendations: List[str] = Field(\n        default_factory=list,\n        description=\"Suggestions for improving compliance posture\",\n    )\n    checked_at: datetime = Field(\n        default_factory=datetime.utcnow,\n        description=\"When the compliance check was performed\",\n    )\n</code></pre>"},{"location":"api/core/#configuration-classes","title":"Configuration Classes","text":""},{"location":"api/core/#auditconfig","title":"AuditConfig","text":"<p>Configuration for audit logging behavior.</p> <p>Attributes:</p> Attribute Type Default Description <code>destination</code> <code>str</code> Required File path or S3 URL for logs <code>encryption_enabled</code> <code>bool</code> <code>True</code> Encrypt data at rest <code>encryption_key</code> <code>Optional[str]</code> Auto-gen Base64-encoded encryption key <code>retention_days</code> <code>int</code> <code>365</code> Days before deletion (1-3650) <code>max_file_size_mb</code> <code>int</code> <code>100</code> Max file size before rotation <code>rotation_enabled</code> <code>bool</code> <code>True</code> Enable automatic rotation <code>compression_enabled</code> <code>bool</code> <code>False</code> Compress audit files <p>Properties:</p> Property Type Description <code>is_s3_destination</code> <code>bool</code> Whether destination is S3 URL <code>s3_bucket</code> <code>Optional[str]</code> S3 bucket name if applicable <code>s3_prefix</code> <code>Optional[str]</code> S3 key prefix if applicable <p>Example:</p> <pre><code>from rotalabs_comply import AuditConfig\n\n# File storage\nconfig = AuditConfig(\n    destination=\"/var/log/ai-audit/\",\n    encryption_enabled=True,\n    retention_days=365,\n)\n\n# S3 storage\ns3_config = AuditConfig(\n    destination=\"s3://my-bucket/audit-logs/\",\n    encryption_enabled=True,\n    compression_enabled=True,\n)\n</code></pre>"},{"location":"api/core/#rotalabs_comply.core.config.AuditConfig","title":"AuditConfig","text":"<p>Configuration for audit logging behavior.</p> <p>This model defines how audit entries are stored, encrypted, rotated, and retained over time.</p> <p>Attributes:</p> Name Type Description <code>destination</code> <code>str</code> <p>File path or S3 URL (s3://bucket/prefix) for audit logs.</p> <code>encryption_enabled</code> <code>bool</code> <p>Whether to encrypt audit log data at rest.</p> <code>encryption_key</code> <code>Optional[str]</code> <p>Base64-encoded encryption key (auto-generated if not provided).</p> <code>retention_days</code> <code>int</code> <p>Number of days to retain audit logs before deletion.</p> <code>max_file_size_mb</code> <code>int</code> <p>Maximum size of a single audit log file before rotation.</p> <code>rotation_enabled</code> <code>bool</code> <p>Whether to enable automatic log rotation.</p> <code>compression_enabled</code> <code>bool</code> <p>Whether to compress audit log files.</p> Example <p>config = AuditConfig( ...     destination=\"/var/log/ai-audit/\", ...     encryption_enabled=True, ...     retention_days=365, ...     rotation_enabled=True, ... )</p> <p>s3_config = AuditConfig( ...     destination=\"s3://my-bucket/audit-logs/\", ...     encryption_enabled=True, ...     compression_enabled=True, ... )</p> Source code in <code>src/rotalabs_comply/core/config.py</code> <pre><code>class AuditConfig(BaseModel):\n    \"\"\"\n    Configuration for audit logging behavior.\n\n    This model defines how audit entries are stored, encrypted,\n    rotated, and retained over time.\n\n    Attributes:\n        destination: File path or S3 URL (s3://bucket/prefix) for audit logs.\n        encryption_enabled: Whether to encrypt audit log data at rest.\n        encryption_key: Base64-encoded encryption key (auto-generated if not provided).\n        retention_days: Number of days to retain audit logs before deletion.\n        max_file_size_mb: Maximum size of a single audit log file before rotation.\n        rotation_enabled: Whether to enable automatic log rotation.\n        compression_enabled: Whether to compress audit log files.\n\n    Example:\n        &gt;&gt;&gt; config = AuditConfig(\n        ...     destination=\"/var/log/ai-audit/\",\n        ...     encryption_enabled=True,\n        ...     retention_days=365,\n        ...     rotation_enabled=True,\n        ... )\n\n        &gt;&gt;&gt; s3_config = AuditConfig(\n        ...     destination=\"s3://my-bucket/audit-logs/\",\n        ...     encryption_enabled=True,\n        ...     compression_enabled=True,\n        ... )\n    \"\"\"\n\n    model_config = ConfigDict(\n        populate_by_name=True,\n        validate_default=True,\n        extra=\"forbid\",\n    )\n\n    destination: str = Field(\n        ...,\n        description=\"File path or S3 URL (s3://bucket/prefix) for audit logs\",\n    )\n    encryption_enabled: bool = Field(\n        default=True,\n        description=\"Whether to encrypt audit log data at rest\",\n    )\n    encryption_key: Optional[str] = Field(\n        default=None,\n        description=\"Base64-encoded encryption key (auto-generated if not provided)\",\n    )\n    retention_days: int = Field(\n        default=365,\n        ge=1,\n        le=3650,  # Max 10 years\n        description=\"Number of days to retain audit logs before deletion\",\n    )\n    max_file_size_mb: int = Field(\n        default=100,\n        ge=1,\n        le=1000,\n        description=\"Maximum size of a single audit log file before rotation (MB)\",\n    )\n    rotation_enabled: bool = Field(\n        default=True,\n        description=\"Whether to enable automatic log rotation\",\n    )\n    compression_enabled: bool = Field(\n        default=False,\n        description=\"Whether to compress audit log files\",\n    )\n\n    def model_post_init(self, __context) -&gt; None:\n        \"\"\"Auto-generate encryption key if encryption is enabled but no key provided.\"\"\"\n        if self.encryption_enabled and self.encryption_key is None:\n            # Generate a secure 256-bit key (32 bytes) as hex string\n            object.__setattr__(self, \"encryption_key\", secrets.token_hex(32))\n\n    @field_validator(\"destination\")\n    @classmethod\n    def validate_destination(cls, v: str) -&gt; str:\n        \"\"\"Validate that destination is a valid path or S3 URL.\"\"\"\n        v = v.strip()\n        if not v:\n            raise ValueError(\"destination cannot be empty\")\n        # Allow file paths (absolute or relative) and S3 URLs\n        if v.startswith(\"s3://\"):\n            # Basic S3 URL validation\n            parts = v[5:].split(\"/\", 1)\n            if not parts[0]:\n                raise ValueError(\"S3 URL must include bucket name\")\n        return v\n\n    @property\n    def is_s3_destination(self) -&gt; bool:\n        \"\"\"Check if the destination is an S3 URL.\"\"\"\n        return self.destination.startswith(\"s3://\")\n\n    @property\n    def s3_bucket(self) -&gt; Optional[str]:\n        \"\"\"Extract S3 bucket name from destination if applicable.\"\"\"\n        if not self.is_s3_destination:\n            return None\n        return self.destination[5:].split(\"/\", 1)[0]\n\n    @property\n    def s3_prefix(self) -&gt; Optional[str]:\n        \"\"\"Extract S3 key prefix from destination if applicable.\"\"\"\n        if not self.is_s3_destination:\n            return None\n        parts = self.destination[5:].split(\"/\", 1)\n        return parts[1] if len(parts) &gt; 1 else \"\"\n</code></pre>"},{"location":"api/core/#rotalabs_comply.core.config.AuditConfig.is_s3_destination","title":"is_s3_destination  <code>property</code>","text":"<pre><code>is_s3_destination: bool\n</code></pre> <p>Check if the destination is an S3 URL.</p>"},{"location":"api/core/#rotalabs_comply.core.config.AuditConfig.s3_bucket","title":"s3_bucket  <code>property</code>","text":"<pre><code>s3_bucket: Optional[str]\n</code></pre> <p>Extract S3 bucket name from destination if applicable.</p>"},{"location":"api/core/#rotalabs_comply.core.config.AuditConfig.s3_prefix","title":"s3_prefix  <code>property</code>","text":"<pre><code>s3_prefix: Optional[str]\n</code></pre> <p>Extract S3 key prefix from destination if applicable.</p>"},{"location":"api/core/#rotalabs_comply.core.config.AuditConfig.model_post_init","title":"model_post_init","text":"<pre><code>model_post_init(__context) -&gt; None\n</code></pre> <p>Auto-generate encryption key if encryption is enabled but no key provided.</p> Source code in <code>src/rotalabs_comply/core/config.py</code> <pre><code>def model_post_init(self, __context) -&gt; None:\n    \"\"\"Auto-generate encryption key if encryption is enabled but no key provided.\"\"\"\n    if self.encryption_enabled and self.encryption_key is None:\n        # Generate a secure 256-bit key (32 bytes) as hex string\n        object.__setattr__(self, \"encryption_key\", secrets.token_hex(32))\n</code></pre>"},{"location":"api/core/#rotalabs_comply.core.config.AuditConfig.validate_destination","title":"validate_destination  <code>classmethod</code>","text":"<pre><code>validate_destination(v: str) -&gt; str\n</code></pre> <p>Validate that destination is a valid path or S3 URL.</p> Source code in <code>src/rotalabs_comply/core/config.py</code> <pre><code>@field_validator(\"destination\")\n@classmethod\ndef validate_destination(cls, v: str) -&gt; str:\n    \"\"\"Validate that destination is a valid path or S3 URL.\"\"\"\n    v = v.strip()\n    if not v:\n        raise ValueError(\"destination cannot be empty\")\n    # Allow file paths (absolute or relative) and S3 URLs\n    if v.startswith(\"s3://\"):\n        # Basic S3 URL validation\n        parts = v[5:].split(\"/\", 1)\n        if not parts[0]:\n            raise ValueError(\"S3 URL must include bucket name\")\n    return v\n</code></pre>"},{"location":"api/core/#storageconfig","title":"StorageConfig","text":"<p>Configuration for storage backend selection.</p> <p>Attributes:</p> Attribute Type Default Description <code>backend</code> <code>Literal[\"file\", \"s3\", \"memory\"]</code> <code>\"file\"</code> Storage backend type <code>path</code> <code>Optional[str]</code> <code>None</code> Local path for file backend <code>bucket</code> <code>Optional[str]</code> <code>None</code> S3 bucket for S3 backend <code>prefix</code> <code>Optional[str]</code> <code>None</code> S3 key prefix <code>region</code> <code>Optional[str]</code> <code>None</code> AWS region for S3 <p>Example:</p> <pre><code>from rotalabs_comply import StorageConfig\n\n# File storage\nfile_config = StorageConfig(\n    backend=\"file\",\n    path=\"/var/log/ai-audit/\",\n)\n\n# S3 storage\ns3_config = StorageConfig(\n    backend=\"s3\",\n    bucket=\"my-audit-bucket\",\n    prefix=\"prod/audit-logs/\",\n    region=\"us-west-2\",\n)\n\n# Memory storage (testing)\nmemory_config = StorageConfig(backend=\"memory\")\n</code></pre>"},{"location":"api/core/#rotalabs_comply.core.config.StorageConfig","title":"StorageConfig","text":"<p>Configuration for storage backend selection and settings.</p> <p>This model defines which storage backend to use and its specific configuration options.</p> <p>Attributes:</p> Name Type Description <code>backend</code> <code>Literal['file', 's3', 'memory']</code> <p>Storage backend type (\"file\", \"s3\", or \"memory\").</p> <code>path</code> <code>Optional[str]</code> <p>Local file path for file backend.</p> <code>bucket</code> <code>Optional[str]</code> <p>S3 bucket name for S3 backend.</p> <code>prefix</code> <code>Optional[str]</code> <p>S3 key prefix for organizing objects.</p> <code>region</code> <code>Optional[str]</code> <p>AWS region for S3 backend.</p> Example <p>file_storage = StorageConfig( ...     backend=\"file\", ...     path=\"/var/log/ai-audit/\", ... )</p> <p>s3_storage = StorageConfig( ...     backend=\"s3\", ...     bucket=\"my-audit-bucket\", ...     prefix=\"prod/audit-logs/\", ...     region=\"us-west-2\", ... )</p> <p>memory_storage = StorageConfig( ...     backend=\"memory\",  # For testing ... )</p> Source code in <code>src/rotalabs_comply/core/config.py</code> <pre><code>class StorageConfig(BaseModel):\n    \"\"\"\n    Configuration for storage backend selection and settings.\n\n    This model defines which storage backend to use and its\n    specific configuration options.\n\n    Attributes:\n        backend: Storage backend type (\"file\", \"s3\", or \"memory\").\n        path: Local file path for file backend.\n        bucket: S3 bucket name for S3 backend.\n        prefix: S3 key prefix for organizing objects.\n        region: AWS region for S3 backend.\n\n    Example:\n        &gt;&gt;&gt; file_storage = StorageConfig(\n        ...     backend=\"file\",\n        ...     path=\"/var/log/ai-audit/\",\n        ... )\n\n        &gt;&gt;&gt; s3_storage = StorageConfig(\n        ...     backend=\"s3\",\n        ...     bucket=\"my-audit-bucket\",\n        ...     prefix=\"prod/audit-logs/\",\n        ...     region=\"us-west-2\",\n        ... )\n\n        &gt;&gt;&gt; memory_storage = StorageConfig(\n        ...     backend=\"memory\",  # For testing\n        ... )\n    \"\"\"\n\n    model_config = ConfigDict(\n        populate_by_name=True,\n        validate_default=True,\n        extra=\"forbid\",\n    )\n\n    backend: Literal[\"file\", \"s3\", \"memory\"] = Field(\n        default=\"file\",\n        description=\"Storage backend type\",\n    )\n    path: Optional[str] = Field(\n        default=None,\n        description=\"Local file path for file backend\",\n    )\n    bucket: Optional[str] = Field(\n        default=None,\n        description=\"S3 bucket name for S3 backend\",\n    )\n    prefix: Optional[str] = Field(\n        default=None,\n        description=\"S3 key prefix for organizing objects\",\n    )\n    region: Optional[str] = Field(\n        default=None,\n        description=\"AWS region for S3 backend\",\n    )\n\n    @field_validator(\"path\")\n    @classmethod\n    def validate_path(cls, v: Optional[str]) -&gt; Optional[str]:\n        \"\"\"Validate and normalize file path.\"\"\"\n        if v is not None:\n            v = v.strip()\n            if not v:\n                return None\n        return v\n\n    @field_validator(\"bucket\")\n    @classmethod\n    def validate_bucket(cls, v: Optional[str]) -&gt; Optional[str]:\n        \"\"\"Validate S3 bucket name.\"\"\"\n        if v is not None:\n            v = v.strip()\n            if not v:\n                return None\n            # Basic S3 bucket naming validation\n            if len(v) &lt; 3 or len(v) &gt; 63:\n                raise ValueError(\"S3 bucket name must be between 3 and 63 characters\")\n            if not v[0].isalnum():\n                raise ValueError(\"S3 bucket name must start with a letter or number\")\n        return v\n\n    def model_post_init(self, __context) -&gt; None:\n        \"\"\"Validate backend-specific requirements.\"\"\"\n        if self.backend == \"file\" and not self.path:\n            raise ValueError(\"path is required for file backend\")\n        if self.backend == \"s3\" and not self.bucket:\n            raise ValueError(\"bucket is required for S3 backend\")\n</code></pre>"},{"location":"api/core/#rotalabs_comply.core.config.StorageConfig.validate_path","title":"validate_path  <code>classmethod</code>","text":"<pre><code>validate_path(v: Optional[str]) -&gt; Optional[str]\n</code></pre> <p>Validate and normalize file path.</p> Source code in <code>src/rotalabs_comply/core/config.py</code> <pre><code>@field_validator(\"path\")\n@classmethod\ndef validate_path(cls, v: Optional[str]) -&gt; Optional[str]:\n    \"\"\"Validate and normalize file path.\"\"\"\n    if v is not None:\n        v = v.strip()\n        if not v:\n            return None\n    return v\n</code></pre>"},{"location":"api/core/#rotalabs_comply.core.config.StorageConfig.validate_bucket","title":"validate_bucket  <code>classmethod</code>","text":"<pre><code>validate_bucket(v: Optional[str]) -&gt; Optional[str]\n</code></pre> <p>Validate S3 bucket name.</p> Source code in <code>src/rotalabs_comply/core/config.py</code> <pre><code>@field_validator(\"bucket\")\n@classmethod\ndef validate_bucket(cls, v: Optional[str]) -&gt; Optional[str]:\n    \"\"\"Validate S3 bucket name.\"\"\"\n    if v is not None:\n        v = v.strip()\n        if not v:\n            return None\n        # Basic S3 bucket naming validation\n        if len(v) &lt; 3 or len(v) &gt; 63:\n            raise ValueError(\"S3 bucket name must be between 3 and 63 characters\")\n        if not v[0].isalnum():\n            raise ValueError(\"S3 bucket name must start with a letter or number\")\n    return v\n</code></pre>"},{"location":"api/core/#rotalabs_comply.core.config.StorageConfig.model_post_init","title":"model_post_init","text":"<pre><code>model_post_init(__context) -&gt; None\n</code></pre> <p>Validate backend-specific requirements.</p> Source code in <code>src/rotalabs_comply/core/config.py</code> <pre><code>def model_post_init(self, __context) -&gt; None:\n    \"\"\"Validate backend-specific requirements.\"\"\"\n    if self.backend == \"file\" and not self.path:\n        raise ValueError(\"path is required for file backend\")\n    if self.backend == \"s3\" and not self.bucket:\n        raise ValueError(\"bucket is required for S3 backend\")\n</code></pre>"},{"location":"api/core/#exceptions","title":"Exceptions","text":""},{"location":"api/core/#complianceerror","title":"ComplianceError","text":"<p>Base exception for all compliance-related errors.</p> <p>Attributes:</p> Attribute Type Description <code>message</code> <code>str</code> Human-readable error description <code>details</code> <code>Dict[str, Any]</code> Additional error context <p>Example:</p> <pre><code>from rotalabs_comply import ComplianceError\n\ntry:\n    # ... compliance operation\n    pass\nexcept ComplianceError as e:\n    print(f\"Error: {e.message}\")\n    print(f\"Details: {e.details}\")\n</code></pre>"},{"location":"api/core/#rotalabs_comply.core.exceptions.ComplianceError","title":"ComplianceError","text":"<p>Base exception for all compliance-related errors.</p> <p>All other exceptions in this module inherit from this class, allowing for broad exception catching when needed.</p> <p>Attributes:</p> Name Type Description <code>message</code> <p>Human-readable error description.</p> <code>details</code> <p>Optional dictionary with additional error context.</p> Source code in <code>src/rotalabs_comply/core/exceptions.py</code> <pre><code>class ComplianceError(Exception):\n    \"\"\"\n    Base exception for all compliance-related errors.\n\n    All other exceptions in this module inherit from this class,\n    allowing for broad exception catching when needed.\n\n    Attributes:\n        message: Human-readable error description.\n        details: Optional dictionary with additional error context.\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        details: Optional[Dict[str, Any]] = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize a ComplianceError.\n\n        Args:\n            message: Human-readable error description.\n            details: Optional dictionary with additional context about the error.\n        \"\"\"\n        self.message = message\n        self.details = details or {}\n        super().__init__(message)\n\n    def __str__(self) -&gt; str:\n        \"\"\"Return string representation of the error.\"\"\"\n        if self.details:\n            return f\"{self.message} | Details: {self.details}\"\n        return self.message\n</code></pre>"},{"location":"api/core/#rotalabs_comply.core.exceptions.ComplianceError.__init__","title":"__init__","text":"<pre><code>__init__(\n    message: str, details: Optional[Dict[str, Any]] = None\n) -&gt; None\n</code></pre> <p>Initialize a ComplianceError.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error description.</p> required <code>details</code> <code>Optional[Dict[str, Any]]</code> <p>Optional dictionary with additional context about the error.</p> <code>None</code> Source code in <code>src/rotalabs_comply/core/exceptions.py</code> <pre><code>def __init__(\n    self,\n    message: str,\n    details: Optional[Dict[str, Any]] = None,\n) -&gt; None:\n    \"\"\"\n    Initialize a ComplianceError.\n\n    Args:\n        message: Human-readable error description.\n        details: Optional dictionary with additional context about the error.\n    \"\"\"\n    self.message = message\n    self.details = details or {}\n    super().__init__(message)\n</code></pre>"},{"location":"api/core/#rotalabs_comply.core.exceptions.ComplianceError.__str__","title":"__str__","text":"<pre><code>__str__() -&gt; str\n</code></pre> <p>Return string representation of the error.</p> Source code in <code>src/rotalabs_comply/core/exceptions.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return string representation of the error.\"\"\"\n    if self.details:\n        return f\"{self.message} | Details: {self.details}\"\n    return self.message\n</code></pre>"},{"location":"api/core/#auditerror","title":"AuditError","text":"<p>Exception for audit logging failures.</p> <p>Raised when: - Writing audit entries fails - Reading audit logs fails - Audit log rotation fails - Audit data validation fails</p>"},{"location":"api/core/#rotalabs_comply.core.exceptions.AuditError","title":"AuditError","text":"<p>Exception raised for audit logging failures.</p> <p>This exception is raised when there are issues with: - Writing audit entries - Reading audit logs - Audit log rotation - Audit data validation</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise AuditError(\"Failed to write audit entry\", {\"entry_id\": \"abc123\"})\n</code></pre> Source code in <code>src/rotalabs_comply/core/exceptions.py</code> <pre><code>class AuditError(ComplianceError):\n    \"\"\"\n    Exception raised for audit logging failures.\n\n    This exception is raised when there are issues with:\n    - Writing audit entries\n    - Reading audit logs\n    - Audit log rotation\n    - Audit data validation\n\n    Examples:\n        &gt;&gt;&gt; raise AuditError(\"Failed to write audit entry\", {\"entry_id\": \"abc123\"})\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api/core/#storageerror","title":"StorageError","text":"<p>Exception for storage backend failures.</p> <p>Raised when: - Storage backend connection fails - Reading/writing data fails - Storage configuration is invalid - Permission issues occur</p>"},{"location":"api/core/#rotalabs_comply.core.exceptions.StorageError","title":"StorageError","text":"<p>Exception raised for storage backend failures.</p> <p>This exception is raised when there are issues with: - Connecting to storage backends (file, S3, etc.) - Reading or writing data to storage - Storage configuration problems - Permission issues</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise StorageError(\"S3 bucket not accessible\", {\"bucket\": \"my-bucket\"})\n</code></pre> Source code in <code>src/rotalabs_comply/core/exceptions.py</code> <pre><code>class StorageError(ComplianceError):\n    \"\"\"\n    Exception raised for storage backend failures.\n\n    This exception is raised when there are issues with:\n    - Connecting to storage backends (file, S3, etc.)\n    - Reading or writing data to storage\n    - Storage configuration problems\n    - Permission issues\n\n    Examples:\n        &gt;&gt;&gt; raise StorageError(\"S3 bucket not accessible\", {\"bucket\": \"my-bucket\"})\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api/core/#encryptionerror","title":"EncryptionError","text":"<p>Exception for encryption/decryption failures.</p> <p>Raised when: - Encrypting audit data fails - Decrypting stored data fails - Key management issues occur - Invalid encryption configuration</p>"},{"location":"api/core/#rotalabs_comply.core.exceptions.EncryptionError","title":"EncryptionError","text":"<p>Exception raised for encryption/decryption failures.</p> <p>This exception is raised when there are issues with: - Encrypting audit data - Decrypting stored data - Key management - Invalid encryption configuration</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise EncryptionError(\"Invalid encryption key format\")\n</code></pre> Source code in <code>src/rotalabs_comply/core/exceptions.py</code> <pre><code>class EncryptionError(ComplianceError):\n    \"\"\"\n    Exception raised for encryption/decryption failures.\n\n    This exception is raised when there are issues with:\n    - Encrypting audit data\n    - Decrypting stored data\n    - Key management\n    - Invalid encryption configuration\n\n    Examples:\n        &gt;&gt;&gt; raise EncryptionError(\"Invalid encryption key format\")\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"api/core/#validationerror","title":"ValidationError","text":"<p>Exception for data validation failures.</p> <p>Additional Attributes:</p> Attribute Type Description <code>field</code> <code>Optional[str]</code> Field that failed validation <code>value</code> <code>Optional[Any]</code> Value that caused failure <p>Example:</p> <pre><code>from rotalabs_comply import ValidationError\n\ntry:\n    # ... validation\n    pass\nexcept ValidationError as e:\n    print(f\"Field: {e.field}\")\n    print(f\"Value: {e.value}\")\n</code></pre>"},{"location":"api/core/#rotalabs_comply.core.exceptions.ValidationError","title":"ValidationError","text":"<p>Exception raised for data validation failures.</p> <p>This exception is raised when there are issues with: - Invalid input data format - Missing required fields - Data type mismatches - Schema validation failures</p> <p>Attributes:</p> Name Type Description <code>field</code> <p>Optional name of the field that failed validation.</p> <code>value</code> <p>Optional value that caused the validation failure.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise ValidationError(\n...     \"Invalid risk level\",\n...     details={\"field\": \"risk_level\", \"value\": \"UNKNOWN\"}\n... )\n</code></pre> Source code in <code>src/rotalabs_comply/core/exceptions.py</code> <pre><code>class ValidationError(ComplianceError):\n    \"\"\"\n    Exception raised for data validation failures.\n\n    This exception is raised when there are issues with:\n    - Invalid input data format\n    - Missing required fields\n    - Data type mismatches\n    - Schema validation failures\n\n    Attributes:\n        field: Optional name of the field that failed validation.\n        value: Optional value that caused the validation failure.\n\n    Examples:\n        &gt;&gt;&gt; raise ValidationError(\n        ...     \"Invalid risk level\",\n        ...     details={\"field\": \"risk_level\", \"value\": \"UNKNOWN\"}\n        ... )\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        details: Optional[Dict[str, Any]] = None,\n        field: Optional[str] = None,\n        value: Optional[Any] = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize a ValidationError.\n\n        Args:\n            message: Human-readable error description.\n            details: Optional dictionary with additional context.\n            field: Optional name of the field that failed validation.\n            value: Optional value that caused the validation failure.\n        \"\"\"\n        details = details or {}\n        if field:\n            details[\"field\"] = field\n        if value is not None:\n            details[\"value\"] = value\n        super().__init__(message, details)\n        self.field = field\n        self.value = value\n</code></pre>"},{"location":"api/core/#rotalabs_comply.core.exceptions.ValidationError.__init__","title":"__init__","text":"<pre><code>__init__(\n    message: str,\n    details: Optional[Dict[str, Any]] = None,\n    field: Optional[str] = None,\n    value: Optional[Any] = None,\n) -&gt; None\n</code></pre> <p>Initialize a ValidationError.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error description.</p> required <code>details</code> <code>Optional[Dict[str, Any]]</code> <p>Optional dictionary with additional context.</p> <code>None</code> <code>field</code> <code>Optional[str]</code> <p>Optional name of the field that failed validation.</p> <code>None</code> <code>value</code> <code>Optional[Any]</code> <p>Optional value that caused the validation failure.</p> <code>None</code> Source code in <code>src/rotalabs_comply/core/exceptions.py</code> <pre><code>def __init__(\n    self,\n    message: str,\n    details: Optional[Dict[str, Any]] = None,\n    field: Optional[str] = None,\n    value: Optional[Any] = None,\n) -&gt; None:\n    \"\"\"\n    Initialize a ValidationError.\n\n    Args:\n        message: Human-readable error description.\n        details: Optional dictionary with additional context.\n        field: Optional name of the field that failed validation.\n        value: Optional value that caused the validation failure.\n    \"\"\"\n    details = details or {}\n    if field:\n        details[\"field\"] = field\n    if value is not None:\n        details[\"value\"] = value\n    super().__init__(message, details)\n    self.field = field\n    self.value = value\n</code></pre>"},{"location":"api/core/#frameworkerror","title":"FrameworkError","text":"<p>Exception for framework-related failures.</p> <p>Additional Attributes:</p> Attribute Type Description <code>framework</code> <code>Optional[str]</code> Framework that caused the error <p>Raised when: - Unsupported framework operations - Framework rule validation fails - Framework configuration errors - Incompatible framework combinations</p>"},{"location":"api/core/#rotalabs_comply.core.exceptions.FrameworkError","title":"FrameworkError","text":"<p>Exception raised for regulatory framework-related failures.</p> <p>This exception is raised when there are issues with: - Unsupported framework operations - Framework rule validation - Framework configuration errors - Incompatible framework combinations</p> <p>Attributes:</p> Name Type Description <code>framework</code> <p>Optional identifier of the framework that caused the error.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; raise FrameworkError(\n...     \"Framework not supported\",\n...     details={\"framework\": \"UNKNOWN_FRAMEWORK\"}\n... )\n</code></pre> Source code in <code>src/rotalabs_comply/core/exceptions.py</code> <pre><code>class FrameworkError(ComplianceError):\n    \"\"\"\n    Exception raised for regulatory framework-related failures.\n\n    This exception is raised when there are issues with:\n    - Unsupported framework operations\n    - Framework rule validation\n    - Framework configuration errors\n    - Incompatible framework combinations\n\n    Attributes:\n        framework: Optional identifier of the framework that caused the error.\n\n    Examples:\n        &gt;&gt;&gt; raise FrameworkError(\n        ...     \"Framework not supported\",\n        ...     details={\"framework\": \"UNKNOWN_FRAMEWORK\"}\n        ... )\n    \"\"\"\n\n    def __init__(\n        self,\n        message: str,\n        details: Optional[Dict[str, Any]] = None,\n        framework: Optional[str] = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize a FrameworkError.\n\n        Args:\n            message: Human-readable error description.\n            details: Optional dictionary with additional context.\n            framework: Optional identifier of the framework that caused the error.\n        \"\"\"\n        details = details or {}\n        if framework:\n            details[\"framework\"] = framework\n        super().__init__(message, details)\n        self.framework = framework\n</code></pre>"},{"location":"api/core/#rotalabs_comply.core.exceptions.FrameworkError.__init__","title":"__init__","text":"<pre><code>__init__(\n    message: str,\n    details: Optional[Dict[str, Any]] = None,\n    framework: Optional[str] = None,\n) -&gt; None\n</code></pre> <p>Initialize a FrameworkError.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <code>str</code> <p>Human-readable error description.</p> required <code>details</code> <code>Optional[Dict[str, Any]]</code> <p>Optional dictionary with additional context.</p> <code>None</code> <code>framework</code> <code>Optional[str]</code> <p>Optional identifier of the framework that caused the error.</p> <code>None</code> Source code in <code>src/rotalabs_comply/core/exceptions.py</code> <pre><code>def __init__(\n    self,\n    message: str,\n    details: Optional[Dict[str, Any]] = None,\n    framework: Optional[str] = None,\n) -&gt; None:\n    \"\"\"\n    Initialize a FrameworkError.\n\n    Args:\n        message: Human-readable error description.\n        details: Optional dictionary with additional context.\n        framework: Optional identifier of the framework that caused the error.\n    \"\"\"\n    details = details or {}\n    if framework:\n        details[\"framework\"] = framework\n    super().__init__(message, details)\n    self.framework = framework\n</code></pre>"},{"location":"api/frameworks/","title":"Frameworks Module","text":"<p>Compliance framework implementations for EU AI Act, SOC2, HIPAA, GDPR, NIST AI RMF, ISO 42001, and MAS FEAT.</p>"},{"location":"api/frameworks/#base-types","title":"Base Types","text":""},{"location":"api/frameworks/#compliancerule","title":"ComplianceRule","text":"<p>Definition of a single compliance rule within a framework.</p> <p>Attributes:</p> Attribute Type Description <code>rule_id</code> <code>str</code> Unique identifier within framework <code>name</code> <code>str</code> Human-readable name <code>description</code> <code>str</code> Detailed requirement description <code>severity</code> <code>RiskLevel</code> Default severity for violations <code>category</code> <code>str</code> Category grouping <code>check_fn</code> <code>Optional[Callable]</code> Custom check function <code>remediation</code> <code>str</code> Default remediation guidance <code>references</code> <code>List[str]</code> External references <p>Example:</p> <pre><code>from rotalabs_comply.frameworks.base import ComplianceRule, RiskLevel\n\nrule = ComplianceRule(\n    rule_id=\"CUSTOM-001\",\n    name=\"Custom Requirement\",\n    description=\"Description of what's required\",\n    severity=RiskLevel.MEDIUM,\n    category=\"custom\",\n    remediation=\"How to fix violations\",\n    references=[\"Internal Policy 1.2.3\"],\n)\n</code></pre>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.base.ComplianceRule","title":"ComplianceRule  <code>dataclass</code>","text":"<p>Definition of a single compliance rule within a framework.</p> <p>Rules represent specific regulatory requirements that AI systems must satisfy. Each rule has an associated check function that evaluates audit entries for compliance.</p> <p>Attributes:</p> Name Type Description <code>rule_id</code> <code>str</code> <p>Unique identifier for this rule within the framework</p> <code>name</code> <code>str</code> <p>Human-readable name of the rule</p> <code>description</code> <code>str</code> <p>Detailed description of the requirement</p> <code>severity</code> <code>RiskLevel</code> <p>Default severity level for violations of this rule</p> <code>category</code> <code>str</code> <p>Category grouping for the rule</p> <code>check_fn</code> <code>Optional[Callable[[AuditEntry], bool]]</code> <p>Optional custom check function for specialized validation</p> <code>remediation</code> <code>str</code> <p>Default remediation guidance for violations</p> <code>references</code> <code>List[str]</code> <p>External references (regulation sections, standards, etc.)</p> Source code in <code>src/rotalabs_comply/frameworks/base.py</code> <pre><code>@dataclass\nclass ComplianceRule:\n    \"\"\"\n    Definition of a single compliance rule within a framework.\n\n    Rules represent specific regulatory requirements that AI systems\n    must satisfy. Each rule has an associated check function that\n    evaluates audit entries for compliance.\n\n    Attributes:\n        rule_id: Unique identifier for this rule within the framework\n        name: Human-readable name of the rule\n        description: Detailed description of the requirement\n        severity: Default severity level for violations of this rule\n        category: Category grouping for the rule\n        check_fn: Optional custom check function for specialized validation\n        remediation: Default remediation guidance for violations\n        references: External references (regulation sections, standards, etc.)\n    \"\"\"\n    rule_id: str\n    name: str\n    description: str\n    severity: RiskLevel\n    category: str\n    check_fn: Optional[Callable[[AuditEntry], bool]] = None\n    remediation: str = \"\"\n    references: List[str] = field(default_factory=list)\n</code></pre>"},{"location":"api/frameworks/#complianceframework-protocol","title":"ComplianceFramework Protocol","text":"<p>Protocol defining the interface for compliance frameworks.</p> <p>Properties:</p> Property Type Description <code>name</code> <code>str</code> Framework name <code>version</code> <code>str</code> Framework version <code>rules</code> <code>List[ComplianceRule]</code> All rules <p>Methods:</p> Method Signature Description <code>check</code> <code>async (entry, profile) -&gt; ComplianceCheckResult</code> Check entry <code>get_rule</code> <code>(rule_id: str) -&gt; Optional[ComplianceRule]</code> Get rule by ID <code>list_categories</code> <code>() -&gt; List[str]</code> List categories"},{"location":"api/frameworks/#rotalabs_comply.frameworks.base.ComplianceFramework","title":"ComplianceFramework","text":"<p>Protocol defining the interface for compliance frameworks.</p> <p>All compliance frameworks must implement this protocol to ensure consistent behavior across different regulatory standards.</p> <p>Frameworks evaluate audit entries against their rules and produce compliance check results with any violations found.</p> Source code in <code>src/rotalabs_comply/frameworks/base.py</code> <pre><code>@runtime_checkable\nclass ComplianceFramework(Protocol):\n    \"\"\"\n    Protocol defining the interface for compliance frameworks.\n\n    All compliance frameworks must implement this protocol to ensure\n    consistent behavior across different regulatory standards.\n\n    Frameworks evaluate audit entries against their rules and produce\n    compliance check results with any violations found.\n    \"\"\"\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"\n        Get the name of this compliance framework.\n\n        Returns:\n            Human-readable name (e.g., \"EU AI Act\", \"SOC2 Type II\")\n        \"\"\"\n        ...\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"\n        Get the version of the framework being implemented.\n\n        Returns:\n            Version string (e.g., \"2024\", \"2017\")\n        \"\"\"\n        ...\n\n    @property\n    def rules(self) -&gt; List[ComplianceRule]:\n        \"\"\"\n        Get all rules defined in this framework.\n\n        Returns:\n            List of all compliance rules\n        \"\"\"\n        ...\n\n    async def check(\n        self, entry: AuditEntry, profile: ComplianceProfile\n    ) -&gt; ComplianceCheckResult:\n        \"\"\"\n        Check an audit entry for compliance violations.\n\n        Evaluates the entry against all applicable rules based on\n        the provided compliance profile.\n\n        Args:\n            entry: The audit entry to evaluate\n            profile: Configuration profile controlling evaluation\n\n        Returns:\n            ComplianceCheckResult containing any violations found\n        \"\"\"\n        ...\n\n    def get_rule(self, rule_id: str) -&gt; Optional[ComplianceRule]:\n        \"\"\"\n        Get a specific rule by its ID.\n\n        Args:\n            rule_id: The unique identifier of the rule\n\n        Returns:\n            The ComplianceRule if found, None otherwise\n        \"\"\"\n        ...\n\n    def list_categories(self) -&gt; List[str]:\n        \"\"\"\n        List all rule categories in this framework.\n\n        Returns:\n            List of unique category names\n        \"\"\"\n        ...\n</code></pre>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.base.ComplianceFramework.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>Get the name of this compliance framework.</p> <p>Returns:</p> Type Description <code>str</code> <p>Human-readable name (e.g., \"EU AI Act\", \"SOC2 Type II\")</p>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.base.ComplianceFramework.version","title":"version  <code>property</code>","text":"<pre><code>version: str\n</code></pre> <p>Get the version of the framework being implemented.</p> <p>Returns:</p> Type Description <code>str</code> <p>Version string (e.g., \"2024\", \"2017\")</p>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.base.ComplianceFramework.rules","title":"rules  <code>property</code>","text":"<pre><code>rules: List[ComplianceRule]\n</code></pre> <p>Get all rules defined in this framework.</p> <p>Returns:</p> Type Description <code>List[ComplianceRule]</code> <p>List of all compliance rules</p>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.base.ComplianceFramework.check","title":"check  <code>async</code>","text":"<pre><code>check(\n    entry: AuditEntry, profile: ComplianceProfile\n) -&gt; ComplianceCheckResult\n</code></pre> <p>Check an audit entry for compliance violations.</p> <p>Evaluates the entry against all applicable rules based on the provided compliance profile.</p> <p>Parameters:</p> Name Type Description Default <code>entry</code> <code>AuditEntry</code> <p>The audit entry to evaluate</p> required <code>profile</code> <code>ComplianceProfile</code> <p>Configuration profile controlling evaluation</p> required <p>Returns:</p> Type Description <code>ComplianceCheckResult</code> <p>ComplianceCheckResult containing any violations found</p> Source code in <code>src/rotalabs_comply/frameworks/base.py</code> <pre><code>async def check(\n    self, entry: AuditEntry, profile: ComplianceProfile\n) -&gt; ComplianceCheckResult:\n    \"\"\"\n    Check an audit entry for compliance violations.\n\n    Evaluates the entry against all applicable rules based on\n    the provided compliance profile.\n\n    Args:\n        entry: The audit entry to evaluate\n        profile: Configuration profile controlling evaluation\n\n    Returns:\n        ComplianceCheckResult containing any violations found\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.base.ComplianceFramework.get_rule","title":"get_rule","text":"<pre><code>get_rule(rule_id: str) -&gt; Optional[ComplianceRule]\n</code></pre> <p>Get a specific rule by its ID.</p> <p>Parameters:</p> Name Type Description Default <code>rule_id</code> <code>str</code> <p>The unique identifier of the rule</p> required <p>Returns:</p> Type Description <code>Optional[ComplianceRule]</code> <p>The ComplianceRule if found, None otherwise</p> Source code in <code>src/rotalabs_comply/frameworks/base.py</code> <pre><code>def get_rule(self, rule_id: str) -&gt; Optional[ComplianceRule]:\n    \"\"\"\n    Get a specific rule by its ID.\n\n    Args:\n        rule_id: The unique identifier of the rule\n\n    Returns:\n        The ComplianceRule if found, None otherwise\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.base.ComplianceFramework.list_categories","title":"list_categories","text":"<pre><code>list_categories() -&gt; List[str]\n</code></pre> <p>List all rule categories in this framework.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of unique category names</p> Source code in <code>src/rotalabs_comply/frameworks/base.py</code> <pre><code>def list_categories(self) -&gt; List[str]:\n    \"\"\"\n    List all rule categories in this framework.\n\n    Returns:\n        List of unique category names\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/frameworks/#baseframework","title":"BaseFramework","text":"<p>Abstract base class for compliance frameworks.</p>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.base.BaseFramework","title":"BaseFramework","text":"<p>Abstract base class for compliance frameworks.</p> <p>Provides common functionality for all framework implementations including rule management, category listing, and the main check loop. Subclasses must implement the _check_rule method to define framework-specific validation logic.</p> <p>Attributes:</p> Name Type Description <code>_name</code> <p>Framework name</p> <code>_version</code> <p>Framework version</p> <code>_rules</code> <p>List of rules in this framework</p> <code>_rules_by_id</code> <code>Dict[str, ComplianceRule]</code> <p>Dictionary mapping rule IDs to rules for fast lookup</p> Source code in <code>src/rotalabs_comply/frameworks/base.py</code> <pre><code>class BaseFramework(ABC):\n    \"\"\"\n    Abstract base class for compliance frameworks.\n\n    Provides common functionality for all framework implementations\n    including rule management, category listing, and the main check\n    loop. Subclasses must implement the _check_rule method to define\n    framework-specific validation logic.\n\n    Attributes:\n        _name: Framework name\n        _version: Framework version\n        _rules: List of rules in this framework\n        _rules_by_id: Dictionary mapping rule IDs to rules for fast lookup\n    \"\"\"\n\n    def __init__(self, name: str, version: str, rules: List[ComplianceRule]):\n        \"\"\"\n        Initialize the base framework.\n\n        Args:\n            name: Human-readable framework name\n            version: Framework version string\n            rules: List of compliance rules\n        \"\"\"\n        self._name = name\n        self._version = version\n        self._rules = rules\n        self._rules_by_id: Dict[str, ComplianceRule] = {\n            rule.rule_id: rule for rule in rules\n        }\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"Get the framework name.\"\"\"\n        return self._name\n\n    @property\n    def version(self) -&gt; str:\n        \"\"\"Get the framework version.\"\"\"\n        return self._version\n\n    @property\n    def rules(self) -&gt; List[ComplianceRule]:\n        \"\"\"Get all rules in this framework.\"\"\"\n        return self._rules\n\n    def get_rule(self, rule_id: str) -&gt; Optional[ComplianceRule]:\n        \"\"\"\n        Get a specific rule by its ID.\n\n        Args:\n            rule_id: The unique identifier of the rule\n\n        Returns:\n            The ComplianceRule if found, None otherwise\n        \"\"\"\n        return self._rules_by_id.get(rule_id)\n\n    def list_categories(self) -&gt; List[str]:\n        \"\"\"\n        List all unique rule categories in this framework.\n\n        Returns:\n            Sorted list of unique category names\n        \"\"\"\n        categories = set(rule.category for rule in self._rules)\n        return sorted(categories)\n\n    async def check(\n        self, entry: AuditEntry, profile: ComplianceProfile\n    ) -&gt; ComplianceCheckResult:\n        \"\"\"\n        Check an audit entry for compliance violations.\n\n        Evaluates the entry against all applicable rules based on\n        the provided compliance profile, respecting category filters\n        and excluded rules.\n\n        Args:\n            entry: The audit entry to evaluate\n            profile: Configuration profile controlling evaluation\n\n        Returns:\n            ComplianceCheckResult containing any violations found\n        \"\"\"\n        violations: List[ComplianceViolation] = []\n        rules_checked = 0\n\n        for rule in self._rules:\n            # Skip excluded rules\n            if rule.rule_id in profile.excluded_rules:\n                continue\n\n            # Filter by category if specified\n            if profile.enabled_categories and rule.category not in profile.enabled_categories:\n                continue\n\n            # Filter by minimum severity\n            severity_order = [\n                RiskLevel.INFO,\n                RiskLevel.LOW,\n                RiskLevel.MEDIUM,\n                RiskLevel.HIGH,\n                RiskLevel.CRITICAL,\n            ]\n            if severity_order.index(rule.severity) &lt; severity_order.index(profile.min_severity):\n                continue\n\n            rules_checked += 1\n\n            # Check the rule\n            violation = self._check_rule(entry, rule)\n            if violation is not None:\n                violations.append(violation)\n\n        return ComplianceCheckResult(\n            entry_id=entry.entry_id,\n            framework=self._name,\n            framework_version=self._version,\n            timestamp=datetime.utcnow(),\n            violations=violations,\n            rules_checked=rules_checked,\n            rules_passed=rules_checked - len(violations),\n            is_compliant=len(violations) == 0,\n        )\n\n    @abstractmethod\n    def _check_rule(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check a single rule against an audit entry.\n\n        This method must be implemented by subclasses to define\n        framework-specific validation logic.\n\n        Args:\n            entry: The audit entry to check\n            rule: The rule to evaluate\n\n        Returns:\n            ComplianceViolation if the rule is violated, None otherwise\n        \"\"\"\n        ...\n</code></pre>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.base.BaseFramework.name","title":"name  <code>property</code>","text":"<pre><code>name: str\n</code></pre> <p>Get the framework name.</p>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.base.BaseFramework.version","title":"version  <code>property</code>","text":"<pre><code>version: str\n</code></pre> <p>Get the framework version.</p>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.base.BaseFramework.rules","title":"rules  <code>property</code>","text":"<pre><code>rules: List[ComplianceRule]\n</code></pre> <p>Get all rules in this framework.</p>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.base.BaseFramework.__init__","title":"__init__","text":"<pre><code>__init__(\n    name: str, version: str, rules: List[ComplianceRule]\n)\n</code></pre> <p>Initialize the base framework.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Human-readable framework name</p> required <code>version</code> <code>str</code> <p>Framework version string</p> required <code>rules</code> <code>List[ComplianceRule]</code> <p>List of compliance rules</p> required Source code in <code>src/rotalabs_comply/frameworks/base.py</code> <pre><code>def __init__(self, name: str, version: str, rules: List[ComplianceRule]):\n    \"\"\"\n    Initialize the base framework.\n\n    Args:\n        name: Human-readable framework name\n        version: Framework version string\n        rules: List of compliance rules\n    \"\"\"\n    self._name = name\n    self._version = version\n    self._rules = rules\n    self._rules_by_id: Dict[str, ComplianceRule] = {\n        rule.rule_id: rule for rule in rules\n    }\n</code></pre>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.base.BaseFramework.get_rule","title":"get_rule","text":"<pre><code>get_rule(rule_id: str) -&gt; Optional[ComplianceRule]\n</code></pre> <p>Get a specific rule by its ID.</p> <p>Parameters:</p> Name Type Description Default <code>rule_id</code> <code>str</code> <p>The unique identifier of the rule</p> required <p>Returns:</p> Type Description <code>Optional[ComplianceRule]</code> <p>The ComplianceRule if found, None otherwise</p> Source code in <code>src/rotalabs_comply/frameworks/base.py</code> <pre><code>def get_rule(self, rule_id: str) -&gt; Optional[ComplianceRule]:\n    \"\"\"\n    Get a specific rule by its ID.\n\n    Args:\n        rule_id: The unique identifier of the rule\n\n    Returns:\n        The ComplianceRule if found, None otherwise\n    \"\"\"\n    return self._rules_by_id.get(rule_id)\n</code></pre>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.base.BaseFramework.list_categories","title":"list_categories","text":"<pre><code>list_categories() -&gt; List[str]\n</code></pre> <p>List all unique rule categories in this framework.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>Sorted list of unique category names</p> Source code in <code>src/rotalabs_comply/frameworks/base.py</code> <pre><code>def list_categories(self) -&gt; List[str]:\n    \"\"\"\n    List all unique rule categories in this framework.\n\n    Returns:\n        Sorted list of unique category names\n    \"\"\"\n    categories = set(rule.category for rule in self._rules)\n    return sorted(categories)\n</code></pre>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.base.BaseFramework.check","title":"check  <code>async</code>","text":"<pre><code>check(\n    entry: AuditEntry, profile: ComplianceProfile\n) -&gt; ComplianceCheckResult\n</code></pre> <p>Check an audit entry for compliance violations.</p> <p>Evaluates the entry against all applicable rules based on the provided compliance profile, respecting category filters and excluded rules.</p> <p>Parameters:</p> Name Type Description Default <code>entry</code> <code>AuditEntry</code> <p>The audit entry to evaluate</p> required <code>profile</code> <code>ComplianceProfile</code> <p>Configuration profile controlling evaluation</p> required <p>Returns:</p> Type Description <code>ComplianceCheckResult</code> <p>ComplianceCheckResult containing any violations found</p> Source code in <code>src/rotalabs_comply/frameworks/base.py</code> <pre><code>async def check(\n    self, entry: AuditEntry, profile: ComplianceProfile\n) -&gt; ComplianceCheckResult:\n    \"\"\"\n    Check an audit entry for compliance violations.\n\n    Evaluates the entry against all applicable rules based on\n    the provided compliance profile, respecting category filters\n    and excluded rules.\n\n    Args:\n        entry: The audit entry to evaluate\n        profile: Configuration profile controlling evaluation\n\n    Returns:\n        ComplianceCheckResult containing any violations found\n    \"\"\"\n    violations: List[ComplianceViolation] = []\n    rules_checked = 0\n\n    for rule in self._rules:\n        # Skip excluded rules\n        if rule.rule_id in profile.excluded_rules:\n            continue\n\n        # Filter by category if specified\n        if profile.enabled_categories and rule.category not in profile.enabled_categories:\n            continue\n\n        # Filter by minimum severity\n        severity_order = [\n            RiskLevel.INFO,\n            RiskLevel.LOW,\n            RiskLevel.MEDIUM,\n            RiskLevel.HIGH,\n            RiskLevel.CRITICAL,\n        ]\n        if severity_order.index(rule.severity) &lt; severity_order.index(profile.min_severity):\n            continue\n\n        rules_checked += 1\n\n        # Check the rule\n        violation = self._check_rule(entry, rule)\n        if violation is not None:\n            violations.append(violation)\n\n    return ComplianceCheckResult(\n        entry_id=entry.entry_id,\n        framework=self._name,\n        framework_version=self._version,\n        timestamp=datetime.utcnow(),\n        violations=violations,\n        rules_checked=rules_checked,\n        rules_passed=rules_checked - len(violations),\n        is_compliant=len(violations) == 0,\n    )\n</code></pre>"},{"location":"api/frameworks/#constructor","title":"Constructor","text":"<pre><code>BaseFramework(name: str, version: str, rules: List[ComplianceRule])\n</code></pre>"},{"location":"api/frameworks/#abstract-method","title":"Abstract Method","text":"<p>Subclasses must implement:</p> <pre><code>def _check_rule(\n    self, entry: AuditEntry, rule: ComplianceRule\n) -&gt; Optional[ComplianceViolation]\n</code></pre> <p>Example Custom Framework:</p> <pre><code>from rotalabs_comply.frameworks.base import BaseFramework, ComplianceRule, RiskLevel\n\nclass MyFramework(BaseFramework):\n    def __init__(self):\n        rules = [\n            ComplianceRule(\n                rule_id=\"MY-001\",\n                name=\"My Rule\",\n                description=\"Description\",\n                severity=RiskLevel.MEDIUM,\n                category=\"custom\",\n            ),\n        ]\n        super().__init__(\"My Framework\", \"1.0\", rules)\n\n    def _check_rule(self, entry, rule):\n        if rule.rule_id == \"MY-001\":\n            if not entry.metadata.get(\"my_field\"):\n                return self._create_violation(entry, rule, \"my_field missing\")\n        return None\n</code></pre>"},{"location":"api/frameworks/#auditentry-frameworks","title":"AuditEntry (Frameworks)","text":"<p>Audit entry structure used by frameworks for compliance checking.</p> <p>Attributes:</p> Attribute Type Default Description <code>entry_id</code> <code>str</code> Required Unique identifier <code>timestamp</code> <code>datetime</code> Required Event time <code>event_type</code> <code>str</code> Required Type of event <code>actor</code> <code>str</code> Required Who triggered event <code>action</code> <code>str</code> Required Action description <code>resource</code> <code>str</code> <code>\"\"</code> Resource accessed <code>metadata</code> <code>Dict[str, Any]</code> <code>{}</code> Additional context <code>risk_level</code> <code>RiskLevel</code> <code>LOW</code> Risk classification <code>system_id</code> <code>str</code> <code>\"\"</code> AI system identifier <code>data_classification</code> <code>str</code> <code>\"unclassified\"</code> Data sensitivity <code>user_notified</code> <code>bool</code> <code>False</code> User knows about AI <code>human_oversight</code> <code>bool</code> <code>False</code> Human oversight present <code>error_handled</code> <code>bool</code> <code>True</code> Errors handled gracefully <code>documentation_ref</code> <code>Optional[str]</code> <code>None</code> Documentation reference"},{"location":"api/frameworks/#rotalabs_comply.frameworks.base.AuditEntry","title":"AuditEntry  <code>dataclass</code>","text":"<p>Represents a single audit log entry for an AI system interaction.</p> <p>Audit entries capture the essential metadata about AI system operations that compliance frameworks need to evaluate against regulatory requirements.</p> <p>Attributes:</p> Name Type Description <code>entry_id</code> <code>str</code> <p>Unique identifier for this audit entry</p> <code>timestamp</code> <code>datetime</code> <p>When the event occurred</p> <code>event_type</code> <code>str</code> <p>Type of event (e.g., \"inference\", \"training\", \"data_access\")</p> <code>actor</code> <code>str</code> <p>Identifier for the user, system, or agent that triggered the event</p> <code>action</code> <code>str</code> <p>Description of the action taken</p> <code>resource</code> <code>str</code> <p>The resource being accessed or modified</p> <code>metadata</code> <code>Dict[str, Any]</code> <p>Additional context-specific information about the event</p> <code>risk_level</code> <code>RiskLevel</code> <p>Assessed risk level of this operation</p> <code>system_id</code> <code>str</code> <p>Identifier for the AI system involved</p> <code>data_classification</code> <code>str</code> <p>Classification of data involved (e.g., \"PII\", \"PHI\", \"public\")</p> <code>user_notified</code> <code>bool</code> <p>Whether the user was notified about AI involvement</p> <code>human_oversight</code> <code>bool</code> <p>Whether human oversight was present</p> <code>error_handled</code> <code>bool</code> <p>Whether errors were handled gracefully</p> <code>documentation_ref</code> <code>Optional[str]</code> <p>Reference to related technical documentation</p> Source code in <code>src/rotalabs_comply/frameworks/base.py</code> <pre><code>@dataclass\nclass AuditEntry:\n    \"\"\"\n    Represents a single audit log entry for an AI system interaction.\n\n    Audit entries capture the essential metadata about AI system operations\n    that compliance frameworks need to evaluate against regulatory requirements.\n\n    Attributes:\n        entry_id: Unique identifier for this audit entry\n        timestamp: When the event occurred\n        event_type: Type of event (e.g., \"inference\", \"training\", \"data_access\")\n        actor: Identifier for the user, system, or agent that triggered the event\n        action: Description of the action taken\n        resource: The resource being accessed or modified\n        metadata: Additional context-specific information about the event\n        risk_level: Assessed risk level of this operation\n        system_id: Identifier for the AI system involved\n        data_classification: Classification of data involved (e.g., \"PII\", \"PHI\", \"public\")\n        user_notified: Whether the user was notified about AI involvement\n        human_oversight: Whether human oversight was present\n        error_handled: Whether errors were handled gracefully\n        documentation_ref: Reference to related technical documentation\n    \"\"\"\n    entry_id: str\n    timestamp: datetime\n    event_type: str\n    actor: str\n    action: str\n    resource: str = \"\"\n    metadata: Dict[str, Any] = field(default_factory=dict)\n    risk_level: RiskLevel = RiskLevel.LOW\n    system_id: str = \"\"\n    data_classification: str = \"unclassified\"\n    user_notified: bool = False\n    human_oversight: bool = False\n    error_handled: bool = True\n    documentation_ref: Optional[str] = None\n</code></pre>"},{"location":"api/frameworks/#complianceprofile-frameworks","title":"ComplianceProfile (Frameworks)","text":"<p>Configuration profile for compliance evaluation.</p> <p>Attributes:</p> Attribute Type Default Description <code>profile_id</code> <code>str</code> Required Unique identifier <code>name</code> <code>str</code> Required Profile name <code>description</code> <code>str</code> <code>\"\"</code> Profile description <code>enabled_frameworks</code> <code>List[str]</code> <code>[]</code> Frameworks to evaluate <code>enabled_categories</code> <code>List[str]</code> <code>[]</code> Categories to check <code>min_severity</code> <code>RiskLevel</code> <code>LOW</code> Minimum severity to report <code>system_classification</code> <code>str</code> <code>\"standard\"</code> System classification <code>custom_rules</code> <code>List[str]</code> <code>[]</code> Additional rule IDs <code>excluded_rules</code> <code>List[str]</code> <code>[]</code> Rules to skip <code>metadata</code> <code>Dict[str, Any]</code> <code>{}</code> Additional config"},{"location":"api/frameworks/#rotalabs_comply.frameworks.base.ComplianceProfile","title":"ComplianceProfile  <code>dataclass</code>","text":"<p>Configuration profile for compliance evaluation.</p> <p>Profiles define which rules to apply, severity thresholds, and system-specific compliance requirements.</p> <p>Attributes:</p> Name Type Description <code>profile_id</code> <code>str</code> <p>Unique identifier for this profile</p> <code>name</code> <code>str</code> <p>Human-readable profile name</p> <code>description</code> <code>str</code> <p>Detailed description of the profile's purpose</p> <code>enabled_frameworks</code> <code>List[str]</code> <p>List of framework names to evaluate against</p> <code>enabled_categories</code> <code>List[str]</code> <p>Categories of rules to check (empty = all)</p> <code>min_severity</code> <code>RiskLevel</code> <p>Minimum severity level to report</p> <code>system_classification</code> <code>str</code> <p>Classification of the AI system being evaluated</p> <code>custom_rules</code> <code>List[str]</code> <p>Additional custom rule IDs to include</p> <code>excluded_rules</code> <code>List[str]</code> <p>Rule IDs to exclude from evaluation</p> <code>metadata</code> <code>Dict[str, Any]</code> <p>Additional profile configuration</p> Source code in <code>src/rotalabs_comply/frameworks/base.py</code> <pre><code>@dataclass\nclass ComplianceProfile:\n    \"\"\"\n    Configuration profile for compliance evaluation.\n\n    Profiles define which rules to apply, severity thresholds, and\n    system-specific compliance requirements.\n\n    Attributes:\n        profile_id: Unique identifier for this profile\n        name: Human-readable profile name\n        description: Detailed description of the profile's purpose\n        enabled_frameworks: List of framework names to evaluate against\n        enabled_categories: Categories of rules to check (empty = all)\n        min_severity: Minimum severity level to report\n        system_classification: Classification of the AI system being evaluated\n        custom_rules: Additional custom rule IDs to include\n        excluded_rules: Rule IDs to exclude from evaluation\n        metadata: Additional profile configuration\n    \"\"\"\n    profile_id: str\n    name: str\n    description: str = \"\"\n    enabled_frameworks: List[str] = field(default_factory=list)\n    enabled_categories: List[str] = field(default_factory=list)\n    min_severity: RiskLevel = RiskLevel.LOW\n    system_classification: str = \"standard\"\n    custom_rules: List[str] = field(default_factory=list)\n    excluded_rules: List[str] = field(default_factory=list)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n</code></pre>"},{"location":"api/frameworks/#complianceviolation-frameworks","title":"ComplianceViolation (Frameworks)","text":"<p>A compliance violation detected during evaluation.</p> <p>Attributes:</p> Attribute Type Description <code>rule_id</code> <code>str</code> Violated rule ID <code>rule_name</code> <code>str</code> Rule name <code>severity</code> <code>RiskLevel</code> Violation severity <code>description</code> <code>str</code> Rule description <code>evidence</code> <code>str</code> Specific evidence <code>remediation</code> <code>str</code> How to fix <code>entry_id</code> <code>str</code> Entry that triggered <code>category</code> <code>str</code> Rule category <code>framework</code> <code>str</code> Framework name"},{"location":"api/frameworks/#rotalabs_comply.frameworks.base.ComplianceViolation","title":"ComplianceViolation  <code>dataclass</code>","text":"<p>Represents a single compliance violation detected during evaluation.</p> <p>Violations are the output of rule checks that identify non-compliance with regulatory requirements.</p> <p>Attributes:</p> Name Type Description <code>rule_id</code> <code>str</code> <p>ID of the rule that was violated</p> <code>rule_name</code> <code>str</code> <p>Human-readable name of the violated rule</p> <code>severity</code> <code>RiskLevel</code> <p>Severity level of the violation</p> <code>description</code> <code>str</code> <p>Detailed description of what was violated</p> <code>evidence</code> <code>str</code> <p>Specific evidence from the audit entry</p> <code>remediation</code> <code>str</code> <p>Suggested steps to remediate the violation</p> <code>entry_id</code> <code>str</code> <p>ID of the audit entry that triggered this violation</p> <code>category</code> <code>str</code> <p>Category of the violated rule</p> <code>framework</code> <code>str</code> <p>Name of the framework containing the rule</p> Source code in <code>src/rotalabs_comply/frameworks/base.py</code> <pre><code>@dataclass\nclass ComplianceViolation:\n    \"\"\"\n    Represents a single compliance violation detected during evaluation.\n\n    Violations are the output of rule checks that identify non-compliance\n    with regulatory requirements.\n\n    Attributes:\n        rule_id: ID of the rule that was violated\n        rule_name: Human-readable name of the violated rule\n        severity: Severity level of the violation\n        description: Detailed description of what was violated\n        evidence: Specific evidence from the audit entry\n        remediation: Suggested steps to remediate the violation\n        entry_id: ID of the audit entry that triggered this violation\n        category: Category of the violated rule\n        framework: Name of the framework containing the rule\n    \"\"\"\n    rule_id: str\n    rule_name: str\n    severity: RiskLevel\n    description: str\n    evidence: str\n    remediation: str\n    entry_id: str\n    category: str\n    framework: str\n</code></pre>"},{"location":"api/frameworks/#compliancecheckresult-frameworks","title":"ComplianceCheckResult (Frameworks)","text":"<p>Result of a compliance check against an audit entry.</p> <p>Attributes:</p> Attribute Type Description <code>entry_id</code> <code>str</code> Checked entry ID <code>framework</code> <code>str</code> Framework name <code>framework_version</code> <code>str</code> Framework version <code>timestamp</code> <code>datetime</code> Check time <code>violations</code> <code>List[ComplianceViolation]</code> Violations found <code>rules_checked</code> <code>int</code> Total rules evaluated <code>rules_passed</code> <code>int</code> Rules that passed <code>is_compliant</code> <code>bool</code> No violations found <code>metadata</code> <code>Dict[str, Any]</code> Additional data"},{"location":"api/frameworks/#rotalabs_comply.frameworks.base.ComplianceCheckResult","title":"ComplianceCheckResult  <code>dataclass</code>","text":"<p>Result of a compliance check against an audit entry.</p> <p>Contains all violations found, along with summary statistics about the compliance evaluation.</p> <p>Attributes:</p> Name Type Description <code>entry_id</code> <code>str</code> <p>ID of the audit entry that was checked</p> <code>framework</code> <code>str</code> <p>Name of the framework used for evaluation</p> <code>framework_version</code> <code>str</code> <p>Version of the framework</p> <code>timestamp</code> <code>datetime</code> <p>When the check was performed</p> <code>violations</code> <code>List[ComplianceViolation]</code> <p>List of all violations found</p> <code>rules_checked</code> <code>int</code> <p>Total number of rules evaluated</p> <code>rules_passed</code> <code>int</code> <p>Number of rules that passed</p> <code>is_compliant</code> <code>bool</code> <p>Whether the entry is fully compliant (no violations)</p> <code>metadata</code> <code>Dict[str, Any]</code> <p>Additional check result metadata</p> Source code in <code>src/rotalabs_comply/frameworks/base.py</code> <pre><code>@dataclass\nclass ComplianceCheckResult:\n    \"\"\"\n    Result of a compliance check against an audit entry.\n\n    Contains all violations found, along with summary statistics\n    about the compliance evaluation.\n\n    Attributes:\n        entry_id: ID of the audit entry that was checked\n        framework: Name of the framework used for evaluation\n        framework_version: Version of the framework\n        timestamp: When the check was performed\n        violations: List of all violations found\n        rules_checked: Total number of rules evaluated\n        rules_passed: Number of rules that passed\n        is_compliant: Whether the entry is fully compliant (no violations)\n        metadata: Additional check result metadata\n    \"\"\"\n    entry_id: str\n    framework: str\n    framework_version: str\n    timestamp: datetime\n    violations: List[ComplianceViolation] = field(default_factory=list)\n    rules_checked: int = 0\n    rules_passed: int = 0\n    is_compliant: bool = True\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n    def __post_init__(self):\n        \"\"\"Update is_compliant based on violations.\"\"\"\n        self.is_compliant = len(self.violations) == 0\n</code></pre>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.base.ComplianceCheckResult.__post_init__","title":"__post_init__","text":"<pre><code>__post_init__()\n</code></pre> <p>Update is_compliant based on violations.</p> Source code in <code>src/rotalabs_comply/frameworks/base.py</code> <pre><code>def __post_init__(self):\n    \"\"\"Update is_compliant based on violations.\"\"\"\n    self.is_compliant = len(self.violations) == 0\n</code></pre>"},{"location":"api/frameworks/#eu-ai-act-framework","title":"EU AI Act Framework","text":"<p>EU AI Act (2024) compliance framework.</p>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.eu_ai_act.EUAIActFramework","title":"EUAIActFramework","text":"<p>EU AI Act compliance framework.</p> <p>Implements compliance checks based on the EU AI Act (2024) requirements for high-risk AI systems. The framework evaluates audit entries against the Act's requirements for transparency, human oversight, risk management, documentation, and security.</p> <p>The EU AI Act classifies AI systems into risk categories: - Unacceptable risk: Prohibited systems - High-risk: Systems subject to strict requirements (this framework's focus) - Limited risk: Systems with transparency obligations - Minimal risk: Most AI systems with few requirements</p> <p>This implementation focuses on high-risk system requirements as they represent the most comprehensive compliance obligations.</p> Example <p>framework = EUAIActFramework() result = await framework.check(entry, profile) if not result.is_compliant: ...     for violation in result.violations: ...         print(f\"{violation.rule_id}: {violation.description}\")</p> Source code in <code>src/rotalabs_comply/frameworks/eu_ai_act.py</code> <pre><code>class EUAIActFramework(BaseFramework):\n    \"\"\"\n    EU AI Act compliance framework.\n\n    Implements compliance checks based on the EU AI Act (2024) requirements\n    for high-risk AI systems. The framework evaluates audit entries against\n    the Act's requirements for transparency, human oversight, risk management,\n    documentation, and security.\n\n    The EU AI Act classifies AI systems into risk categories:\n    - Unacceptable risk: Prohibited systems\n    - High-risk: Systems subject to strict requirements (this framework's focus)\n    - Limited risk: Systems with transparency obligations\n    - Minimal risk: Most AI systems with few requirements\n\n    This implementation focuses on high-risk system requirements as they\n    represent the most comprehensive compliance obligations.\n\n    Example:\n        &gt;&gt;&gt; framework = EUAIActFramework()\n        &gt;&gt;&gt; result = await framework.check(entry, profile)\n        &gt;&gt;&gt; if not result.is_compliant:\n        ...     for violation in result.violations:\n        ...         print(f\"{violation.rule_id}: {violation.description}\")\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the EU AI Act framework with all defined rules.\"\"\"\n        rules = self._create_rules()\n        super().__init__(name=\"EU AI Act\", version=\"2024\", rules=rules)\n\n    def _create_rules(self) -&gt; List[ComplianceRule]:\n        \"\"\"\n        Create all EU AI Act compliance rules.\n\n        Returns:\n            List of ComplianceRule objects representing EU AI Act requirements\n        \"\"\"\n        return [\n            ComplianceRule(\n                rule_id=\"EUAI-001\",\n                name=\"Human Oversight Documentation\",\n                description=(\n                    \"High-risk AI systems shall be designed and developed in such a way \"\n                    \"that they can be effectively overseen by natural persons during the \"\n                    \"period in which they are in use. Human oversight shall aim to prevent \"\n                    \"or minimise the risks to health, safety or fundamental rights that may \"\n                    \"emerge when a high-risk AI system is used in accordance with its \"\n                    \"intended purpose or under conditions of reasonably foreseeable misuse. \"\n                    \"(Article 14)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"oversight\",\n                remediation=(\n                    \"Ensure human oversight mechanisms are in place and documented. \"\n                    \"Implement 'human-in-the-loop', 'human-on-the-loop', or \"\n                    \"'human-in-command' approaches as appropriate for the risk level.\"\n                ),\n                references=[\"EU AI Act Article 14\", \"Annex IV point 3\"],\n            ),\n            ComplianceRule(\n                rule_id=\"EUAI-002\",\n                name=\"Transparency - AI Interaction Notification\",\n                description=(\n                    \"Providers shall ensure that AI systems intended to interact directly \"\n                    \"with natural persons are designed and developed in such a way that \"\n                    \"the natural persons concerned are informed that they are interacting \"\n                    \"with an AI system, unless this is obvious from the circumstances and \"\n                    \"the context of use. (Article 50)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"transparency\",\n                remediation=(\n                    \"Implement clear notification mechanisms to inform users when they \"\n                    \"are interacting with an AI system. This notification should be \"\n                    \"provided before or at the start of the interaction.\"\n                ),\n                references=[\"EU AI Act Article 50(1)\"],\n            ),\n            ComplianceRule(\n                rule_id=\"EUAI-003\",\n                name=\"Risk Assessment for High-Risk Systems\",\n                description=(\n                    \"High-risk AI systems shall be subject to a risk management system \"\n                    \"consisting of a continuous iterative process planned and run \"\n                    \"throughout the entire lifecycle of a high-risk AI system, requiring \"\n                    \"regular systematic updating. It shall include identification, \"\n                    \"estimation, and evaluation of risks. (Article 9)\"\n                ),\n                severity=RiskLevel.CRITICAL,\n                category=\"risk_management\",\n                remediation=(\n                    \"Implement a comprehensive risk management system that identifies, \"\n                    \"analyzes, estimates, and evaluates risks throughout the AI system's \"\n                    \"lifecycle. Document all risk assessments and mitigation measures.\"\n                ),\n                references=[\"EU AI Act Article 9\", \"Annex IV point 2\"],\n            ),\n            ComplianceRule(\n                rule_id=\"EUAI-004\",\n                name=\"Technical Documentation Maintenance\",\n                description=(\n                    \"The technical documentation of a high-risk AI system shall be drawn \"\n                    \"up before that system is placed on the market or put into service \"\n                    \"and shall be kept up to date. Technical documentation shall contain \"\n                    \"at minimum the elements set out in Annex IV. (Article 11)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"documentation\",\n                remediation=(\n                    \"Maintain comprehensive technical documentation including: general \"\n                    \"description, detailed description of elements, development process, \"\n                    \"monitoring and functioning information, and description of \"\n                    \"appropriate human oversight measures.\"\n                ),\n                references=[\"EU AI Act Article 11\", \"Annex IV\"],\n            ),\n            ComplianceRule(\n                rule_id=\"EUAI-005\",\n                name=\"Data Governance - Training Data Documentation\",\n                description=(\n                    \"High-risk AI systems which make use of techniques involving the \"\n                    \"training of AI models with data shall be developed on the basis of \"\n                    \"training, validation and testing data sets that meet quality criteria. \"\n                    \"Training data must be documented regarding data collection, \"\n                    \"preparation, and assumptions. (Article 10)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"documentation\",\n                remediation=(\n                    \"Document all training, validation, and testing datasets including: \"\n                    \"data collection processes, data preparation operations (annotation, \"\n                    \"labeling, cleaning), relevant assumptions, prior assessment of \"\n                    \"availability, quantity and suitability of datasets, and examination \"\n                    \"of possible biases.\"\n                ),\n                references=[\"EU AI Act Article 10\", \"Annex IV point 2(d)\"],\n            ),\n            ComplianceRule(\n                rule_id=\"EUAI-006\",\n                name=\"Robustness - Error Handling\",\n                description=(\n                    \"High-risk AI systems shall be designed and developed in such a way \"\n                    \"that they achieve an appropriate level of robustness and that they \"\n                    \"can handle errors or inconsistencies during all lifecycle phases, \"\n                    \"including interaction with other systems. (Article 15)\"\n                ),\n                severity=RiskLevel.MEDIUM,\n                category=\"risk_management\",\n                remediation=(\n                    \"Implement robust error handling mechanisms including: graceful \"\n                    \"degradation, fallback procedures, and appropriate logging. Systems \"\n                    \"should continue to operate safely even when errors occur.\"\n                ),\n                references=[\"EU AI Act Article 15(1)(2)\"],\n            ),\n            ComplianceRule(\n                rule_id=\"EUAI-007\",\n                name=\"Accuracy Monitoring\",\n                description=(\n                    \"High-risk AI systems shall be designed and developed in such a way \"\n                    \"that they achieve an appropriate level of accuracy, robustness and \"\n                    \"cybersecurity. Accuracy levels shall be specified in the accompanying \"\n                    \"instructions of use and monitored throughout the system's lifecycle. \"\n                    \"(Article 15)\"\n                ),\n                severity=RiskLevel.MEDIUM,\n                category=\"risk_management\",\n                remediation=(\n                    \"Implement accuracy monitoring systems that track system performance \"\n                    \"over time. Document accuracy metrics in technical documentation and \"\n                    \"instructions for use. Establish thresholds for acceptable accuracy.\"\n                ),\n                references=[\"EU AI Act Article 15(1)\", \"Annex IV point 2(g)\"],\n            ),\n            ComplianceRule(\n                rule_id=\"EUAI-008\",\n                name=\"Cybersecurity Measures\",\n                description=(\n                    \"High-risk AI systems shall be designed and developed in such a way \"\n                    \"that they achieve an appropriate level of cybersecurity. The AI \"\n                    \"system shall be resilient against attempts by unauthorized third \"\n                    \"parties to alter its use, outputs or performance by exploiting \"\n                    \"system vulnerabilities. (Article 15)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"security\",\n                remediation=(\n                    \"Implement comprehensive cybersecurity measures including: access \"\n                    \"controls, input validation, adversarial robustness testing, and \"\n                    \"regular security assessments. Document security measures in \"\n                    \"technical documentation.\"\n                ),\n                references=[\"EU AI Act Article 15(4)(5)\"],\n            ),\n        ]\n\n    def _check_rule(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check a single EU AI Act rule against an audit entry.\n\n        Evaluates the audit entry against the specific rule requirements\n        and returns a violation if the entry does not comply.\n\n        Args:\n            entry: The audit entry to check\n            rule: The rule to evaluate\n\n        Returns:\n            ComplianceViolation if the rule is violated, None otherwise\n        \"\"\"\n        # Use custom check function if provided\n        if rule.check_fn is not None:\n            is_compliant = rule.check_fn(entry)\n            if not is_compliant:\n                return self._create_violation(entry, rule, \"Custom check failed\")\n            return None\n\n        # Framework-specific rule checks\n        if rule.rule_id == \"EUAI-001\":\n            return self._check_human_oversight(entry, rule)\n        elif rule.rule_id == \"EUAI-002\":\n            return self._check_transparency(entry, rule)\n        elif rule.rule_id == \"EUAI-003\":\n            return self._check_risk_assessment(entry, rule)\n        elif rule.rule_id == \"EUAI-004\":\n            return self._check_technical_documentation(entry, rule)\n        elif rule.rule_id == \"EUAI-005\":\n            return self._check_data_governance(entry, rule)\n        elif rule.rule_id == \"EUAI-006\":\n            return self._check_robustness(entry, rule)\n        elif rule.rule_id == \"EUAI-007\":\n            return self._check_accuracy_monitoring(entry, rule)\n        elif rule.rule_id == \"EUAI-008\":\n            return self._check_cybersecurity(entry, rule)\n\n        return None\n\n    def _check_human_oversight(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check EUAI-001: Human oversight documentation required for high-risk.\n\n        High-risk AI operations must have human oversight documented.\n        This is evaluated based on the risk_level and human_oversight flags.\n        \"\"\"\n        # Only applies to high-risk operations\n        if entry.risk_level not in (RiskLevel.HIGH, RiskLevel.CRITICAL):\n            return None\n\n        if not entry.human_oversight:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"High-risk operation (level={entry.risk_level.value}) performed \"\n                f\"without documented human oversight\",\n            )\n        return None\n\n    def _check_transparency(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check EUAI-002: Users must know they're interacting with AI.\n\n        User-facing interactions must include AI disclosure notification.\n        \"\"\"\n        # Check if this is a user-facing interaction\n        user_facing_events = {\"inference\", \"chat\", \"completion\", \"interaction\", \"response\"}\n        if entry.event_type.lower() not in user_facing_events:\n            return None\n\n        if not entry.user_notified:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"User-facing AI interaction (type={entry.event_type}) performed \"\n                f\"without notifying user of AI involvement\",\n            )\n        return None\n\n    def _check_risk_assessment(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check EUAI-003: Risk assessment required for high-risk systems.\n\n        High-risk operations must have risk assessment documentation.\n        \"\"\"\n        if entry.risk_level not in (RiskLevel.HIGH, RiskLevel.CRITICAL):\n            return None\n\n        # Check for risk assessment documentation in metadata\n        has_risk_assessment = entry.metadata.get(\"risk_assessment_documented\", False)\n        if not has_risk_assessment:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"High-risk operation (level={entry.risk_level.value}) performed \"\n                f\"without documented risk assessment\",\n            )\n        return None\n\n    def _check_technical_documentation(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check EUAI-004: Technical documentation must be maintained.\n\n        All operations should reference technical documentation.\n        \"\"\"\n        # Only check for significant operations\n        significant_events = {\"deployment\", \"training\", \"fine_tuning\", \"model_update\"}\n        if entry.event_type.lower() not in significant_events:\n            return None\n\n        if not entry.documentation_ref:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Significant operation (type={entry.event_type}) performed \"\n                f\"without reference to technical documentation\",\n            )\n        return None\n\n    def _check_data_governance(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check EUAI-005: Training data must be documented.\n\n        Training-related operations must document data governance.\n        \"\"\"\n        training_events = {\"training\", \"fine_tuning\", \"data_preparation\", \"data_ingestion\"}\n        if entry.event_type.lower() not in training_events:\n            return None\n\n        has_data_governance = entry.metadata.get(\"data_governance_documented\", False)\n        if not has_data_governance:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Training operation (type={entry.event_type}) performed \"\n                f\"without documented data governance\",\n            )\n        return None\n\n    def _check_robustness(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check EUAI-006: System must handle errors gracefully.\n\n        Operations should demonstrate proper error handling.\n        \"\"\"\n        if not entry.error_handled:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Operation (type={entry.event_type}) indicates error was not \"\n                f\"handled gracefully\",\n            )\n        return None\n\n    def _check_accuracy_monitoring(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check EUAI-007: Accuracy monitoring required.\n\n        Inference operations should include accuracy monitoring metadata.\n        \"\"\"\n        inference_events = {\"inference\", \"prediction\", \"completion\"}\n        if entry.event_type.lower() not in inference_events:\n            return None\n\n        has_accuracy_monitoring = entry.metadata.get(\"accuracy_monitored\", False)\n        if not has_accuracy_monitoring:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Inference operation (type={entry.event_type}) performed \"\n                f\"without accuracy monitoring\",\n            )\n        return None\n\n    def _check_cybersecurity(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check EUAI-008: Cybersecurity measures required.\n\n        Check for security-related metadata on operations.\n        \"\"\"\n        # Only check for operations that could have security implications\n        security_relevant_events = {\n            \"inference\", \"data_access\", \"model_access\", \"api_call\",\n            \"authentication\", \"data_export\"\n        }\n        if entry.event_type.lower() not in security_relevant_events:\n            return None\n\n        # Check for security metadata\n        has_security_check = entry.metadata.get(\"security_validated\", False)\n        has_access_control = entry.metadata.get(\"access_controlled\", False)\n\n        if not (has_security_check or has_access_control):\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Security-relevant operation (type={entry.event_type}) performed \"\n                f\"without documented cybersecurity validation\",\n            )\n        return None\n\n    def _create_violation(\n        self, entry: AuditEntry, rule: ComplianceRule, evidence: str\n    ) -&gt; ComplianceViolation:\n        \"\"\"\n        Create a compliance violation object.\n\n        Args:\n            entry: The audit entry that triggered the violation\n            rule: The rule that was violated\n            evidence: Specific evidence describing the violation\n\n        Returns:\n            ComplianceViolation object\n        \"\"\"\n        return ComplianceViolation(\n            rule_id=rule.rule_id,\n            rule_name=rule.name,\n            severity=rule.severity,\n            description=rule.description,\n            evidence=evidence,\n            remediation=rule.remediation,\n            entry_id=entry.entry_id,\n            category=rule.category,\n            framework=self._name,\n        )\n</code></pre>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.eu_ai_act.EUAIActFramework.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> <p>Initialize the EU AI Act framework with all defined rules.</p> Source code in <code>src/rotalabs_comply/frameworks/eu_ai_act.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize the EU AI Act framework with all defined rules.\"\"\"\n    rules = self._create_rules()\n    super().__init__(name=\"EU AI Act\", version=\"2024\", rules=rules)\n</code></pre>"},{"location":"api/frameworks/#categories","title":"Categories","text":"Category Description <code>transparency</code> User notification requirements <code>oversight</code> Human oversight requirements <code>risk_management</code> Risk assessment and handling <code>documentation</code> Technical documentation <code>security</code> Cybersecurity measures"},{"location":"api/frameworks/#rules","title":"Rules","text":"Rule ID Name Severity Category <code>EUAI-001</code> Human Oversight Documentation HIGH oversight <code>EUAI-002</code> AI Interaction Notification HIGH transparency <code>EUAI-003</code> Risk Assessment CRITICAL risk_management <code>EUAI-004</code> Technical Documentation HIGH documentation <code>EUAI-005</code> Data Governance HIGH documentation <code>EUAI-006</code> Error Handling MEDIUM risk_management <code>EUAI-007</code> Accuracy Monitoring MEDIUM risk_management <code>EUAI-008</code> Cybersecurity Measures HIGH security"},{"location":"api/frameworks/#usage","title":"Usage","text":"<pre><code>from rotalabs_comply.frameworks.eu_ai_act import EUAIActFramework\nfrom rotalabs_comply.frameworks.base import AuditEntry, ComplianceProfile, RiskLevel\nfrom datetime import datetime\n\nframework = EUAIActFramework()\n\nentry = AuditEntry(\n    entry_id=\"test-001\",\n    timestamp=datetime.utcnow(),\n    event_type=\"inference\",\n    actor=\"user@example.com\",\n    action=\"AI response\",\n    risk_level=RiskLevel.HIGH,\n    user_notified=True,\n    human_oversight=True,\n    metadata={\"risk_assessment_documented\": True},\n)\n\nprofile = ComplianceProfile(\n    profile_id=\"eu-ai\",\n    name=\"EU AI Compliance\",\n)\n\nresult = await framework.check(entry, profile)\n</code></pre>"},{"location":"api/frameworks/#key-requirements","title":"Key Requirements","text":"<p>High-risk operations require: - <code>human_oversight=True</code> - <code>metadata[\"risk_assessment_documented\"]=True</code></p> <p>User-facing interactions require: - <code>user_notified=True</code></p> <p>Inference events require: - <code>metadata[\"accuracy_monitored\"]=True</code></p>"},{"location":"api/frameworks/#soc2-framework","title":"SOC2 Framework","text":"<p>SOC2 Type II compliance framework.</p>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.soc2.SOC2Framework","title":"SOC2Framework","text":"<p>SOC2 Type II compliance framework.</p> <p>Implements compliance checks based on the AICPA Trust Service Criteria for SOC2 Type II reporting. This framework evaluates audit entries against the five trust service principles: Security, Availability, Processing Integrity, Confidentiality, and Privacy.</p> <p>SOC2 Type II reports assess both the design and operating effectiveness of controls over a specified period. This implementation focuses on controls relevant to AI systems and their operational characteristics.</p> <p>Trust Service Categories: - CC (Common Criteria): Security-related controls - A: Availability controls - PI: Processing Integrity controls - C: Confidentiality controls - P: Privacy controls</p> Example <p>framework = SOC2Framework() result = await framework.check(entry, profile) if not result.is_compliant: ...     for violation in result.violations: ...         print(f\"{violation.rule_id}: {violation.description}\")</p> Source code in <code>src/rotalabs_comply/frameworks/soc2.py</code> <pre><code>class SOC2Framework(BaseFramework):\n    \"\"\"\n    SOC2 Type II compliance framework.\n\n    Implements compliance checks based on the AICPA Trust Service Criteria\n    for SOC2 Type II reporting. This framework evaluates audit entries against\n    the five trust service principles: Security, Availability, Processing\n    Integrity, Confidentiality, and Privacy.\n\n    SOC2 Type II reports assess both the design and operating effectiveness\n    of controls over a specified period. This implementation focuses on\n    controls relevant to AI systems and their operational characteristics.\n\n    Trust Service Categories:\n    - CC (Common Criteria): Security-related controls\n    - A: Availability controls\n    - PI: Processing Integrity controls\n    - C: Confidentiality controls\n    - P: Privacy controls\n\n    Example:\n        &gt;&gt;&gt; framework = SOC2Framework()\n        &gt;&gt;&gt; result = await framework.check(entry, profile)\n        &gt;&gt;&gt; if not result.is_compliant:\n        ...     for violation in result.violations:\n        ...         print(f\"{violation.rule_id}: {violation.description}\")\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the SOC2 Type II framework with all defined rules.\"\"\"\n        rules = self._create_rules()\n        super().__init__(name=\"SOC2 Type II\", version=\"2017\", rules=rules)\n\n    def _create_rules(self) -&gt; List[ComplianceRule]:\n        \"\"\"\n        Create all SOC2 Type II compliance rules.\n\n        Returns:\n            List of ComplianceRule objects representing SOC2 Trust Service Criteria\n        \"\"\"\n        return [\n            # Security (Common Criteria)\n            ComplianceRule(\n                rule_id=\"SOC2-CC6.1\",\n                name=\"Logical Access Controls\",\n                description=(\n                    \"The entity implements logical access security software, \"\n                    \"infrastructure, and architectures over protected information \"\n                    \"assets to protect them from security events to meet the entity's \"\n                    \"objectives. Logical access security measures restrict access to \"\n                    \"information resources based on the user's identity, role, or other \"\n                    \"criteria, and are designed to permit access only to authorized users.\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"security\",\n                remediation=(\n                    \"Implement role-based access control (RBAC) or attribute-based \"\n                    \"access control (ABAC). Ensure all access to AI systems and data \"\n                    \"is authenticated and authorized. Log all access attempts.\"\n                ),\n                references=[\n                    \"AICPA TSC CC6.1\",\n                    \"NIST SP 800-53 AC-2, AC-3\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"SOC2-CC6.2\",\n                name=\"System Boundary Definition\",\n                description=(\n                    \"Prior to issuing system credentials and granting system access, \"\n                    \"the entity registers and authorizes new internal and external \"\n                    \"users whose access is administered by the entity. For those users \"\n                    \"whose access is administered by the entity, user system credentials \"\n                    \"are removed when user access is no longer authorized.\"\n                ),\n                severity=RiskLevel.MEDIUM,\n                category=\"security\",\n                remediation=(\n                    \"Maintain a clear inventory of system boundaries and authorized \"\n                    \"users. Implement user provisioning and deprovisioning processes. \"\n                    \"Conduct regular access reviews to ensure only authorized users \"\n                    \"have access.\"\n                ),\n                references=[\n                    \"AICPA TSC CC6.2\",\n                    \"NIST SP 800-53 AC-2\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"SOC2-CC6.3\",\n                name=\"Change Management\",\n                description=(\n                    \"The entity authorizes, designs, develops or acquires, configures, \"\n                    \"documents, tests, approves, and implements changes to \"\n                    \"infrastructure, data, software, and procedures to meet its \"\n                    \"objectives. Changes are authorized, documented, tested, and \"\n                    \"approved before implementation.\"\n                ),\n                severity=RiskLevel.MEDIUM,\n                category=\"security\",\n                remediation=(\n                    \"Establish formal change management procedures for AI systems. \"\n                    \"Document all changes to models, configurations, and infrastructure. \"\n                    \"Require approval before production deployment. Test changes in \"\n                    \"non-production environments first.\"\n                ),\n                references=[\n                    \"AICPA TSC CC6.3\",\n                    \"NIST SP 800-53 CM-3\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"SOC2-CC7.1\",\n                name=\"System Monitoring\",\n                description=(\n                    \"To meet its objectives, the entity uses detection and monitoring \"\n                    \"procedures to identify (1) changes to configurations that result \"\n                    \"in the introduction of new vulnerabilities, and (2) susceptibilities \"\n                    \"to newly discovered vulnerabilities. The entity monitors system \"\n                    \"components for anomalies and investigates identified anomalies.\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"security\",\n                remediation=(\n                    \"Implement comprehensive monitoring for AI systems including: \"\n                    \"performance metrics, error rates, drift detection, and security \"\n                    \"events. Establish alerting thresholds and response procedures. \"\n                    \"Review logs regularly for anomalies.\"\n                ),\n                references=[\n                    \"AICPA TSC CC7.1\",\n                    \"NIST SP 800-53 AU-6, SI-4\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"SOC2-CC7.2\",\n                name=\"Incident Response\",\n                description=(\n                    \"The entity monitors system components and the operation of those \"\n                    \"components for anomalies that are indicative of malicious acts, \"\n                    \"natural disasters, and errors affecting the entity's ability to \"\n                    \"meet its objectives; anomalies are analyzed to determine whether \"\n                    \"they represent security events.\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"security\",\n                remediation=(\n                    \"Establish an incident response plan specific to AI systems. \"\n                    \"Define procedures for detecting, analyzing, containing, eradicating, \"\n                    \"and recovering from incidents. Include procedures for model \"\n                    \"rollback and bias/fairness incidents.\"\n                ),\n                references=[\n                    \"AICPA TSC CC7.2\",\n                    \"NIST SP 800-53 IR-4, IR-5\",\n                ],\n            ),\n\n            # Availability\n            ComplianceRule(\n                rule_id=\"SOC2-CC8.1\",\n                name=\"Availability Monitoring\",\n                description=(\n                    \"The entity authorizes, designs, develops or acquires, implements, \"\n                    \"operates, approves, maintains, and monitors environmental \"\n                    \"protections, software, data backup processes, and recovery \"\n                    \"infrastructure to meet its objectives. System availability is \"\n                    \"monitored against service level commitments.\"\n                ),\n                severity=RiskLevel.MEDIUM,\n                category=\"availability\",\n                remediation=(\n                    \"Implement availability monitoring for all AI system components. \"\n                    \"Define and monitor SLAs for inference latency, throughput, and \"\n                    \"uptime. Establish alerting for availability degradation. \"\n                    \"Maintain redundancy for critical components.\"\n                ),\n                references=[\n                    \"AICPA TSC CC8.1\",\n                    \"NIST SP 800-53 CP-2, CP-7\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"SOC2-A1.1\",\n                name=\"Recovery Objectives Defined\",\n                description=(\n                    \"The entity maintains, monitors, and evaluates current processing \"\n                    \"capacity and use of system components (infrastructure, data, and \"\n                    \"software) to manage capacity demand and to enable the implementation \"\n                    \"of additional capacity to help meet its objectives. Recovery time \"\n                    \"objectives (RTO) and recovery point objectives (RPO) are defined.\"\n                ),\n                severity=RiskLevel.MEDIUM,\n                category=\"availability\",\n                remediation=(\n                    \"Define and document RTO and RPO for AI systems. Implement backup \"\n                    \"procedures for models, configurations, and data. Test recovery \"\n                    \"procedures regularly. Ensure capacity planning considers peak loads.\"\n                ),\n                references=[\n                    \"AICPA TSC A1.1\",\n                    \"NIST SP 800-53 CP-9, CP-10\",\n                ],\n            ),\n\n            # Processing Integrity\n            ComplianceRule(\n                rule_id=\"SOC2-PI1.1\",\n                name=\"Processing Integrity Validation\",\n                description=(\n                    \"The entity implements policies and procedures over system inputs \"\n                    \"including controls over input processes that help ensure \"\n                    \"completeness, accuracy, timeliness, and authorization of system \"\n                    \"inputs. Processing integrity refers to the completeness, validity, \"\n                    \"accuracy, timeliness, and authorization of system processing.\"\n                ),\n                severity=RiskLevel.MEDIUM,\n                category=\"processing_integrity\",\n                remediation=(\n                    \"Implement input validation for all AI system inputs. Validate \"\n                    \"data formats, ranges, and consistency. Log all inputs with \"\n                    \"timestamps. Implement data quality checks and monitoring for \"\n                    \"data drift.\"\n                ),\n                references=[\n                    \"AICPA TSC PI1.1\",\n                    \"NIST SP 800-53 SI-10\",\n                ],\n            ),\n\n            # Confidentiality\n            ComplianceRule(\n                rule_id=\"SOC2-C1.1\",\n                name=\"Confidentiality Classification\",\n                description=(\n                    \"The entity identifies and maintains confidential information to \"\n                    \"meet the entity's objectives related to confidentiality. \"\n                    \"Information is classified by the entity according to its \"\n                    \"sensitivity and is protected accordingly. Confidential information \"\n                    \"is identified based on regulatory requirements, contractual \"\n                    \"commitments, and business needs.\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"confidentiality\",\n                remediation=(\n                    \"Implement data classification for all data processed by AI systems. \"\n                    \"Label data according to sensitivity levels (public, internal, \"\n                    \"confidential, restricted). Apply appropriate protection measures \"\n                    \"based on classification. Document handling procedures.\"\n                ),\n                references=[\n                    \"AICPA TSC C1.1\",\n                    \"NIST SP 800-53 RA-2\",\n                ],\n            ),\n\n            # Privacy\n            ComplianceRule(\n                rule_id=\"SOC2-P1.1\",\n                name=\"Privacy Notice Provided\",\n                description=(\n                    \"The entity provides notice to data subjects about its privacy \"\n                    \"practices to meet the entity's objectives related to privacy. \"\n                    \"The notice is provided to data subjects at or before the time \"\n                    \"their personal information is collected. The notice describes \"\n                    \"the purposes for which personal information is collected, used, \"\n                    \"retained, and disclosed.\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"privacy\",\n                remediation=(\n                    \"Provide clear privacy notices before collecting personal data \"\n                    \"for AI processing. Document how personal data is used in AI \"\n                    \"training and inference. Implement consent mechanisms where \"\n                    \"required. Maintain records of privacy notices provided.\"\n                ),\n                references=[\n                    \"AICPA TSC P1.1\",\n                    \"GDPR Article 13\",\n                ],\n            ),\n        ]\n\n    def _check_rule(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check a single SOC2 rule against an audit entry.\n\n        Evaluates the audit entry against the specific rule requirements\n        and returns a violation if the entry does not comply.\n\n        Args:\n            entry: The audit entry to check\n            rule: The rule to evaluate\n\n        Returns:\n            ComplianceViolation if the rule is violated, None otherwise\n        \"\"\"\n        # Use custom check function if provided\n        if rule.check_fn is not None:\n            is_compliant = rule.check_fn(entry)\n            if not is_compliant:\n                return self._create_violation(entry, rule, \"Custom check failed\")\n            return None\n\n        # Framework-specific rule checks\n        if rule.rule_id == \"SOC2-CC6.1\":\n            return self._check_logical_access(entry, rule)\n        elif rule.rule_id == \"SOC2-CC6.2\":\n            return self._check_system_boundary(entry, rule)\n        elif rule.rule_id == \"SOC2-CC6.3\":\n            return self._check_change_management(entry, rule)\n        elif rule.rule_id == \"SOC2-CC7.1\":\n            return self._check_system_monitoring(entry, rule)\n        elif rule.rule_id == \"SOC2-CC7.2\":\n            return self._check_incident_response(entry, rule)\n        elif rule.rule_id == \"SOC2-CC8.1\":\n            return self._check_availability_monitoring(entry, rule)\n        elif rule.rule_id == \"SOC2-A1.1\":\n            return self._check_recovery_objectives(entry, rule)\n        elif rule.rule_id == \"SOC2-PI1.1\":\n            return self._check_processing_integrity(entry, rule)\n        elif rule.rule_id == \"SOC2-C1.1\":\n            return self._check_confidentiality_classification(entry, rule)\n        elif rule.rule_id == \"SOC2-P1.1\":\n            return self._check_privacy_notice(entry, rule)\n\n        return None\n\n    def _check_logical_access(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check SOC2-CC6.1: Logical access controls.\n\n        All data access and model operations should have access controls.\n        \"\"\"\n        access_events = {\n            \"data_access\", \"model_access\", \"api_call\", \"authentication\",\n            \"inference\", \"training\", \"data_export\"\n        }\n        if entry.event_type.lower() not in access_events:\n            return None\n\n        # Check for access control metadata\n        has_authentication = bool(entry.actor and entry.actor != \"anonymous\")\n        has_access_control = entry.metadata.get(\"access_controlled\", False)\n\n        if not has_authentication:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Access event (type={entry.event_type}) performed by \"\n                f\"unauthenticated or anonymous user\",\n            )\n\n        if not has_access_control:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Access event (type={entry.event_type}) performed without \"\n                f\"documented access control validation\",\n            )\n\n        return None\n\n    def _check_system_boundary(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check SOC2-CC6.2: System boundary definition.\n\n        Users should be registered and authorized before access.\n        \"\"\"\n        # Check for external access events\n        external_events = {\"api_call\", \"external_integration\", \"data_import\", \"data_export\"}\n        if entry.event_type.lower() not in external_events:\n            return None\n\n        # Check that system_id is defined (system boundary is known)\n        if not entry.system_id:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"External event (type={entry.event_type}) performed without \"\n                f\"defined system boundary (missing system_id)\",\n            )\n\n        return None\n\n    def _check_change_management(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check SOC2-CC6.3: Change management.\n\n        Changes should be authorized, documented, and tested.\n        \"\"\"\n        change_events = {\n            \"deployment\", \"model_update\", \"config_change\", \"training\",\n            \"fine_tuning\", \"rollback\"\n        }\n        if entry.event_type.lower() not in change_events:\n            return None\n\n        has_change_approval = entry.metadata.get(\"change_approved\", False)\n        has_change_documentation = entry.documentation_ref is not None\n\n        if not has_change_approval:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Change event (type={entry.event_type}) performed without \"\n                f\"documented change approval\",\n            )\n\n        if not has_change_documentation:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Change event (type={entry.event_type}) performed without \"\n                f\"documentation reference\",\n            )\n\n        return None\n\n    def _check_system_monitoring(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check SOC2-CC7.1: System monitoring.\n\n        System operations should be monitored for anomalies.\n        \"\"\"\n        # All entries should have monitoring; check for monitoring metadata\n        has_monitoring = entry.metadata.get(\"monitored\", True)  # Default to true for basic entries\n\n        # For significant operations, require explicit monitoring documentation\n        significant_events = {\"inference\", \"training\", \"deployment\", \"data_access\"}\n        if entry.event_type.lower() in significant_events:\n            has_monitoring = entry.metadata.get(\"monitored\", False)\n\n            if not has_monitoring:\n                return self._create_violation(\n                    entry,\n                    rule,\n                    f\"Significant operation (type={entry.event_type}) performed \"\n                    f\"without documented monitoring\",\n                )\n\n        return None\n\n    def _check_incident_response(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check SOC2-CC7.2: Incident response.\n\n        Security events should trigger incident response procedures.\n        \"\"\"\n        # Check for error or security events\n        if entry.error_handled is False:\n            has_incident_response = entry.metadata.get(\"incident_logged\", False)\n\n            if not has_incident_response:\n                return self._create_violation(\n                    entry,\n                    rule,\n                    f\"Error event (type={entry.event_type}) occurred without \"\n                    f\"incident response logging\",\n                )\n\n        # Check for security-related events\n        security_events = {\"authentication_failure\", \"access_denied\", \"security_alert\"}\n        if entry.event_type.lower() in security_events:\n            has_incident_response = entry.metadata.get(\"incident_logged\", False)\n\n            if not has_incident_response:\n                return self._create_violation(\n                    entry,\n                    rule,\n                    f\"Security event (type={entry.event_type}) without \"\n                    f\"incident response logging\",\n                )\n\n        return None\n\n    def _check_availability_monitoring(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check SOC2-CC8.1: Availability monitoring.\n\n        System availability should be monitored against SLAs.\n        \"\"\"\n        availability_events = {\"health_check\", \"deployment\", \"scaling\", \"recovery\"}\n        if entry.event_type.lower() not in availability_events:\n            return None\n\n        has_sla_monitoring = entry.metadata.get(\"sla_monitored\", False)\n\n        if not has_sla_monitoring:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Availability event (type={entry.event_type}) without \"\n                f\"documented SLA monitoring\",\n            )\n\n        return None\n\n    def _check_recovery_objectives(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check SOC2-A1.1: Recovery objectives defined.\n\n        RTO and RPO should be defined for recovery operations.\n        \"\"\"\n        recovery_events = {\"backup\", \"restore\", \"recovery\", \"disaster_recovery\"}\n        if entry.event_type.lower() not in recovery_events:\n            return None\n\n        has_rto_defined = entry.metadata.get(\"rto_defined\", False)\n        has_rpo_defined = entry.metadata.get(\"rpo_defined\", False)\n\n        if not has_rto_defined or not has_rpo_defined:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Recovery event (type={entry.event_type}) without defined \"\n                f\"RTO/RPO objectives (rto={has_rto_defined}, rpo={has_rpo_defined})\",\n            )\n\n        return None\n\n    def _check_processing_integrity(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check SOC2-PI1.1: Processing integrity validation.\n\n        Data processing should validate input integrity.\n        \"\"\"\n        processing_events = {\"inference\", \"training\", \"data_processing\", \"data_transformation\"}\n        if entry.event_type.lower() not in processing_events:\n            return None\n\n        has_input_validation = entry.metadata.get(\"input_validated\", False)\n\n        if not has_input_validation:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Processing event (type={entry.event_type}) without \"\n                f\"documented input validation\",\n            )\n\n        return None\n\n    def _check_confidentiality_classification(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check SOC2-C1.1: Confidentiality classification.\n\n        Data should be classified according to sensitivity.\n        \"\"\"\n        data_events = {\"data_access\", \"data_processing\", \"inference\", \"training\", \"data_export\"}\n        if entry.event_type.lower() not in data_events:\n            return None\n\n        # Check if data classification is documented\n        is_classified = entry.data_classification != \"unclassified\"\n\n        if not is_classified:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Data event (type={entry.event_type}) with unclassified data \"\n                f\"(classification should be specified)\",\n            )\n\n        return None\n\n    def _check_privacy_notice(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check SOC2-P1.1: Privacy notice provided.\n\n        Personal data collection should include privacy notice.\n        \"\"\"\n        # Check for PII-related events\n        pii_classifications = {\"PII\", \"PHI\", \"personal\", \"sensitive\"}\n        if entry.data_classification.upper() not in {c.upper() for c in pii_classifications}:\n            return None\n\n        has_privacy_notice = entry.metadata.get(\"privacy_notice_provided\", False)\n\n        if not has_privacy_notice:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Personal data event (type={entry.event_type}, \"\n                f\"classification={entry.data_classification}) without \"\n                f\"documented privacy notice\",\n            )\n\n        return None\n\n    def _create_violation(\n        self, entry: AuditEntry, rule: ComplianceRule, evidence: str\n    ) -&gt; ComplianceViolation:\n        \"\"\"\n        Create a compliance violation object.\n\n        Args:\n            entry: The audit entry that triggered the violation\n            rule: The rule that was violated\n            evidence: Specific evidence describing the violation\n\n        Returns:\n            ComplianceViolation object\n        \"\"\"\n        return ComplianceViolation(\n            rule_id=rule.rule_id,\n            rule_name=rule.name,\n            severity=rule.severity,\n            description=rule.description,\n            evidence=evidence,\n            remediation=rule.remediation,\n            entry_id=entry.entry_id,\n            category=rule.category,\n            framework=self._name,\n        )\n</code></pre>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.soc2.SOC2Framework.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> <p>Initialize the SOC2 Type II framework with all defined rules.</p> Source code in <code>src/rotalabs_comply/frameworks/soc2.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize the SOC2 Type II framework with all defined rules.\"\"\"\n    rules = self._create_rules()\n    super().__init__(name=\"SOC2 Type II\", version=\"2017\", rules=rules)\n</code></pre>"},{"location":"api/frameworks/#categories_1","title":"Categories","text":"Category TSC Description <code>security</code> CC Common Criteria - Security controls <code>availability</code> A System availability <code>processing_integrity</code> PI Data processing accuracy <code>confidentiality</code> C Confidential information protection <code>privacy</code> P Personal information protection"},{"location":"api/frameworks/#rules_1","title":"Rules","text":"Rule ID Name Severity Category <code>SOC2-CC6.1</code> Logical Access Controls HIGH security <code>SOC2-CC6.2</code> System Boundary Definition MEDIUM security <code>SOC2-CC6.3</code> Change Management MEDIUM security <code>SOC2-CC7.1</code> System Monitoring HIGH security <code>SOC2-CC7.2</code> Incident Response HIGH security <code>SOC2-CC8.1</code> Availability Monitoring MEDIUM availability <code>SOC2-A1.1</code> Recovery Objectives MEDIUM availability <code>SOC2-PI1.1</code> Processing Integrity MEDIUM processing_integrity <code>SOC2-C1.1</code> Confidentiality Classification HIGH confidentiality <code>SOC2-P1.1</code> Privacy Notice HIGH privacy"},{"location":"api/frameworks/#usage_1","title":"Usage","text":"<pre><code>from rotalabs_comply.frameworks.soc2 import SOC2Framework\n\nframework = SOC2Framework()\n\nentry = AuditEntry(\n    entry_id=\"soc2-001\",\n    timestamp=datetime.utcnow(),\n    event_type=\"data_access\",\n    actor=\"admin@company.com\",\n    action=\"Query database\",\n    data_classification=\"confidential\",\n    metadata={\n        \"access_controlled\": True,\n        \"monitored\": True,\n    },\n)\n\nresult = await framework.check(entry, profile)\n</code></pre>"},{"location":"api/frameworks/#key-requirements_1","title":"Key Requirements","text":"<p>Access events require: - Authenticated actor (not \"anonymous\") - <code>metadata[\"access_controlled\"]=True</code></p> <p>Change events require: - <code>metadata[\"change_approved\"]=True</code> - <code>documentation_ref</code> set</p> <p>Data events require: - <code>data_classification</code> not \"unclassified\"</p>"},{"location":"api/frameworks/#hipaa-framework","title":"HIPAA Framework","text":"<p>HIPAA compliance framework for PHI handling.</p>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.hipaa.HIPAAFramework","title":"HIPAAFramework","text":"<p>HIPAA compliance framework.</p> <p>Implements compliance checks based on HIPAA Security Rule technical safeguards and Privacy Rule requirements. This framework evaluates audit entries for AI systems that process Protected Health Information (PHI) or electronic PHI (ePHI).</p> <p>HIPAA requires covered entities and business associates to: - Ensure confidentiality, integrity, and availability of ePHI - Protect against anticipated threats and hazards - Protect against unauthorized uses or disclosures - Ensure workforce compliance</p> <p>This implementation focuses on technical safeguards (164.312) which are most relevant to AI system operations: - Access controls (164.312(a)) - Audit controls (164.312(b)) - Integrity controls (164.312(c)) - Authentication (164.312(d)) - Transmission security (164.312(e))</p> Example <p>framework = HIPAAFramework() result = await framework.check(entry, profile) if not result.is_compliant: ...     for violation in result.violations: ...         print(f\"{violation.rule_id}: {violation.description}\")</p> Source code in <code>src/rotalabs_comply/frameworks/hipaa.py</code> <pre><code>class HIPAAFramework(BaseFramework):\n    \"\"\"\n    HIPAA compliance framework.\n\n    Implements compliance checks based on HIPAA Security Rule technical\n    safeguards and Privacy Rule requirements. This framework evaluates\n    audit entries for AI systems that process Protected Health Information\n    (PHI) or electronic PHI (ePHI).\n\n    HIPAA requires covered entities and business associates to:\n    - Ensure confidentiality, integrity, and availability of ePHI\n    - Protect against anticipated threats and hazards\n    - Protect against unauthorized uses or disclosures\n    - Ensure workforce compliance\n\n    This implementation focuses on technical safeguards (164.312) which\n    are most relevant to AI system operations:\n    - Access controls (164.312(a))\n    - Audit controls (164.312(b))\n    - Integrity controls (164.312(c))\n    - Authentication (164.312(d))\n    - Transmission security (164.312(e))\n\n    Example:\n        &gt;&gt;&gt; framework = HIPAAFramework()\n        &gt;&gt;&gt; result = await framework.check(entry, profile)\n        &gt;&gt;&gt; if not result.is_compliant:\n        ...     for violation in result.violations:\n        ...         print(f\"{violation.rule_id}: {violation.description}\")\n    \"\"\"\n\n    # PHI-related data classifications\n    PHI_CLASSIFICATIONS = {\n        \"PHI\", \"ePHI\", \"protected_health_information\",\n        \"health_data\", \"medical\", \"clinical\"\n    }\n\n    def __init__(self):\n        \"\"\"Initialize the HIPAA framework with all defined rules.\"\"\"\n        rules = self._create_rules()\n        super().__init__(name=\"HIPAA\", version=\"1996/2013\", rules=rules)\n\n    def _create_rules(self) -&gt; List[ComplianceRule]:\n        \"\"\"\n        Create all HIPAA compliance rules.\n\n        Returns:\n            List of ComplianceRule objects representing HIPAA requirements\n        \"\"\"\n        return [\n            # Security Rule - Technical Safeguards\n            ComplianceRule(\n                rule_id=\"HIPAA-164.312(a)\",\n                name=\"Access Control\",\n                description=(\n                    \"Implement technical policies and procedures for electronic \"\n                    \"information systems that maintain electronic protected health \"\n                    \"information to allow access only to those persons or software \"\n                    \"programs that have been granted access rights as specified in \"\n                    \"164.308(a)(4). This includes: unique user identification, \"\n                    \"emergency access procedures, automatic logoff, and encryption \"\n                    \"and decryption mechanisms.\"\n                ),\n                severity=RiskLevel.CRITICAL,\n                category=\"access_control\",\n                remediation=(\n                    \"Implement comprehensive access controls including: unique user \"\n                    \"IDs for all users accessing ePHI, role-based access policies, \"\n                    \"automatic session timeouts, emergency access procedures, and \"\n                    \"encryption for ePHI at rest. Document all access control \"\n                    \"policies and procedures.\"\n                ),\n                references=[\n                    \"45 CFR 164.312(a)(1)\",\n                    \"45 CFR 164.312(a)(2)(i-iv)\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"HIPAA-164.312(b)\",\n                name=\"Audit Controls\",\n                description=(\n                    \"Implement hardware, software, and/or procedural mechanisms that \"\n                    \"record and examine activity in information systems that contain \"\n                    \"or use electronic protected health information. Audit controls \"\n                    \"must capture sufficient information to support review of system \"\n                    \"activity, including who accessed what data and when.\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"audit\",\n                remediation=(\n                    \"Implement comprehensive audit logging for all systems containing \"\n                    \"ePHI. Logs should capture: user identification, timestamp, type \"\n                    \"of access, data accessed, and success/failure status. Implement \"\n                    \"log retention policies and regular log review procedures.\"\n                ),\n                references=[\n                    \"45 CFR 164.312(b)\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"HIPAA-164.312(c)\",\n                name=\"Integrity Controls\",\n                description=(\n                    \"Implement policies and procedures to protect electronic protected \"\n                    \"health information from improper alteration or destruction. \"\n                    \"Implement electronic mechanisms to corroborate that electronic \"\n                    \"protected health information has not been altered or destroyed \"\n                    \"in an unauthorized manner.\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"integrity\",\n                remediation=(\n                    \"Implement integrity controls including: checksums or digital \"\n                    \"signatures for ePHI, change detection mechanisms, version \"\n                    \"control for data modifications, and procedures for detecting \"\n                    \"unauthorized changes. Document all integrity verification \"\n                    \"procedures.\"\n                ),\n                references=[\n                    \"45 CFR 164.312(c)(1)\",\n                    \"45 CFR 164.312(c)(2)\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"HIPAA-164.312(d)\",\n                name=\"Person or Entity Authentication\",\n                description=(\n                    \"Implement procedures to verify that a person or entity seeking \"\n                    \"access to electronic protected health information is the one \"\n                    \"claimed. Authentication mechanisms should be appropriate for \"\n                    \"the risk level of the systems and data being accessed.\"\n                ),\n                severity=RiskLevel.CRITICAL,\n                category=\"authentication\",\n                remediation=(\n                    \"Implement strong authentication mechanisms for all ePHI access. \"\n                    \"Consider multi-factor authentication for high-risk access. \"\n                    \"Implement password policies meeting industry standards. \"\n                    \"Document authentication procedures and verify identity before \"\n                    \"granting access credentials.\"\n                ),\n                references=[\n                    \"45 CFR 164.312(d)\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"HIPAA-164.312(e)\",\n                name=\"Transmission Security\",\n                description=(\n                    \"Implement technical security measures to guard against \"\n                    \"unauthorized access to electronic protected health information \"\n                    \"that is being transmitted over an electronic communications \"\n                    \"network. This includes integrity controls and encryption for \"\n                    \"data in transit.\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"transmission\",\n                remediation=(\n                    \"Implement encryption for all ePHI transmitted over networks \"\n                    \"(TLS 1.2+ recommended). Use secure protocols for data transfer. \"\n                    \"Implement integrity verification for transmitted data. \"\n                    \"Document transmission security policies and procedures.\"\n                ),\n                references=[\n                    \"45 CFR 164.312(e)(1)\",\n                    \"45 CFR 164.312(e)(2)(i-ii)\",\n                ],\n            ),\n\n            # Privacy Rule\n            ComplianceRule(\n                rule_id=\"HIPAA-164.502\",\n                name=\"Uses and Disclosures\",\n                description=(\n                    \"A covered entity or business associate may not use or disclose \"\n                    \"protected health information, except as permitted or required. \"\n                    \"The minimum necessary standard requires limiting PHI use, \"\n                    \"disclosure, and requests to the minimum necessary to accomplish \"\n                    \"the intended purpose. AI systems must respect these limitations.\"\n                ),\n                severity=RiskLevel.CRITICAL,\n                category=\"privacy\",\n                remediation=(\n                    \"Implement minimum necessary controls for PHI access by AI \"\n                    \"systems. Document the purpose for each PHI access. Limit data \"\n                    \"exposure to only what is required for the specific use case. \"\n                    \"Implement data masking or filtering where possible. Maintain \"\n                    \"records of all PHI disclosures.\"\n                ),\n                references=[\n                    \"45 CFR 164.502\",\n                    \"45 CFR 164.514(d)\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"HIPAA-164.514\",\n                name=\"De-identification Standards\",\n                description=(\n                    \"Health information that does not identify an individual and \"\n                    \"with respect to which there is no reasonable basis to believe \"\n                    \"that the information can be used to identify an individual is \"\n                    \"not individually identifiable health information. De-identification \"\n                    \"may be achieved through expert determination or safe harbor methods.\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"privacy\",\n                remediation=(\n                    \"When using health data for AI training or analytics, implement \"\n                    \"de-identification following HIPAA Safe Harbor (remove 18 \"\n                    \"identifiers) or Expert Determination methods. Document \"\n                    \"de-identification procedures and maintain records of \"\n                    \"de-identification status for all datasets.\"\n                ),\n                references=[\n                    \"45 CFR 164.514(a)\",\n                    \"45 CFR 164.514(b)\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"HIPAA-164.530\",\n                name=\"Administrative Requirements\",\n                description=(\n                    \"A covered entity must maintain, until six years after the later \"\n                    \"of the date of their creation or last effective date, its \"\n                    \"privacy policies and procedures, its privacy practices notices, \"\n                    \"disposition of complaints, and other actions, activities, and \"\n                    \"designations that the Privacy Rule requires to be documented.\"\n                ),\n                severity=RiskLevel.MEDIUM,\n                category=\"privacy\",\n                remediation=(\n                    \"Maintain comprehensive documentation of all privacy policies, \"\n                    \"procedures, and practices related to AI systems processing PHI. \"\n                    \"Retain all documentation for at least six years. Implement \"\n                    \"procedures for responding to individual rights requests \"\n                    \"(access, amendment, accounting of disclosures).\"\n                ),\n                references=[\n                    \"45 CFR 164.530(j)\",\n                ],\n            ),\n        ]\n\n    def _is_phi_related(self, entry: AuditEntry) -&gt; bool:\n        \"\"\"\n        Determine if an audit entry involves PHI.\n\n        Args:\n            entry: The audit entry to check\n\n        Returns:\n            True if the entry involves PHI, False otherwise\n        \"\"\"\n        classification_upper = entry.data_classification.upper()\n        return any(\n            phi.upper() in classification_upper\n            for phi in self.PHI_CLASSIFICATIONS\n        )\n\n    def _check_rule(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check a single HIPAA rule against an audit entry.\n\n        HIPAA rules are only evaluated for entries involving PHI.\n        Non-PHI entries are automatically compliant.\n\n        Args:\n            entry: The audit entry to check\n            rule: The rule to evaluate\n\n        Returns:\n            ComplianceViolation if the rule is violated, None otherwise\n        \"\"\"\n        # HIPAA rules only apply to PHI-related entries\n        if not self._is_phi_related(entry):\n            return None\n\n        # Use custom check function if provided\n        if rule.check_fn is not None:\n            is_compliant = rule.check_fn(entry)\n            if not is_compliant:\n                return self._create_violation(entry, rule, \"Custom check failed\")\n            return None\n\n        # Framework-specific rule checks\n        if rule.rule_id == \"HIPAA-164.312(a)\":\n            return self._check_access_control(entry, rule)\n        elif rule.rule_id == \"HIPAA-164.312(b)\":\n            return self._check_audit_controls(entry, rule)\n        elif rule.rule_id == \"HIPAA-164.312(c)\":\n            return self._check_integrity_controls(entry, rule)\n        elif rule.rule_id == \"HIPAA-164.312(d)\":\n            return self._check_authentication(entry, rule)\n        elif rule.rule_id == \"HIPAA-164.312(e)\":\n            return self._check_transmission_security(entry, rule)\n        elif rule.rule_id == \"HIPAA-164.502\":\n            return self._check_uses_and_disclosures(entry, rule)\n        elif rule.rule_id == \"HIPAA-164.514\":\n            return self._check_deidentification(entry, rule)\n        elif rule.rule_id == \"HIPAA-164.530\":\n            return self._check_administrative_requirements(entry, rule)\n\n        return None\n\n    def _check_access_control(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check HIPAA-164.312(a): Access control required.\n\n        PHI access must have proper access controls including unique user ID,\n        authorization validation, and encryption.\n        \"\"\"\n        # Check for unique user identification\n        has_unique_user = bool(entry.actor and entry.actor != \"anonymous\")\n        if not has_unique_user:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"PHI access (type={entry.event_type}) performed without \"\n                f\"unique user identification (actor={entry.actor})\",\n            )\n\n        # Check for access control validation\n        has_access_control = entry.metadata.get(\"access_controlled\", False)\n        if not has_access_control:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"PHI access (type={entry.event_type}) without documented \"\n                f\"access control validation\",\n            )\n\n        # For data access, check for encryption\n        data_events = {\"data_access\", \"data_export\", \"inference\"}\n        if entry.event_type.lower() in data_events:\n            has_encryption = entry.metadata.get(\"encryption_enabled\", False)\n            if not has_encryption:\n                return self._create_violation(\n                    entry,\n                    rule,\n                    f\"PHI data access (type={entry.event_type}) without \"\n                    f\"encryption enabled\",\n                )\n\n        return None\n\n    def _check_audit_controls(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check HIPAA-164.312(b): Audit controls required.\n\n        All PHI access must be logged with sufficient detail.\n        \"\"\"\n        # Check that entry has required audit fields\n        required_fields = [\n            (\"entry_id\", entry.entry_id),\n            (\"timestamp\", entry.timestamp),\n            (\"actor\", entry.actor),\n            (\"event_type\", entry.event_type),\n            (\"action\", entry.action),\n        ]\n\n        missing_fields = [\n            field_name for field_name, field_value in required_fields\n            if not field_value\n        ]\n\n        if missing_fields:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"PHI event missing required audit fields: {', '.join(missing_fields)}\",\n            )\n\n        # Check for audit logging confirmation\n        has_audit_logged = entry.metadata.get(\"audit_logged\", True)  # Assume logged if entry exists\n        if not has_audit_logged:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"PHI event (type={entry.event_type}) without confirmation \"\n                f\"of audit logging\",\n            )\n\n        return None\n\n    def _check_integrity_controls(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check HIPAA-164.312(c): Integrity controls.\n\n        PHI modifications must have integrity verification.\n        \"\"\"\n        modification_events = {\n            \"update\", \"modify\", \"write\", \"training\", \"data_transformation\",\n            \"data_processing\"\n        }\n        if entry.event_type.lower() not in modification_events:\n            return None\n\n        has_integrity_check = entry.metadata.get(\"integrity_verified\", False)\n        if not has_integrity_check:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"PHI modification (type={entry.event_type}) without \"\n                f\"integrity verification controls\",\n            )\n\n        return None\n\n    def _check_authentication(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check HIPAA-164.312(d): Person authentication.\n\n        PHI access requires verified authentication.\n        \"\"\"\n        # Must have authenticated user\n        if not entry.actor or entry.actor == \"anonymous\":\n            return self._create_violation(\n                entry,\n                rule,\n                f\"PHI access (type={entry.event_type}) without authenticated \"\n                f\"user identification\",\n            )\n\n        # Check for authentication verification\n        has_authentication = entry.metadata.get(\"authenticated\", False)\n        if not has_authentication:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"PHI access (type={entry.event_type}) without documented \"\n                f\"authentication verification\",\n            )\n\n        # For high-risk operations, check for strong authentication\n        high_risk_events = {\"data_export\", \"bulk_access\", \"admin_access\"}\n        if entry.event_type.lower() in high_risk_events:\n            has_mfa = entry.metadata.get(\"mfa_verified\", False)\n            if not has_mfa:\n                return self._create_violation(\n                    entry,\n                    rule,\n                    f\"High-risk PHI operation (type={entry.event_type}) without \"\n                    f\"multi-factor authentication\",\n                )\n\n        return None\n\n    def _check_transmission_security(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check HIPAA-164.312(e): Transmission security.\n\n        PHI transmission must be encrypted and secured.\n        \"\"\"\n        transmission_events = {\n            \"data_transfer\", \"data_export\", \"api_call\", \"external_integration\",\n            \"inference\"  # May involve PHI transmission\n        }\n        if entry.event_type.lower() not in transmission_events:\n            return None\n\n        has_encryption = entry.metadata.get(\"transmission_encrypted\", False)\n        if not has_encryption:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"PHI transmission (type={entry.event_type}) without \"\n                f\"documented encryption\",\n            )\n\n        # Check for secure protocol\n        protocol = entry.metadata.get(\"protocol\", \"\")\n        insecure_protocols = {\"http\", \"ftp\", \"telnet\"}\n        if protocol.lower() in insecure_protocols:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"PHI transmission (type={entry.event_type}) using insecure \"\n                f\"protocol ({protocol})\",\n            )\n\n        return None\n\n    def _check_uses_and_disclosures(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check HIPAA-164.502: Uses and disclosures.\n\n        PHI use must be limited to minimum necessary and properly authorized.\n        \"\"\"\n        # Check for documented purpose\n        has_purpose = entry.metadata.get(\"purpose_documented\", False)\n        if not has_purpose:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"PHI use (type={entry.event_type}) without documented \"\n                f\"purpose for access\",\n            )\n\n        # Check for minimum necessary compliance\n        has_minimum_necessary = entry.metadata.get(\"minimum_necessary_applied\", False)\n        if not has_minimum_necessary:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"PHI use (type={entry.event_type}) without minimum necessary \"\n                f\"standard applied\",\n            )\n\n        # For disclosures, check for authorization\n        disclosure_events = {\"data_export\", \"data_share\", \"external_integration\"}\n        if entry.event_type.lower() in disclosure_events:\n            has_authorization = entry.metadata.get(\"disclosure_authorized\", False)\n            if not has_authorization:\n                return self._create_violation(\n                    entry,\n                    rule,\n                    f\"PHI disclosure (type={entry.event_type}) without \"\n                    f\"documented authorization\",\n                )\n\n        return None\n\n    def _check_deidentification(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check HIPAA-164.514: De-identification standards.\n\n        Training and analytics should use de-identified data where possible.\n        \"\"\"\n        # Check events where de-identification is typically required\n        deidentification_events = {\"training\", \"analytics\", \"research\", \"data_aggregation\"}\n        if entry.event_type.lower() not in deidentification_events:\n            return None\n\n        # Check if de-identification was applied\n        is_deidentified = entry.metadata.get(\"deidentified\", False)\n        has_deidentification_exception = entry.metadata.get(\n            \"deidentification_exception_documented\", False\n        )\n\n        if not is_deidentified and not has_deidentification_exception:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"PHI used for {entry.event_type} without de-identification \"\n                f\"or documented exception\",\n            )\n\n        return None\n\n    def _check_administrative_requirements(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check HIPAA-164.530: Administrative requirements.\n\n        PHI operations should reference documentation and policies.\n        \"\"\"\n        # Check for policy compliance documentation\n        has_policy_ref = entry.documentation_ref is not None\n        has_policy_compliance = entry.metadata.get(\"policy_compliant\", False)\n\n        if not has_policy_ref and not has_policy_compliance:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"PHI operation (type={entry.event_type}) without reference \"\n                f\"to privacy policies or documented compliance\",\n            )\n\n        return None\n\n    def _create_violation(\n        self, entry: AuditEntry, rule: ComplianceRule, evidence: str\n    ) -&gt; ComplianceViolation:\n        \"\"\"\n        Create a compliance violation object.\n\n        Args:\n            entry: The audit entry that triggered the violation\n            rule: The rule that was violated\n            evidence: Specific evidence describing the violation\n\n        Returns:\n            ComplianceViolation object\n        \"\"\"\n        return ComplianceViolation(\n            rule_id=rule.rule_id,\n            rule_name=rule.name,\n            severity=rule.severity,\n            description=rule.description,\n            evidence=evidence,\n            remediation=rule.remediation,\n            entry_id=entry.entry_id,\n            category=rule.category,\n            framework=self._name,\n        )\n</code></pre>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.hipaa.HIPAAFramework.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> <p>Initialize the HIPAA framework with all defined rules.</p> Source code in <code>src/rotalabs_comply/frameworks/hipaa.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize the HIPAA framework with all defined rules.\"\"\"\n    rules = self._create_rules()\n    super().__init__(name=\"HIPAA\", version=\"1996/2013\", rules=rules)\n</code></pre>"},{"location":"api/frameworks/#categories_2","title":"Categories","text":"Category Rule Section Description <code>access_control</code> 164.312(a) System and data access <code>audit</code> 164.312(b) Audit controls <code>integrity</code> 164.312(c) Data integrity <code>authentication</code> 164.312(d) Entity authentication <code>transmission</code> 164.312(e) Transmission security <code>privacy</code> 164.502/514/530 Privacy rule"},{"location":"api/frameworks/#rules_2","title":"Rules","text":"Rule ID Name Severity Category <code>HIPAA-164.312(a)</code> Access Control CRITICAL access_control <code>HIPAA-164.312(b)</code> Audit Controls HIGH audit <code>HIPAA-164.312(c)</code> Integrity Controls HIGH integrity <code>HIPAA-164.312(d)</code> Authentication CRITICAL authentication <code>HIPAA-164.312(e)</code> Transmission Security HIGH transmission <code>HIPAA-164.502</code> Uses and Disclosures CRITICAL privacy <code>HIPAA-164.514</code> De-identification HIGH privacy <code>HIPAA-164.530</code> Administrative Requirements MEDIUM privacy"},{"location":"api/frameworks/#phi-detection","title":"PHI Detection","text":"<p>Rules only apply when <code>data_classification</code> contains:</p> <ul> <li><code>\"PHI\"</code></li> <li><code>\"ePHI\"</code></li> <li><code>\"protected_health_information\"</code></li> <li><code>\"health_data\"</code></li> <li><code>\"medical\"</code></li> <li><code>\"clinical\"</code></li> </ul>"},{"location":"api/frameworks/#usage_2","title":"Usage","text":"<pre><code>from rotalabs_comply.frameworks.hipaa import HIPAAFramework\n\nframework = HIPAAFramework()\n\n# PHI-related entry (rules apply)\nentry = AuditEntry(\n    entry_id=\"hipaa-001\",\n    timestamp=datetime.utcnow(),\n    event_type=\"inference\",\n    actor=\"doctor@hospital.com\",\n    action=\"AI diagnostic\",\n    data_classification=\"PHI\",\n    metadata={\n        \"access_controlled\": True,\n        \"encryption_enabled\": True,\n        \"authenticated\": True,\n        \"purpose_documented\": True,\n        \"minimum_necessary_applied\": True,\n    },\n)\n\nresult = await framework.check(entry, profile)\n</code></pre>"},{"location":"api/frameworks/#key-requirements_2","title":"Key Requirements","text":"<p>All PHI access requires: - Authenticated actor - <code>metadata[\"access_controlled\"]=True</code> - <code>metadata[\"encryption_enabled\"]=True</code></p> <p>High-risk PHI operations require: - <code>metadata[\"mfa_verified\"]=True</code></p> <p>PHI use requires: - <code>metadata[\"purpose_documented\"]=True</code> - <code>metadata[\"minimum_necessary_applied\"]=True</code></p>"},{"location":"api/frameworks/#gdpr-framework","title":"GDPR Framework","text":"<p>GDPR (EU General Data Protection Regulation 2016/679) compliance framework for processing personal data.</p>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.gdpr.GDPRFramework","title":"GDPRFramework","text":"<p>GDPR compliance framework.</p> <p>Implements compliance checks based on the General Data Protection Regulation (GDPR) requirements for processing personal data. The framework evaluates audit entries against the Regulation's requirements for data protection, consent, transparency, data subject rights, security, and accountability.</p> <p>The GDPR applies to: - Organizations established in the EU processing personal data - Organizations outside the EU offering goods/services to EU residents - Organizations monitoring behavior of individuals in the EU</p> <p>Key principles enforced: - Lawfulness, fairness, and transparency - Purpose limitation - Data minimization - Accuracy - Storage limitation - Integrity and confidentiality - Accountability</p> Example <p>framework = GDPRFramework() result = await framework.check(entry, profile) if not result.is_compliant: ...     for violation in result.violations: ...         print(f\"{violation.rule_id}: {violation.description}\")</p> Source code in <code>src/rotalabs_comply/frameworks/gdpr.py</code> <pre><code>class GDPRFramework(BaseFramework):\n    \"\"\"\n    GDPR compliance framework.\n\n    Implements compliance checks based on the General Data Protection Regulation\n    (GDPR) requirements for processing personal data. The framework evaluates\n    audit entries against the Regulation's requirements for data protection,\n    consent, transparency, data subject rights, security, and accountability.\n\n    The GDPR applies to:\n    - Organizations established in the EU processing personal data\n    - Organizations outside the EU offering goods/services to EU residents\n    - Organizations monitoring behavior of individuals in the EU\n\n    Key principles enforced:\n    - Lawfulness, fairness, and transparency\n    - Purpose limitation\n    - Data minimization\n    - Accuracy\n    - Storage limitation\n    - Integrity and confidentiality\n    - Accountability\n\n    Example:\n        &gt;&gt;&gt; framework = GDPRFramework()\n        &gt;&gt;&gt; result = await framework.check(entry, profile)\n        &gt;&gt;&gt; if not result.is_compliant:\n        ...     for violation in result.violations:\n        ...         print(f\"{violation.rule_id}: {violation.description}\")\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the GDPR framework with all defined rules.\"\"\"\n        rules = self._create_rules()\n        super().__init__(name=\"GDPR\", version=\"2016/679\", rules=rules)\n\n    def _create_rules(self) -&gt; List[ComplianceRule]:\n        \"\"\"\n        Create all GDPR compliance rules.\n\n        Returns:\n            List of ComplianceRule objects representing GDPR requirements\n        \"\"\"\n        return [\n            ComplianceRule(\n                rule_id=\"GDPR-Art5\",\n                name=\"Data Processing Principles\",\n                description=(\n                    \"Personal data shall be processed lawfully, fairly and in a transparent \"\n                    \"manner in relation to the data subject ('lawfulness, fairness and \"\n                    \"transparency'). Data must be collected for specified, explicit and \"\n                    \"legitimate purposes and not further processed in a manner incompatible \"\n                    \"with those purposes. Data shall be adequate, relevant and limited to \"\n                    \"what is necessary ('data minimisation'), accurate and kept up to date, \"\n                    \"kept for no longer than necessary ('storage limitation'), and processed \"\n                    \"in a manner that ensures appropriate security ('integrity and \"\n                    \"confidentiality'). The controller shall be responsible for, and be able \"\n                    \"to demonstrate compliance with these principles ('accountability'). \"\n                    \"(Article 5)\"\n                ),\n                severity=RiskLevel.CRITICAL,\n                category=\"data_protection\",\n                remediation=(\n                    \"Ensure all personal data processing adheres to GDPR principles: \"\n                    \"1) Document the lawful basis for processing, 2) Limit data collection \"\n                    \"to what is necessary, 3) Implement data accuracy checks, 4) Define \"\n                    \"retention periods, 5) Apply appropriate security measures, and \"\n                    \"6) Maintain records demonstrating compliance.\"\n                ),\n                references=[\"GDPR Article 5(1)(2)\", \"Recitals 39-47\"],\n            ),\n            ComplianceRule(\n                rule_id=\"GDPR-Art6\",\n                name=\"Lawful Basis for Processing\",\n                description=(\n                    \"Processing shall be lawful only if and to the extent that at least one \"\n                    \"of the following applies: (a) consent, (b) contract necessity, \"\n                    \"(c) legal obligation, (d) vital interests, (e) public interest or \"\n                    \"official authority, or (f) legitimate interests (except where \"\n                    \"overridden by data subject's interests or fundamental rights). Each \"\n                    \"processing activity must have a documented legal basis before \"\n                    \"processing begins. (Article 6)\"\n                ),\n                severity=RiskLevel.CRITICAL,\n                category=\"legal_basis\",\n                remediation=(\n                    \"Identify and document the appropriate lawful basis for each processing \"\n                    \"activity before processing begins. For consent, ensure it meets GDPR \"\n                    \"requirements. For legitimate interests, conduct a balancing test. \"\n                    \"Record the lawful basis in your processing records and privacy notices.\"\n                ),\n                references=[\"GDPR Article 6(1)\", \"Recitals 40-50\"],\n            ),\n            ComplianceRule(\n                rule_id=\"GDPR-Art7\",\n                name=\"Conditions for Consent\",\n                description=(\n                    \"Where processing is based on consent, the controller shall be able to \"\n                    \"demonstrate that the data subject has consented to processing. Consent \"\n                    \"must be freely given, specific, informed and unambiguous. The request \"\n                    \"for consent shall be presented in a manner clearly distinguishable from \"\n                    \"other matters, in an intelligible and easily accessible form, using \"\n                    \"clear and plain language. The data subject shall have the right to \"\n                    \"withdraw consent at any time, and withdrawal must be as easy as giving \"\n                    \"consent. (Article 7)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"consent\",\n                remediation=(\n                    \"Implement consent mechanisms that: 1) Require affirmative action \"\n                    \"(no pre-ticked boxes), 2) Are specific to each processing purpose, \"\n                    \"3) Provide clear information about data use, 4) Are separate from \"\n                    \"other terms, 5) Allow easy withdrawal, and 6) Maintain consent records. \"\n                    \"Regularly review and refresh consent where appropriate.\"\n                ),\n                references=[\"GDPR Article 7(1-4)\", \"Recitals 32, 42, 43\"],\n            ),\n            ComplianceRule(\n                rule_id=\"GDPR-Art12\",\n                name=\"Transparent Information and Communication\",\n                description=(\n                    \"The controller shall take appropriate measures to provide any \"\n                    \"information referred to in Articles 13 and 14 and any communication \"\n                    \"under Articles 15 to 22 relating to processing to the data subject \"\n                    \"in a concise, transparent, intelligible and easily accessible form, \"\n                    \"using clear and plain language. Information shall be provided in \"\n                    \"writing, or by other means including electronic means. The controller \"\n                    \"shall facilitate the exercise of data subject rights. (Article 12)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"transparency\",\n                remediation=(\n                    \"Develop clear, accessible privacy notices using plain language. \"\n                    \"Provide information through multiple channels (website, app, paper). \"\n                    \"Establish procedures to respond to data subject requests within one \"\n                    \"month. Train staff on handling requests. Use layered approaches for \"\n                    \"complex information. Test readability of notices.\"\n                ),\n                references=[\"GDPR Article 12(1-6)\", \"Recitals 58-59\"],\n            ),\n            ComplianceRule(\n                rule_id=\"GDPR-Art13\",\n                name=\"Information at Collection\",\n                description=(\n                    \"Where personal data are collected from the data subject, the controller \"\n                    \"shall, at the time when personal data are obtained, provide the data \"\n                    \"subject with: controller identity and contact details, DPO contact \"\n                    \"details, purposes and legal basis for processing, legitimate interests \"\n                    \"pursued, recipients or categories of recipients, intention to transfer \"\n                    \"data to third countries, retention period, data subject rights, right \"\n                    \"to withdraw consent, right to lodge complaint, whether provision is \"\n                    \"statutory/contractual requirement, and existence of automated \"\n                    \"decision-making including profiling. (Article 13)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"transparency\",\n                remediation=(\n                    \"Create comprehensive privacy notices that include all required \"\n                    \"information under Article 13. Provide this information at the point \"\n                    \"of data collection. For AI systems, clearly explain any automated \"\n                    \"decision-making, profiling, and the logic involved. Update notices \"\n                    \"when processing changes.\"\n                ),\n                references=[\"GDPR Article 13(1-3)\", \"Recitals 60-62\"],\n            ),\n            ComplianceRule(\n                rule_id=\"GDPR-Art15\",\n                name=\"Right of Access\",\n                description=(\n                    \"The data subject shall have the right to obtain from the controller \"\n                    \"confirmation as to whether or not personal data concerning him or her \"\n                    \"are being processed, and, where that is the case, access to the personal \"\n                    \"data and information including: purposes of processing, categories of \"\n                    \"data, recipients, retention period, existence of rights (rectification, \"\n                    \"erasure, restriction, objection), right to lodge complaint, source of \"\n                    \"data, and existence of automated decision-making. The controller shall \"\n                    \"provide a copy of the personal data undergoing processing. (Article 15)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"data_subject_rights\",\n                remediation=(\n                    \"Implement systems to: 1) Verify data subject identity, 2) Search and \"\n                    \"retrieve all personal data across systems, 3) Generate comprehensive \"\n                    \"response within one month, 4) Provide data in commonly used electronic \"\n                    \"format, 5) Include all supplementary information required. Establish \"\n                    \"processes for handling complex or repeated requests.\"\n                ),\n                references=[\"GDPR Article 15(1-4)\", \"Recitals 63-64\"],\n            ),\n            ComplianceRule(\n                rule_id=\"GDPR-Art17\",\n                name=\"Right to Erasure (Right to be Forgotten)\",\n                description=(\n                    \"The data subject shall have the right to obtain from the controller the \"\n                    \"erasure of personal data without undue delay where: data no longer \"\n                    \"necessary for original purposes, consent withdrawn, data subject objects \"\n                    \"and no overriding legitimate grounds, data unlawfully processed, legal \"\n                    \"obligation requires erasure, or data collected in relation to offer of \"\n                    \"information society services to a child. Where data has been made public, \"\n                    \"the controller must take reasonable steps to inform other controllers \"\n                    \"processing the data. Exceptions apply for legal claims, legal obligations, \"\n                    \"public health, archiving, and research. (Article 17)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"data_subject_rights\",\n                remediation=(\n                    \"Implement erasure capabilities that: 1) Can identify all instances of \"\n                    \"personal data, 2) Securely delete data from all systems including backups, \"\n                    \"3) Notify third parties who received the data, 4) Document the erasure \"\n                    \"process, and 5) Respond within one month. For AI systems, consider \"\n                    \"whether data in training sets can be removed or models retrained.\"\n                ),\n                references=[\"GDPR Article 17(1-3)\", \"Recitals 65-66\"],\n            ),\n            ComplianceRule(\n                rule_id=\"GDPR-Art20\",\n                name=\"Right to Data Portability\",\n                description=(\n                    \"The data subject shall have the right to receive personal data concerning \"\n                    \"him or her, which he or she has provided to a controller, in a structured, \"\n                    \"commonly used and machine-readable format and have the right to transmit \"\n                    \"those data to another controller without hindrance where: processing is \"\n                    \"based on consent or contract, and processing is carried out by automated \"\n                    \"means. The data subject shall have the right to have data transmitted \"\n                    \"directly from one controller to another, where technically feasible. \"\n                    \"(Article 20)\"\n                ),\n                severity=RiskLevel.MEDIUM,\n                category=\"data_subject_rights\",\n                remediation=(\n                    \"Implement data export functionality that: 1) Provides data in structured, \"\n                    \"machine-readable formats (JSON, CSV, XML), 2) Includes all data provided \"\n                    \"by the data subject, 3) Allows direct transmission to other controllers \"\n                    \"where feasible, 4) Responds within one month. Distinguish between data \"\n                    \"'provided' by the subject and data 'derived' through processing.\"\n                ),\n                references=[\"GDPR Article 20(1-4)\", \"Recital 68\"],\n            ),\n            ComplianceRule(\n                rule_id=\"GDPR-Art22\",\n                name=\"Automated Decision-Making and Profiling\",\n                description=(\n                    \"The data subject shall have the right not to be subject to a decision \"\n                    \"based solely on automated processing, including profiling, which produces \"\n                    \"legal effects concerning him or her or similarly significantly affects \"\n                    \"him or her. This does not apply if the decision: is necessary for a \"\n                    \"contract, is authorised by law, or is based on explicit consent. In \"\n                    \"those cases, the controller shall implement suitable measures to safeguard \"\n                    \"the data subject's rights and freedoms and legitimate interests, at least \"\n                    \"the right to obtain human intervention, to express his or her point of \"\n                    \"view and to contest the decision. (Article 22)\"\n                ),\n                severity=RiskLevel.CRITICAL,\n                category=\"data_subject_rights\",\n                remediation=(\n                    \"For AI systems making automated decisions: 1) Implement human review \"\n                    \"mechanisms for decisions with legal or significant effects, 2) Provide \"\n                    \"meaningful information about the logic involved, 3) Allow data subjects \"\n                    \"to express their views and contest decisions, 4) Conduct DPIAs for \"\n                    \"profiling activities, and 5) Document the necessity and safeguards. \"\n                    \"Consider whether purely automated decisions can be avoided.\"\n                ),\n                references=[\"GDPR Article 22(1-4)\", \"Recitals 71-72\"],\n            ),\n            ComplianceRule(\n                rule_id=\"GDPR-Art25\",\n                name=\"Data Protection by Design and Default\",\n                description=(\n                    \"The controller shall, both at the time of the determination of the means \"\n                    \"for processing and at the time of the processing itself, implement \"\n                    \"appropriate technical and organisational measures designed to implement \"\n                    \"data-protection principles (such as data minimisation) in an effective \"\n                    \"manner and to integrate the necessary safeguards into the processing. \"\n                    \"The controller shall implement appropriate measures for ensuring that, \"\n                    \"by default, only personal data which are necessary for each specific \"\n                    \"purpose of the processing are processed. (Article 25)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"accountability\",\n                remediation=(\n                    \"Embed privacy into system design from the outset: 1) Conduct privacy \"\n                    \"impact assessments during development, 2) Implement data minimisation \"\n                    \"by default, 3) Use pseudonymisation and encryption, 4) Build in consent \"\n                    \"mechanisms, 5) Design for data subject rights, 6) Limit access by default, \"\n                    \"7) Document design decisions. Review and update as technology evolves.\"\n                ),\n                references=[\"GDPR Article 25(1-3)\", \"Recitals 78\"],\n            ),\n            ComplianceRule(\n                rule_id=\"GDPR-Art30\",\n                name=\"Records of Processing Activities\",\n                description=(\n                    \"Each controller shall maintain a record of processing activities under \"\n                    \"its responsibility. That record shall contain: name and contact details \"\n                    \"of controller and DPO, purposes of processing, description of categories \"\n                    \"of data subjects and personal data, categories of recipients, transfers \"\n                    \"to third countries, retention periods, and description of technical and \"\n                    \"organisational security measures. These records shall be in writing, \"\n                    \"including electronic form, and made available to the supervisory \"\n                    \"authority on request. (Article 30)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"accountability\",\n                remediation=(\n                    \"Create and maintain comprehensive records of all processing activities \"\n                    \"(ROPA) that include all required elements. Review and update records \"\n                    \"regularly. Ensure records cover all systems including AI/ML systems. \"\n                    \"Use a consistent format that can be provided to supervisory authorities. \"\n                    \"Train staff responsible for maintaining records.\"\n                ),\n                references=[\"GDPR Article 30(1-5)\", \"Recital 82\"],\n            ),\n            ComplianceRule(\n                rule_id=\"GDPR-Art32\",\n                name=\"Security of Processing\",\n                description=(\n                    \"The controller and processor shall implement appropriate technical and \"\n                    \"organisational measures to ensure a level of security appropriate to the \"\n                    \"risk, including as appropriate: (a) pseudonymisation and encryption of \"\n                    \"personal data, (b) ability to ensure ongoing confidentiality, integrity, \"\n                    \"availability and resilience of systems, (c) ability to restore \"\n                    \"availability and access to data in timely manner following an incident, \"\n                    \"(d) process for regularly testing, assessing and evaluating effectiveness \"\n                    \"of measures. The controller and processor shall take steps to ensure any \"\n                    \"person acting under their authority with access to personal data processes \"\n                    \"only on instructions. (Article 32)\"\n                ),\n                severity=RiskLevel.CRITICAL,\n                category=\"security\",\n                remediation=(\n                    \"Implement security measures appropriate to the risk: 1) Encrypt personal \"\n                    \"data in transit and at rest, 2) Implement access controls and \"\n                    \"authentication, 3) Maintain backup and recovery procedures, 4) Conduct \"\n                    \"regular security testing and audits, 5) Train personnel on security \"\n                    \"procedures, 6) Document security measures. For AI systems, also consider \"\n                    \"model security and adversarial robustness.\"\n                ),\n                references=[\"GDPR Article 32(1-4)\", \"Recitals 83\"],\n            ),\n            ComplianceRule(\n                rule_id=\"GDPR-Art33\",\n                name=\"Personal Data Breach Notification\",\n                description=(\n                    \"In the case of a personal data breach, the controller shall without \"\n                    \"undue delay and, where feasible, not later than 72 hours after having \"\n                    \"become aware of it, notify the personal data breach to the supervisory \"\n                    \"authority, unless the breach is unlikely to result in a risk to rights \"\n                    \"and freedoms. Where notification is not made within 72 hours, it shall \"\n                    \"be accompanied by reasons for the delay. The notification shall describe: \"\n                    \"nature of breach including categories and approximate numbers of data \"\n                    \"subjects and records, DPO contact details, likely consequences, and \"\n                    \"measures taken or proposed to address the breach. (Article 33)\"\n                ),\n                severity=RiskLevel.CRITICAL,\n                category=\"security\",\n                remediation=(\n                    \"Establish breach detection and response procedures: 1) Implement \"\n                    \"monitoring to detect breaches quickly, 2) Create incident response plan \"\n                    \"with clear escalation paths, 3) Prepare notification templates, \"\n                    \"4) Document all breaches in a breach register, 5) Conduct post-incident \"\n                    \"reviews, 6) Train staff on breach identification and reporting. \"\n                    \"Ensure 72-hour notification capability is tested.\"\n                ),\n                references=[\"GDPR Article 33(1-5)\", \"Recitals 85-88\"],\n            ),\n            ComplianceRule(\n                rule_id=\"GDPR-Art35\",\n                name=\"Data Protection Impact Assessment\",\n                description=(\n                    \"Where a type of processing, in particular using new technologies, and \"\n                    \"taking into account the nature, scope, context and purposes of the \"\n                    \"processing, is likely to result in a high risk to the rights and freedoms \"\n                    \"of natural persons, the controller shall, prior to the processing, carry \"\n                    \"out an assessment of the impact of the envisaged processing operations \"\n                    \"on the protection of personal data. A DPIA is required in particular for: \"\n                    \"(a) systematic and extensive evaluation of personal aspects based on \"\n                    \"automated processing, including profiling, (b) large scale processing of \"\n                    \"special categories of data or criminal convictions data, (c) systematic \"\n                    \"monitoring of a publicly accessible area on a large scale. (Article 35)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"accountability\",\n                remediation=(\n                    \"Conduct DPIAs for high-risk processing, especially AI/ML systems: \"\n                    \"1) Describe processing operations and purposes, 2) Assess necessity \"\n                    \"and proportionality, 3) Identify and assess risks to data subjects, \"\n                    \"4) Identify measures to address risks, 5) Consult with DPO, \"\n                    \"6) Review and update as processing changes. For new AI systems, \"\n                    \"complete DPIA before deployment.\"\n                ),\n                references=[\"GDPR Article 35(1-11)\", \"Recitals 89-92\"],\n            ),\n        ]\n\n    def _check_rule(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check a single GDPR rule against an audit entry.\n\n        Evaluates the audit entry against the specific rule requirements\n        and returns a violation if the entry does not comply.\n\n        Args:\n            entry: The audit entry to check\n            rule: The rule to evaluate\n\n        Returns:\n            ComplianceViolation if the rule is violated, None otherwise\n        \"\"\"\n        # Use custom check function if provided\n        if rule.check_fn is not None:\n            is_compliant = rule.check_fn(entry)\n            if not is_compliant:\n                return self._create_violation(entry, rule, \"Custom check failed\")\n            return None\n\n        # Framework-specific rule checks\n        if rule.rule_id == \"GDPR-Art5\":\n            return self._check_data_processing_principles(entry, rule)\n        elif rule.rule_id == \"GDPR-Art6\":\n            return self._check_lawful_basis(entry, rule)\n        elif rule.rule_id == \"GDPR-Art7\":\n            return self._check_consent(entry, rule)\n        elif rule.rule_id == \"GDPR-Art12\":\n            return self._check_transparent_communication(entry, rule)\n        elif rule.rule_id == \"GDPR-Art13\":\n            return self._check_information_at_collection(entry, rule)\n        elif rule.rule_id == \"GDPR-Art15\":\n            return self._check_right_of_access(entry, rule)\n        elif rule.rule_id == \"GDPR-Art17\":\n            return self._check_right_to_erasure(entry, rule)\n        elif rule.rule_id == \"GDPR-Art20\":\n            return self._check_data_portability(entry, rule)\n        elif rule.rule_id == \"GDPR-Art22\":\n            return self._check_automated_decision_making(entry, rule)\n        elif rule.rule_id == \"GDPR-Art25\":\n            return self._check_privacy_by_design(entry, rule)\n        elif rule.rule_id == \"GDPR-Art30\":\n            return self._check_processing_records(entry, rule)\n        elif rule.rule_id == \"GDPR-Art32\":\n            return self._check_security(entry, rule)\n        elif rule.rule_id == \"GDPR-Art33\":\n            return self._check_breach_notification(entry, rule)\n        elif rule.rule_id == \"GDPR-Art35\":\n            return self._check_dpia(entry, rule)\n\n        return None\n\n    def _check_data_processing_principles(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check GDPR-Art5: Data processing must follow core GDPR principles.\n\n        Operations involving personal data must demonstrate compliance with\n        lawfulness, fairness, transparency, purpose limitation, data minimisation,\n        accuracy, storage limitation, integrity, confidentiality, and accountability.\n        \"\"\"\n        # Check if processing involves personal data\n        pii_classifications = {\"pii\", \"personal\", \"sensitive\", \"special_category\"}\n        if entry.data_classification.lower() not in pii_classifications:\n            return None\n\n        # Check for documented principles compliance\n        has_lawful_basis = entry.metadata.get(\"lawful_basis_documented\", False)\n        has_purpose_limitation = entry.metadata.get(\"purpose_documented\", False)\n\n        if not (has_lawful_basis and has_purpose_limitation):\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Personal data processing (classification={entry.data_classification}) \"\n                f\"without documented lawful basis or purpose limitation\",\n            )\n        return None\n\n    def _check_lawful_basis(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check GDPR-Art6: Processing must have a documented lawful basis.\n\n        Each processing operation must identify one of the six lawful bases:\n        consent, contract, legal obligation, vital interests, public interest,\n        or legitimate interests.\n        \"\"\"\n        pii_classifications = {\"pii\", \"personal\", \"sensitive\", \"special_category\"}\n        if entry.data_classification.lower() not in pii_classifications:\n            return None\n\n        lawful_basis = entry.metadata.get(\"lawful_basis\")\n        valid_bases = {\n            \"consent\", \"contract\", \"legal_obligation\",\n            \"vital_interests\", \"public_interest\", \"legitimate_interests\"\n        }\n\n        if not lawful_basis or lawful_basis.lower() not in valid_bases:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Personal data processing (classification={entry.data_classification}) \"\n                f\"without valid lawful basis. Provided: {lawful_basis or 'None'}\",\n            )\n        return None\n\n    def _check_consent(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check GDPR-Art7: When consent is the lawful basis, it must meet requirements.\n\n        Consent must be freely given, specific, informed, unambiguous, and\n        demonstrable. The data subject must be able to withdraw consent easily.\n        \"\"\"\n        # Only applies when consent is the lawful basis\n        lawful_basis = entry.metadata.get(\"lawful_basis\", \"\").lower()\n        if lawful_basis != \"consent\":\n            return None\n\n        consent_recorded = entry.metadata.get(\"consent_recorded\", False)\n        consent_specific = entry.metadata.get(\"consent_specific\", False)\n        consent_informed = entry.metadata.get(\"consent_informed\", False)\n\n        if not all([consent_recorded, consent_specific, consent_informed]):\n            missing = []\n            if not consent_recorded:\n                missing.append(\"recorded\")\n            if not consent_specific:\n                missing.append(\"specific\")\n            if not consent_informed:\n                missing.append(\"informed\")\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Consent-based processing without valid consent. Missing: {', '.join(missing)}\",\n            )\n        return None\n\n    def _check_transparent_communication(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check GDPR-Art12: Information must be provided transparently.\n\n        Communications about data processing must be concise, transparent,\n        intelligible, and easily accessible, using clear and plain language.\n        \"\"\"\n        # Check for user-facing data collection events\n        collection_events = {\"data_collection\", \"registration\", \"signup\", \"form_submission\"}\n        if entry.event_type.lower() not in collection_events:\n            return None\n\n        privacy_notice_provided = entry.metadata.get(\"privacy_notice_provided\", False)\n        if not privacy_notice_provided:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Data collection event (type={entry.event_type}) without \"\n                f\"transparent privacy information provided to data subject\",\n            )\n        return None\n\n    def _check_information_at_collection(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check GDPR-Art13: Required information must be provided at collection.\n\n        When collecting personal data, data subjects must receive comprehensive\n        information about the processing including controller identity, purposes,\n        legal basis, rights, and retention periods.\n        \"\"\"\n        collection_events = {\"data_collection\", \"registration\", \"signup\", \"form_submission\"}\n        if entry.event_type.lower() not in collection_events:\n            return None\n\n        pii_classifications = {\"pii\", \"personal\", \"sensitive\", \"special_category\"}\n        if entry.data_classification.lower() not in pii_classifications:\n            return None\n\n        disclosure_complete = entry.metadata.get(\"art13_disclosure_complete\", False)\n        if not disclosure_complete:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Personal data collection (type={entry.event_type}) without \"\n                f\"complete Article 13 information disclosure\",\n            )\n        return None\n\n    def _check_right_of_access(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check GDPR-Art15: Data subject access requests must be handled properly.\n\n        When a data subject requests access, the controller must provide\n        confirmation of processing and a copy of personal data within one month.\n        \"\"\"\n        access_events = {\"data_subject_access_request\", \"dsar\", \"subject_access_request\"}\n        if entry.event_type.lower() not in access_events:\n            return None\n\n        response_within_deadline = entry.metadata.get(\"response_within_deadline\", False)\n        complete_response = entry.metadata.get(\"complete_response_provided\", False)\n\n        if not response_within_deadline:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Data subject access request (type={entry.event_type}) not \"\n                f\"responded to within the required timeframe\",\n            )\n\n        if not complete_response:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Data subject access request (type={entry.event_type}) response \"\n                f\"incomplete - must include all personal data and required information\",\n            )\n        return None\n\n    def _check_right_to_erasure(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check GDPR-Art17: Erasure requests must be handled properly.\n\n        When a data subject requests erasure and it is valid, the controller\n        must erase data without undue delay and notify third parties.\n        \"\"\"\n        erasure_events = {\"erasure_request\", \"deletion_request\", \"right_to_be_forgotten\"}\n        if entry.event_type.lower() not in erasure_events:\n            return None\n\n        erasure_complete = entry.metadata.get(\"erasure_complete\", False)\n        third_parties_notified = entry.metadata.get(\"third_parties_notified\", True)  # Default True if N/A\n\n        if not erasure_complete:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Erasure request (type={entry.event_type}) not completed - \"\n                f\"personal data must be erased from all systems\",\n            )\n\n        if not third_parties_notified:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Erasure request (type={entry.event_type}) - third party \"\n                f\"recipients of data not notified of erasure requirement\",\n            )\n        return None\n\n    def _check_data_portability(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check GDPR-Art20: Portability requests must provide data in machine-readable format.\n\n        Data subjects have the right to receive their data in a structured,\n        commonly used, and machine-readable format.\n        \"\"\"\n        portability_events = {\"portability_request\", \"data_export_request\"}\n        if entry.event_type.lower() not in portability_events:\n            return None\n\n        machine_readable_format = entry.metadata.get(\"machine_readable_format\", False)\n        if not machine_readable_format:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Data portability request (type={entry.event_type}) - data not \"\n                f\"provided in structured, machine-readable format\",\n            )\n        return None\n\n    def _check_automated_decision_making(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check GDPR-Art22: Automated decisions with significant effects need safeguards.\n\n        Data subjects have the right not to be subject to solely automated\n        decisions with legal or similarly significant effects without safeguards.\n        \"\"\"\n        automated_decision_events = {\n            \"automated_decision\", \"profiling\", \"scoring\",\n            \"credit_decision\", \"hiring_decision\", \"eligibility_decision\"\n        }\n        if entry.event_type.lower() not in automated_decision_events:\n            return None\n\n        # Check if decision has significant effects\n        has_significant_effect = entry.metadata.get(\"significant_effect\", False)\n        if not has_significant_effect:\n            return None\n\n        # Check for required safeguards\n        human_intervention_available = entry.metadata.get(\"human_intervention_available\", False)\n        right_to_contest_enabled = entry.metadata.get(\"right_to_contest_enabled\", False)\n        logic_explained = entry.metadata.get(\"logic_explained\", False)\n\n        if not human_intervention_available:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Automated decision with significant effect (type={entry.event_type}) \"\n                f\"without human intervention mechanism available\",\n            )\n\n        if not right_to_contest_enabled:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Automated decision with significant effect (type={entry.event_type}) \"\n                f\"without right to contest the decision\",\n            )\n\n        if not logic_explained:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Automated decision with significant effect (type={entry.event_type}) \"\n                f\"without meaningful information about the logic involved\",\n            )\n        return None\n\n    def _check_privacy_by_design(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check GDPR-Art25: Systems must implement privacy by design and default.\n\n        Controllers must implement technical and organisational measures\n        to implement data protection principles and ensure minimal data\n        processing by default.\n        \"\"\"\n        design_events = {\"system_deployment\", \"feature_launch\", \"processing_change\"}\n        if entry.event_type.lower() not in design_events:\n            return None\n\n        privacy_by_design_assessment = entry.metadata.get(\"privacy_by_design_assessment\", False)\n        data_minimisation_default = entry.metadata.get(\"data_minimisation_default\", False)\n\n        if not privacy_by_design_assessment:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"System deployment/change (type={entry.event_type}) without \"\n                f\"documented privacy by design assessment\",\n            )\n\n        if not data_minimisation_default:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"System deployment/change (type={entry.event_type}) without \"\n                f\"data minimisation implemented by default\",\n            )\n        return None\n\n    def _check_processing_records(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check GDPR-Art30: Records of processing activities must be maintained.\n\n        Controllers must maintain written records of processing activities\n        including purposes, data categories, recipients, and security measures.\n        \"\"\"\n        pii_classifications = {\"pii\", \"personal\", \"sensitive\", \"special_category\"}\n        if entry.data_classification.lower() not in pii_classifications:\n            return None\n\n        # Check for significant processing operations\n        significant_events = {\"data_processing\", \"data_transfer\", \"new_processing_activity\"}\n        if entry.event_type.lower() not in significant_events:\n            return None\n\n        ropa_entry_exists = entry.metadata.get(\"ropa_entry_exists\", False)\n        if not ropa_entry_exists:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Processing activity (type={entry.event_type}) not recorded in \"\n                f\"the Records of Processing Activities (ROPA)\",\n            )\n        return None\n\n    def _check_security(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check GDPR-Art32: Appropriate security measures must be in place.\n\n        Processing must implement security measures appropriate to the risk,\n        including encryption, access controls, and regular security testing.\n        \"\"\"\n        pii_classifications = {\"pii\", \"personal\", \"sensitive\", \"special_category\"}\n        if entry.data_classification.lower() not in pii_classifications:\n            return None\n\n        # Check for security-relevant operations\n        security_relevant_events = {\n            \"data_access\", \"data_transfer\", \"data_processing\",\n            \"data_export\", \"api_call\", \"model_inference\"\n        }\n        if entry.event_type.lower() not in security_relevant_events:\n            return None\n\n        encryption_applied = entry.metadata.get(\"encryption_applied\", False)\n        access_controlled = entry.metadata.get(\"access_controlled\", False)\n\n        if not encryption_applied:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Personal data operation (type={entry.event_type}) without \"\n                f\"appropriate encryption measures\",\n            )\n\n        if not access_controlled:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Personal data operation (type={entry.event_type}) without \"\n                f\"appropriate access control measures\",\n            )\n        return None\n\n    def _check_breach_notification(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check GDPR-Art33: Breaches must be notified within 72 hours.\n\n        Personal data breaches must be notified to the supervisory authority\n        within 72 hours of becoming aware, unless unlikely to result in risk.\n        \"\"\"\n        breach_events = {\"data_breach\", \"security_incident\", \"unauthorized_access\"}\n        if entry.event_type.lower() not in breach_events:\n            return None\n\n        # Check if this is a reportable breach\n        risk_to_rights = entry.metadata.get(\"risk_to_rights_freedoms\", True)\n        if not risk_to_rights:\n            return None  # No notification required if no risk\n\n        notification_sent = entry.metadata.get(\"supervisory_authority_notified\", False)\n        notification_within_72h = entry.metadata.get(\"notification_within_72_hours\", False)\n\n        if not notification_sent:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Personal data breach (type={entry.event_type}) not notified \"\n                f\"to supervisory authority\",\n            )\n\n        if not notification_within_72h:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Personal data breach (type={entry.event_type}) notification \"\n                f\"exceeded 72-hour requirement without documented justification\",\n            )\n        return None\n\n    def _check_dpia(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check GDPR-Art35: High-risk processing requires DPIA.\n\n        A Data Protection Impact Assessment is required for processing\n        likely to result in high risk, including profiling, large-scale\n        special category processing, and systematic monitoring.\n        \"\"\"\n        # Check for high-risk processing types\n        high_risk_events = {\n            \"profiling\", \"automated_decision\", \"large_scale_processing\",\n            \"systematic_monitoring\", \"special_category_processing\",\n            \"new_technology_deployment\", \"ai_model_deployment\"\n        }\n        if entry.event_type.lower() not in high_risk_events:\n            return None\n\n        # Also trigger for high-risk level entries\n        if entry.risk_level not in (RiskLevel.HIGH, RiskLevel.CRITICAL):\n            return None\n\n        dpia_completed = entry.metadata.get(\"dpia_completed\", False)\n        dpia_reviewed = entry.metadata.get(\"dpia_reviewed_by_dpo\", False)\n\n        if not dpia_completed:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"High-risk processing (type={entry.event_type}) commenced \"\n                f\"without completing Data Protection Impact Assessment\",\n            )\n\n        if not dpia_reviewed:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"High-risk processing (type={entry.event_type}) DPIA not \"\n                f\"reviewed by Data Protection Officer\",\n            )\n        return None\n\n    def _create_violation(\n        self, entry: AuditEntry, rule: ComplianceRule, evidence: str\n    ) -&gt; ComplianceViolation:\n        \"\"\"\n        Create a compliance violation object.\n\n        Args:\n            entry: The audit entry that triggered the violation\n            rule: The rule that was violated\n            evidence: Specific evidence describing the violation\n\n        Returns:\n            ComplianceViolation object\n        \"\"\"\n        return ComplianceViolation(\n            rule_id=rule.rule_id,\n            rule_name=rule.name,\n            severity=rule.severity,\n            description=rule.description,\n            evidence=evidence,\n            remediation=rule.remediation,\n            entry_id=entry.entry_id,\n            category=rule.category,\n            framework=self._name,\n        )\n</code></pre>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.gdpr.GDPRFramework.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> <p>Initialize the GDPR framework with all defined rules.</p> Source code in <code>src/rotalabs_comply/frameworks/gdpr.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize the GDPR framework with all defined rules.\"\"\"\n    rules = self._create_rules()\n    super().__init__(name=\"GDPR\", version=\"2016/679\", rules=rules)\n</code></pre>"},{"location":"api/frameworks/#categories_3","title":"Categories","text":"Category Description <code>data_protection</code> Core data protection principles (Article 5) <code>legal_basis</code> Lawful processing requirements (Article 6) <code>consent</code> Valid consent conditions (Article 7) <code>transparency</code> Information provision and communication (Articles 12-13) <code>data_subject_rights</code> Individual rights (Articles 15, 17, 20, 22) <code>security</code> Data security measures (Articles 32-33) <code>accountability</code> Demonstrating compliance (Articles 25, 30, 35)"},{"location":"api/frameworks/#rules_3","title":"Rules","text":"Rule ID Name Category Severity <code>GDPR-Art5</code> Data Processing Principles data_protection CRITICAL <code>GDPR-Art6</code> Lawful Basis for Processing legal_basis CRITICAL <code>GDPR-Art7</code> Conditions for Consent consent HIGH <code>GDPR-Art12</code> Transparent Information and Communication transparency HIGH <code>GDPR-Art13</code> Information at Collection transparency HIGH <code>GDPR-Art15</code> Right of Access data_subject_rights HIGH <code>GDPR-Art17</code> Right to Erasure (Right to be Forgotten) data_subject_rights HIGH <code>GDPR-Art20</code> Right to Data Portability data_subject_rights MEDIUM <code>GDPR-Art22</code> Automated Decision-Making and Profiling data_subject_rights CRITICAL <code>GDPR-Art25</code> Data Protection by Design and Default accountability HIGH <code>GDPR-Art30</code> Records of Processing Activities accountability HIGH <code>GDPR-Art32</code> Security of Processing security CRITICAL <code>GDPR-Art33</code> Personal Data Breach Notification security CRITICAL <code>GDPR-Art35</code> Data Protection Impact Assessment accountability HIGH"},{"location":"api/frameworks/#usage_3","title":"Usage","text":"<pre><code>from rotalabs_comply.frameworks.gdpr import GDPRFramework\nfrom rotalabs_comply.frameworks.base import AuditEntry, ComplianceProfile, RiskLevel\nfrom datetime import datetime\n\nframework = GDPRFramework()\n\nentry = AuditEntry(\n    entry_id=\"gdpr-001\",\n    timestamp=datetime.utcnow(),\n    event_type=\"data_processing\",\n    actor=\"analyst@company.eu\",\n    action=\"Process customer data\",\n    data_classification=\"pii\",\n    metadata={\n        \"lawful_basis_documented\": True,\n        \"lawful_basis\": \"consent\",\n        \"purpose_documented\": True,\n        \"consent_recorded\": True,\n        \"consent_specific\": True,\n        \"consent_informed\": True,\n        \"encryption_applied\": True,\n        \"access_controlled\": True,\n    },\n)\n\nprofile = ComplianceProfile(\n    profile_id=\"gdpr-profile\",\n    name=\"GDPR Compliance\",\n)\n\nresult = await framework.check(entry, profile)\n</code></pre>"},{"location":"api/frameworks/#key-requirements_3","title":"Key Requirements","text":"<p>Personal data processing requires: - <code>data_classification</code> set to \"pii\", \"personal\", \"sensitive\", or \"special_category\" - <code>metadata[\"lawful_basis_documented\"]=True</code> - <code>metadata[\"purpose_documented\"]=True</code> - <code>metadata[\"lawful_basis\"]</code> set to one of: \"consent\", \"contract\", \"legal_obligation\", \"vital_interests\", \"public_interest\", \"legitimate_interests\"</p> <p>Consent-based processing requires: - <code>metadata[\"consent_recorded\"]=True</code> - <code>metadata[\"consent_specific\"]=True</code> - <code>metadata[\"consent_informed\"]=True</code></p> <p>Automated decisions with significant effects require: - <code>metadata[\"human_intervention_available\"]=True</code> - <code>metadata[\"right_to_contest_enabled\"]=True</code> - <code>metadata[\"logic_explained\"]=True</code></p>"},{"location":"api/frameworks/#nist-ai-rmf-framework","title":"NIST AI RMF Framework","text":"<p>NIST AI Risk Management Framework (AI RMF 1.0, January 2023) compliance framework.</p>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.nist_ai_rmf.NISTAIRMFFramework","title":"NISTAIRMFFramework","text":"<p>NIST AI Risk Management Framework compliance framework.</p> <p>Implements compliance checks based on the NIST AI RMF 1.0 (January 2023) requirements for managing AI system risks. The framework evaluates audit entries against requirements for governance, context mapping, risk measurement, and risk management.</p> <p>The NIST AI RMF is built on four core functions:</p> <ol> <li> <p>GOVERN: Cross-cutting function that infuses the AI risk management    culture into the organization. Establishes accountability structures,    policies, and processes for AI risk management.</p> </li> <li> <p>MAP: Establishes the context for framing risks related to an AI system.    Identifies and documents AI system characteristics, intended purposes,    and potential impacts.</p> </li> <li> <p>MEASURE: Employs quantitative and qualitative methods to analyze,    assess, and track AI risks and their impacts. Includes identification    of appropriate metrics and evaluation methods.</p> </li> <li> <p>MANAGE: Allocates risk resources and implements responses to mapped    and measured risks. Includes deployment decisions, post-deployment    monitoring, and incident response.</p> </li> </ol> <p>The framework emphasizes trustworthy AI characteristics: - Valid and Reliable - Safe - Secure and Resilient - Accountable and Transparent - Explainable and Interpretable - Privacy-Enhanced - Fair with Harmful Bias Managed</p> Example <p>framework = NISTAIRMFFramework() result = await framework.check(entry, profile) if not result.is_compliant: ...     for violation in result.violations: ...         print(f\"{violation.rule_id}: {violation.description}\")</p> Source code in <code>src/rotalabs_comply/frameworks/nist_ai_rmf.py</code> <pre><code>class NISTAIRMFFramework(BaseFramework):\n    \"\"\"\n    NIST AI Risk Management Framework compliance framework.\n\n    Implements compliance checks based on the NIST AI RMF 1.0 (January 2023)\n    requirements for managing AI system risks. The framework evaluates audit\n    entries against requirements for governance, context mapping, risk\n    measurement, and risk management.\n\n    The NIST AI RMF is built on four core functions:\n\n    1. GOVERN: Cross-cutting function that infuses the AI risk management\n       culture into the organization. Establishes accountability structures,\n       policies, and processes for AI risk management.\n\n    2. MAP: Establishes the context for framing risks related to an AI system.\n       Identifies and documents AI system characteristics, intended purposes,\n       and potential impacts.\n\n    3. MEASURE: Employs quantitative and qualitative methods to analyze,\n       assess, and track AI risks and their impacts. Includes identification\n       of appropriate metrics and evaluation methods.\n\n    4. MANAGE: Allocates risk resources and implements responses to mapped\n       and measured risks. Includes deployment decisions, post-deployment\n       monitoring, and incident response.\n\n    The framework emphasizes trustworthy AI characteristics:\n    - Valid and Reliable\n    - Safe\n    - Secure and Resilient\n    - Accountable and Transparent\n    - Explainable and Interpretable\n    - Privacy-Enhanced\n    - Fair with Harmful Bias Managed\n\n    Example:\n        &gt;&gt;&gt; framework = NISTAIRMFFramework()\n        &gt;&gt;&gt; result = await framework.check(entry, profile)\n        &gt;&gt;&gt; if not result.is_compliant:\n        ...     for violation in result.violations:\n        ...         print(f\"{violation.rule_id}: {violation.description}\")\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the NIST AI RMF framework with all defined rules.\"\"\"\n        rules = self._create_rules()\n        super().__init__(name=\"NIST AI RMF\", version=\"1.0\", rules=rules)\n\n    def _create_rules(self) -&gt; List[ComplianceRule]:\n        \"\"\"\n        Create all NIST AI RMF compliance rules.\n\n        Returns:\n            List of ComplianceRule objects representing NIST AI RMF requirements\n        \"\"\"\n        return [\n            # ================================================================\n            # GOVERN Function - Organizational Governance\n            # ================================================================\n            ComplianceRule(\n                rule_id=\"NIST-GOV-1\",\n                name=\"AI Risk Management Governance Structure\",\n                description=(\n                    \"Organizations should establish and maintain AI risk management \"\n                    \"governance structures that define clear accountability, roles, \"\n                    \"and decision-making processes. Governance includes policies, \"\n                    \"processes, and procedures to manage AI risks and opportunities \"\n                    \"throughout the AI lifecycle. Senior leadership should demonstrate \"\n                    \"commitment to AI risk management through resource allocation and \"\n                    \"organizational culture. (GOVERN 1.1, 1.2, 1.3)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"governance\",\n                remediation=(\n                    \"Establish an AI governance committee or designate responsible \"\n                    \"leadership. Document AI governance policies and procedures. \"\n                    \"Ensure governance structures are integrated with enterprise \"\n                    \"risk management. Define escalation paths for AI-related decisions.\"\n                ),\n                references=[\n                    \"NIST AI RMF GOVERN 1.1\",\n                    \"NIST AI RMF GOVERN 1.2\",\n                    \"NIST AI RMF GOVERN 1.3\",\n                    \"NIST AI 100-1 Section 3\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"NIST-GOV-2\",\n                name=\"Organizational AI Principles and Values\",\n                description=(\n                    \"Organizations should document and communicate AI principles and \"\n                    \"values that guide AI development and deployment decisions. These \"\n                    \"principles should address trustworthy AI characteristics including \"\n                    \"fairness, accountability, transparency, privacy, safety, and \"\n                    \"security. Principles should be operationalized through specific \"\n                    \"policies and integrated into organizational processes. \"\n                    \"(GOVERN 1.4, 1.5)\"\n                ),\n                severity=RiskLevel.MEDIUM,\n                category=\"governance\",\n                remediation=(\n                    \"Develop and document organizational AI principles aligned with \"\n                    \"trustworthy AI characteristics. Communicate principles to all \"\n                    \"stakeholders. Create mechanisms to operationalize principles in \"\n                    \"AI development and deployment processes. Regularly review and \"\n                    \"update principles based on evolving standards and learnings.\"\n                ),\n                references=[\n                    \"NIST AI RMF GOVERN 1.4\",\n                    \"NIST AI RMF GOVERN 1.5\",\n                    \"NIST AI 100-1 Appendix A\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"NIST-GOV-3\",\n                name=\"Roles and Responsibilities Defined\",\n                description=(\n                    \"Organizations should clearly define and document roles and \"\n                    \"responsibilities for AI risk management across the AI lifecycle. \"\n                    \"This includes designating individuals or teams responsible for \"\n                    \"AI governance, risk assessment, monitoring, and incident response. \"\n                    \"Responsibilities should span development, deployment, and \"\n                    \"decommissioning phases. (GOVERN 2.1, 2.2)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"governance\",\n                remediation=(\n                    \"Document specific roles and responsibilities for AI risk management. \"\n                    \"Assign accountability for each phase of the AI lifecycle. Ensure \"\n                    \"cross-functional representation in AI governance. Define clear \"\n                    \"escalation procedures and decision authority. Provide training \"\n                    \"appropriate to assigned responsibilities.\"\n                ),\n                references=[\n                    \"NIST AI RMF GOVERN 2.1\",\n                    \"NIST AI RMF GOVERN 2.2\",\n                    \"NIST AI 100-1 Section 3\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"NIST-GOV-4\",\n                name=\"Third-Party AI Risk Management\",\n                description=(\n                    \"Organizations should establish processes to assess and manage \"\n                    \"risks from third-party AI components, including AI services, \"\n                    \"models, data, and infrastructure. Due diligence should be \"\n                    \"conducted on third-party AI providers. Contracts should address \"\n                    \"AI risk management requirements, and third-party risks should be \"\n                    \"monitored throughout the relationship. (GOVERN 6.1, 6.2)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"governance\",\n                remediation=(\n                    \"Implement third-party AI risk assessment processes. Include AI \"\n                    \"risk requirements in vendor contracts and SLAs. Conduct due \"\n                    \"diligence on AI providers including model provenance and data \"\n                    \"practices. Establish ongoing monitoring of third-party AI \"\n                    \"performance and compliance. Maintain inventory of third-party \"\n                    \"AI dependencies.\"\n                ),\n                references=[\n                    \"NIST AI RMF GOVERN 6.1\",\n                    \"NIST AI RMF GOVERN 6.2\",\n                    \"NIST AI 100-1 Section 3\",\n                ],\n            ),\n            # ================================================================\n            # MAP Function - Context and Risk Identification\n            # ================================================================\n            ComplianceRule(\n                rule_id=\"NIST-MAP-1\",\n                name=\"AI System Context Established\",\n                description=(\n                    \"Organizations should establish and document the context for \"\n                    \"AI systems including the operating environment, stakeholders, \"\n                    \"and potential impacts. Context includes organizational goals, \"\n                    \"intended users, deployment environment, and societal context. \"\n                    \"Understanding context is essential for identifying and assessing \"\n                    \"AI risks appropriately. (MAP 1.1, 1.2, 1.3)\"\n                ),\n                severity=RiskLevel.MEDIUM,\n                category=\"context\",\n                remediation=(\n                    \"Document the AI system's intended operating environment and \"\n                    \"deployment context. Identify all stakeholders including direct \"\n                    \"users, affected individuals, and oversight bodies. Analyze \"\n                    \"organizational, technical, and societal context factors. \"\n                    \"Assess how context may change over the system lifecycle.\"\n                ),\n                references=[\n                    \"NIST AI RMF MAP 1.1\",\n                    \"NIST AI RMF MAP 1.2\",\n                    \"NIST AI RMF MAP 1.3\",\n                    \"NIST AI 100-1 Section 4\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"NIST-MAP-2\",\n                name=\"AI Categorization and Intended Use Documented\",\n                description=(\n                    \"Organizations should categorize AI systems and document their \"\n                    \"intended use, including the specific tasks the AI is designed \"\n                    \"to perform, the target users, and the decision-making contexts. \"\n                    \"Documentation should address potential misuse scenarios and \"\n                    \"out-of-scope applications. Limitations and constraints should \"\n                    \"be clearly specified. (MAP 2.1, 2.2, 2.3)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"context\",\n                remediation=(\n                    \"Create comprehensive documentation of AI system purpose and \"\n                    \"intended use cases. Categorize the AI system based on risk \"\n                    \"factors and application domain. Document known limitations, \"\n                    \"constraints, and out-of-scope uses. Specify conditions under \"\n                    \"which the AI should and should not be used.\"\n                ),\n                references=[\n                    \"NIST AI RMF MAP 2.1\",\n                    \"NIST AI RMF MAP 2.2\",\n                    \"NIST AI RMF MAP 2.3\",\n                    \"NIST AI 100-1 Section 4\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"NIST-MAP-3\",\n                name=\"AI Benefits and Costs Assessed\",\n                description=(\n                    \"Organizations should assess and document the benefits and costs \"\n                    \"of AI systems, including potential positive and negative impacts \"\n                    \"on individuals, organizations, communities, and society. Assessment \"\n                    \"should consider both intended outcomes and unintended consequences. \"\n                    \"Trade-offs between benefits and risks should be analyzed and \"\n                    \"documented. (MAP 3.1, 3.2)\"\n                ),\n                severity=RiskLevel.MEDIUM,\n                category=\"context\",\n                remediation=(\n                    \"Conduct benefit-cost analysis for AI systems including tangible \"\n                    \"and intangible impacts. Document potential positive outcomes and \"\n                    \"risks to different stakeholder groups. Analyze trade-offs and \"\n                    \"document decision rationale. Consider long-term and systemic \"\n                    \"effects. Re-evaluate periodically as context changes.\"\n                ),\n                references=[\n                    \"NIST AI RMF MAP 3.1\",\n                    \"NIST AI RMF MAP 3.2\",\n                    \"NIST AI 100-1 Section 4\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"NIST-MAP-4\",\n                name=\"Risks from Third-Party Components Mapped\",\n                description=(\n                    \"Organizations should identify and map risks arising from \"\n                    \"third-party AI components including pre-trained models, datasets, \"\n                    \"APIs, and cloud services. Risk mapping should address model \"\n                    \"provenance, data quality, supply chain integrity, and dependency \"\n                    \"risks. Organizations should understand how third-party components \"\n                    \"affect overall system trustworthiness. (MAP 4.1, 4.2)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"risk_identification\",\n                remediation=(\n                    \"Maintain inventory of all third-party AI components and data \"\n                    \"sources. Assess risks associated with each third-party dependency \"\n                    \"including provenance, quality, and support continuity. Document \"\n                    \"how third-party components affect system behavior and risk profile. \"\n                    \"Establish processes for evaluating new third-party AI components.\"\n                ),\n                references=[\n                    \"NIST AI RMF MAP 4.1\",\n                    \"NIST AI RMF MAP 4.2\",\n                    \"NIST AI 100-1 Section 4\",\n                ],\n            ),\n            # ================================================================\n            # MEASURE Function - Risk Analysis\n            # ================================================================\n            ComplianceRule(\n                rule_id=\"NIST-MEAS-1\",\n                name=\"Appropriate Metrics Identified\",\n                description=(\n                    \"Organizations should identify and implement appropriate metrics \"\n                    \"for measuring AI system performance, trustworthiness characteristics, \"\n                    \"and risks. Metrics should be relevant to the AI system context, \"\n                    \"measurable, and aligned with organizational goals. Measurement \"\n                    \"approaches should be documented and validated for reliability. \"\n                    \"(MEASURE 1.1, 1.2, 1.3)\"\n                ),\n                severity=RiskLevel.MEDIUM,\n                category=\"measurement\",\n                remediation=(\n                    \"Define metrics for each trustworthy AI characteristic relevant \"\n                    \"to the system. Establish baselines and thresholds for acceptable \"\n                    \"performance. Document measurement methodologies and their \"\n                    \"limitations. Validate metrics are meaningful for the intended \"\n                    \"context. Review and update metrics as system context evolves.\"\n                ),\n                references=[\n                    \"NIST AI RMF MEASURE 1.1\",\n                    \"NIST AI RMF MEASURE 1.2\",\n                    \"NIST AI RMF MEASURE 1.3\",\n                    \"NIST AI 100-1 Section 5\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"NIST-MEAS-2\",\n                name=\"AI Systems Evaluated for Trustworthy Characteristics\",\n                description=(\n                    \"Organizations should evaluate AI systems against trustworthy AI \"\n                    \"characteristics including validity, reliability, safety, security, \"\n                    \"resilience, accountability, transparency, explainability, \"\n                    \"interpretability, privacy protection, and fairness. Evaluations \"\n                    \"should be conducted throughout the AI lifecycle using appropriate \"\n                    \"testing and assessment methods. (MEASURE 2.1, 2.2, 2.3)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"measurement\",\n                remediation=(\n                    \"Implement evaluation processes for trustworthy AI characteristics. \"\n                    \"Conduct testing for accuracy, robustness, fairness, and other \"\n                    \"relevant characteristics. Document evaluation results and track \"\n                    \"trends over time. Use multiple evaluation methods appropriate to \"\n                    \"each characteristic. Address identified gaps through system \"\n                    \"improvements or risk mitigations.\"\n                ),\n                references=[\n                    \"NIST AI RMF MEASURE 2.1\",\n                    \"NIST AI RMF MEASURE 2.2\",\n                    \"NIST AI RMF MEASURE 2.3\",\n                    \"NIST AI 100-1 Section 5\",\n                    \"NIST AI 100-1 Appendix B\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"NIST-MEAS-3\",\n                name=\"Mechanisms for Tracking Identified Risks\",\n                description=(\n                    \"Organizations should establish mechanisms for tracking identified \"\n                    \"AI risks throughout the system lifecycle. Risk tracking should \"\n                    \"include monitoring of risk indicators, documentation of risk \"\n                    \"status changes, and communication of risk information to relevant \"\n                    \"stakeholders. Risk tracking should be integrated with broader \"\n                    \"organizational risk management processes. (MEASURE 3.1, 3.2, 3.3)\"\n                ),\n                severity=RiskLevel.MEDIUM,\n                category=\"measurement\",\n                remediation=(\n                    \"Implement risk tracking systems or integrate with existing risk \"\n                    \"management tools. Define risk indicators and monitoring processes. \"\n                    \"Establish regular risk review cadence. Document risk status and \"\n                    \"changes over time. Create communication processes for risk \"\n                    \"information sharing with relevant stakeholders.\"\n                ),\n                references=[\n                    \"NIST AI RMF MEASURE 3.1\",\n                    \"NIST AI RMF MEASURE 3.2\",\n                    \"NIST AI RMF MEASURE 3.3\",\n                    \"NIST AI 100-1 Section 5\",\n                ],\n            ),\n            # ================================================================\n            # MANAGE Function - Risk Treatment\n            # ================================================================\n            ComplianceRule(\n                rule_id=\"NIST-MAN-1\",\n                name=\"AI Risks Prioritized and Responded To\",\n                description=(\n                    \"Organizations should prioritize AI risks based on their likelihood \"\n                    \"and potential impact, and develop appropriate risk responses. \"\n                    \"Risk responses may include risk avoidance, mitigation, transfer, \"\n                    \"or acceptance. Resource allocation for risk treatment should align \"\n                    \"with risk priorities. Risk response decisions should be documented \"\n                    \"and communicated. (MANAGE 1.1, 1.2, 1.3)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"risk_treatment\",\n                remediation=(\n                    \"Establish risk prioritization criteria and processes. Document \"\n                    \"risk response decisions including rationale. Allocate resources \"\n                    \"proportionate to risk priority. Implement risk mitigation measures \"\n                    \"and track effectiveness. Review and adjust risk responses based \"\n                    \"on changing conditions and new information.\"\n                ),\n                references=[\n                    \"NIST AI RMF MANAGE 1.1\",\n                    \"NIST AI RMF MANAGE 1.2\",\n                    \"NIST AI RMF MANAGE 1.3\",\n                    \"NIST AI 100-1 Section 6\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"NIST-MAN-2\",\n                name=\"AI System Deployment Decisions Documented\",\n                description=(\n                    \"Organizations should document deployment decisions for AI systems \"\n                    \"including the criteria used, risks considered, and approval process. \"\n                    \"Deployment decisions should consider whether risks have been \"\n                    \"adequately addressed and whether appropriate safeguards are in \"\n                    \"place. Staged deployment approaches should be considered for \"\n                    \"high-risk systems. (MANAGE 2.1, 2.2)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"risk_treatment\",\n                remediation=(\n                    \"Establish deployment decision criteria and approval processes. \"\n                    \"Document risk assessment results informing deployment decisions. \"\n                    \"Implement staged deployment approaches where appropriate. Define \"\n                    \"conditions for full deployment, limited deployment, or non-deployment. \"\n                    \"Document deployment decisions and supporting rationale.\"\n                ),\n                references=[\n                    \"NIST AI RMF MANAGE 2.1\",\n                    \"NIST AI RMF MANAGE 2.2\",\n                    \"NIST AI 100-1 Section 6\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"NIST-MAN-3\",\n                name=\"Post-Deployment Monitoring in Place\",\n                description=(\n                    \"Organizations should implement post-deployment monitoring for \"\n                    \"AI systems to detect performance degradation, emerging risks, \"\n                    \"and unintended impacts. Monitoring should cover system performance, \"\n                    \"user feedback, and environmental changes that may affect risk. \"\n                    \"Monitoring findings should trigger appropriate review and response \"\n                    \"processes. (MANAGE 3.1, 3.2)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"risk_treatment\",\n                remediation=(\n                    \"Implement monitoring systems for deployed AI applications. Define \"\n                    \"metrics and thresholds for detecting performance issues. Establish \"\n                    \"processes for collecting and analyzing user feedback. Monitor for \"\n                    \"data drift, concept drift, and environmental changes. Create \"\n                    \"escalation procedures for monitoring alerts.\"\n                ),\n                references=[\n                    \"NIST AI RMF MANAGE 3.1\",\n                    \"NIST AI RMF MANAGE 3.2\",\n                    \"NIST AI 100-1 Section 6\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"NIST-MAN-4\",\n                name=\"Incident Response and Recovery Procedures\",\n                description=(\n                    \"Organizations should establish incident response and recovery \"\n                    \"procedures for AI-related incidents including system failures, \"\n                    \"security breaches, safety incidents, and harmful outputs. Procedures \"\n                    \"should address incident detection, containment, investigation, \"\n                    \"remediation, and communication. Lessons learned should inform \"\n                    \"system improvements and risk management updates. (MANAGE 4.1, 4.2, 4.3)\"\n                ),\n                severity=RiskLevel.CRITICAL,\n                category=\"risk_treatment\",\n                remediation=(\n                    \"Develop AI-specific incident response procedures. Define incident \"\n                    \"severity levels and response protocols. Establish incident \"\n                    \"communication plans for internal and external stakeholders. \"\n                    \"Implement procedures for system rollback or shutdown when needed. \"\n                    \"Conduct post-incident reviews and update risk management based \"\n                    \"on lessons learned.\"\n                ),\n                references=[\n                    \"NIST AI RMF MANAGE 4.1\",\n                    \"NIST AI RMF MANAGE 4.2\",\n                    \"NIST AI RMF MANAGE 4.3\",\n                    \"NIST AI 100-1 Section 6\",\n                ],\n            ),\n        ]\n\n    def _check_rule(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check a single NIST AI RMF rule against an audit entry.\n\n        Evaluates the audit entry against the specific rule requirements\n        and returns a violation if the entry does not comply.\n\n        Args:\n            entry: The audit entry to check\n            rule: The rule to evaluate\n\n        Returns:\n            ComplianceViolation if the rule is violated, None otherwise\n        \"\"\"\n        # Use custom check function if provided\n        if rule.check_fn is not None:\n            is_compliant = rule.check_fn(entry)\n            if not is_compliant:\n                return self._create_violation(entry, rule, \"Custom check failed\")\n            return None\n\n        # Framework-specific rule checks\n        if rule.rule_id == \"NIST-GOV-1\":\n            return self._check_governance_structure(entry, rule)\n        elif rule.rule_id == \"NIST-GOV-2\":\n            return self._check_ai_principles(entry, rule)\n        elif rule.rule_id == \"NIST-GOV-3\":\n            return self._check_roles_responsibilities(entry, rule)\n        elif rule.rule_id == \"NIST-GOV-4\":\n            return self._check_third_party_governance(entry, rule)\n        elif rule.rule_id == \"NIST-MAP-1\":\n            return self._check_system_context(entry, rule)\n        elif rule.rule_id == \"NIST-MAP-2\":\n            return self._check_categorization_documented(entry, rule)\n        elif rule.rule_id == \"NIST-MAP-3\":\n            return self._check_benefits_costs_assessed(entry, rule)\n        elif rule.rule_id == \"NIST-MAP-4\":\n            return self._check_third_party_risks_mapped(entry, rule)\n        elif rule.rule_id == \"NIST-MEAS-1\":\n            return self._check_metrics_identified(entry, rule)\n        elif rule.rule_id == \"NIST-MEAS-2\":\n            return self._check_trustworthy_evaluation(entry, rule)\n        elif rule.rule_id == \"NIST-MEAS-3\":\n            return self._check_risk_tracking(entry, rule)\n        elif rule.rule_id == \"NIST-MAN-1\":\n            return self._check_risk_prioritization(entry, rule)\n        elif rule.rule_id == \"NIST-MAN-2\":\n            return self._check_deployment_decisions(entry, rule)\n        elif rule.rule_id == \"NIST-MAN-3\":\n            return self._check_post_deployment_monitoring(entry, rule)\n        elif rule.rule_id == \"NIST-MAN-4\":\n            return self._check_incident_response(entry, rule)\n\n        return None\n\n    # ========================================================================\n    # GOVERN Function Checks\n    # ========================================================================\n\n    def _check_governance_structure(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check NIST-GOV-1: AI risk management governance structure required.\n\n        High-risk AI operations must have documented governance oversight.\n        This is evaluated based on the risk_level and governance metadata.\n        \"\"\"\n        # Only applies to high-risk operations\n        if entry.risk_level not in (RiskLevel.HIGH, RiskLevel.CRITICAL):\n            return None\n\n        has_governance = entry.metadata.get(\"governance_documented\", False)\n        has_approval = entry.metadata.get(\"governance_approval\", False)\n\n        if not (has_governance or has_approval):\n            return self._create_violation(\n                entry,\n                rule,\n                f\"High-risk operation (level={entry.risk_level.value}) performed \"\n                f\"without documented AI governance structure or approval\",\n            )\n        return None\n\n    def _check_ai_principles(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check NIST-GOV-2: Organizational AI principles and values documented.\n\n        Operations involving significant AI decisions should reference\n        organizational AI principles.\n        \"\"\"\n        # Check for significant decision-making operations\n        decision_events = {\"deployment\", \"model_selection\", \"training\", \"policy_update\"}\n        if entry.event_type.lower() not in decision_events:\n            return None\n\n        has_principles_ref = entry.metadata.get(\"ai_principles_aligned\", False)\n        if not has_principles_ref:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"AI decision operation (type={entry.event_type}) performed \"\n                f\"without reference to organizational AI principles\",\n            )\n        return None\n\n    def _check_roles_responsibilities(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check NIST-GOV-3: Roles and responsibilities defined.\n\n        High-risk operations must have clear accountability documented.\n        \"\"\"\n        if entry.risk_level not in (RiskLevel.HIGH, RiskLevel.CRITICAL):\n            return None\n\n        has_owner = bool(entry.actor and entry.actor != \"system\")\n        has_accountability = entry.metadata.get(\"accountability_documented\", False)\n\n        if not (has_owner or has_accountability):\n            return self._create_violation(\n                entry,\n                rule,\n                f\"High-risk operation (level={entry.risk_level.value}) performed \"\n                f\"without clear accountability or responsible party documented\",\n            )\n        return None\n\n    def _check_third_party_governance(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check NIST-GOV-4: Third-party AI risk management.\n\n        Operations involving third-party AI components must have\n        appropriate risk governance.\n        \"\"\"\n        # Check if this involves third-party components\n        third_party_events = {\n            \"api_call\", \"external_model\", \"third_party_inference\",\n            \"vendor_integration\", \"model_import\"\n        }\n        if entry.event_type.lower() not in third_party_events:\n            return None\n\n        has_third_party_assessment = entry.metadata.get(\"third_party_assessed\", False)\n        has_vendor_agreement = entry.metadata.get(\"vendor_agreement_documented\", False)\n\n        if not (has_third_party_assessment or has_vendor_agreement):\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Third-party AI operation (type={entry.event_type}) performed \"\n                f\"without documented third-party risk assessment\",\n            )\n        return None\n\n    # ========================================================================\n    # MAP Function Checks\n    # ========================================================================\n\n    def _check_system_context(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check NIST-MAP-1: AI system context established.\n\n        New deployments and significant system changes must have\n        documented context.\n        \"\"\"\n        context_events = {\"deployment\", \"system_change\", \"environment_update\"}\n        if entry.event_type.lower() not in context_events:\n            return None\n\n        has_context = entry.metadata.get(\"system_context_documented\", False)\n        if not has_context:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"System operation (type={entry.event_type}) performed \"\n                f\"without documented AI system context\",\n            )\n        return None\n\n    def _check_categorization_documented(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check NIST-MAP-2: AI categorization and intended use documented.\n\n        Deployment and training operations must have categorization\n        and intended use documentation.\n        \"\"\"\n        significant_events = {\"deployment\", \"training\", \"fine_tuning\", \"model_release\"}\n        if entry.event_type.lower() not in significant_events:\n            return None\n\n        has_categorization = entry.metadata.get(\"ai_categorization_documented\", False)\n        has_intended_use = entry.metadata.get(\"intended_use_documented\", False)\n\n        if not (has_categorization or has_intended_use or entry.documentation_ref):\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Significant operation (type={entry.event_type}) performed \"\n                f\"without documented AI categorization or intended use\",\n            )\n        return None\n\n    def _check_benefits_costs_assessed(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check NIST-MAP-3: AI benefits and costs assessed.\n\n        Deployment decisions should include benefit-cost assessment.\n        \"\"\"\n        # Only check deployment-related events\n        if entry.event_type.lower() != \"deployment\":\n            return None\n\n        has_assessment = entry.metadata.get(\"benefit_cost_assessed\", False)\n        has_impact_analysis = entry.metadata.get(\"impact_analysis_documented\", False)\n\n        if not (has_assessment or has_impact_analysis):\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Deployment operation performed without documented \"\n                f\"benefit-cost or impact assessment\",\n            )\n        return None\n\n    def _check_third_party_risks_mapped(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check NIST-MAP-4: Risks from third-party components mapped.\n\n        Operations using third-party AI must have risks identified.\n        \"\"\"\n        third_party_events = {\n            \"api_call\", \"external_model\", \"third_party_inference\",\n            \"vendor_integration\", \"model_import\", \"data_import\"\n        }\n        if entry.event_type.lower() not in third_party_events:\n            return None\n\n        has_risk_mapping = entry.metadata.get(\"third_party_risks_mapped\", False)\n        has_component_inventory = entry.metadata.get(\"component_inventory_updated\", False)\n\n        if not (has_risk_mapping or has_component_inventory):\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Third-party operation (type={entry.event_type}) performed \"\n                f\"without documented risk mapping for third-party components\",\n            )\n        return None\n\n    # ========================================================================\n    # MEASURE Function Checks\n    # ========================================================================\n\n    def _check_metrics_identified(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check NIST-MEAS-1: Appropriate metrics identified.\n\n        Performance and risk-related operations should reference\n        defined metrics.\n        \"\"\"\n        metric_events = {\n            \"inference\", \"evaluation\", \"testing\", \"monitoring\",\n            \"performance_review\"\n        }\n        if entry.event_type.lower() not in metric_events:\n            return None\n\n        has_metrics = entry.metadata.get(\"metrics_documented\", False)\n        has_baseline = entry.metadata.get(\"baseline_established\", False)\n\n        if not (has_metrics or has_baseline):\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Measurement operation (type={entry.event_type}) performed \"\n                f\"without reference to documented metrics\",\n            )\n        return None\n\n    def _check_trustworthy_evaluation(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check NIST-MEAS-2: AI systems evaluated for trustworthy characteristics.\n\n        Significant operations should include trustworthiness evaluation.\n        \"\"\"\n        # Only applies to high-risk operations and significant events\n        if entry.risk_level not in (RiskLevel.HIGH, RiskLevel.CRITICAL):\n            return None\n\n        evaluation_events = {\n            \"deployment\", \"inference\", \"training\", \"evaluation\",\n            \"model_update\", \"testing\"\n        }\n        if entry.event_type.lower() not in evaluation_events:\n            return None\n\n        has_trustworthy_eval = entry.metadata.get(\"trustworthiness_evaluated\", False)\n        has_fairness_check = entry.metadata.get(\"fairness_assessed\", False)\n        has_safety_check = entry.metadata.get(\"safety_evaluated\", False)\n\n        if not (has_trustworthy_eval or has_fairness_check or has_safety_check):\n            return self._create_violation(\n                entry,\n                rule,\n                f\"High-risk operation (type={entry.event_type}) performed \"\n                f\"without trustworthy AI characteristics evaluation\",\n            )\n        return None\n\n    def _check_risk_tracking(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check NIST-MEAS-3: Mechanisms for tracking identified risks.\n\n        High-risk operations should have risk tracking in place.\n        \"\"\"\n        if entry.risk_level not in (RiskLevel.HIGH, RiskLevel.CRITICAL):\n            return None\n\n        has_risk_tracking = entry.metadata.get(\"risk_tracked\", False)\n        has_risk_registry = entry.metadata.get(\"risk_registry_updated\", False)\n\n        if not (has_risk_tracking or has_risk_registry):\n            return self._create_violation(\n                entry,\n                rule,\n                f\"High-risk operation (level={entry.risk_level.value}) performed \"\n                f\"without documented risk tracking mechanism\",\n            )\n        return None\n\n    # ========================================================================\n    # MANAGE Function Checks\n    # ========================================================================\n\n    def _check_risk_prioritization(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check NIST-MAN-1: AI risks prioritized and responded to.\n\n        High-risk operations should have prioritized risk response.\n        \"\"\"\n        if entry.risk_level not in (RiskLevel.HIGH, RiskLevel.CRITICAL):\n            return None\n\n        has_risk_response = entry.metadata.get(\"risk_response_documented\", False)\n        has_prioritization = entry.metadata.get(\"risk_prioritized\", False)\n        has_risk_assessment = entry.metadata.get(\"risk_assessment_documented\", False)\n\n        if not (has_risk_response or has_prioritization or has_risk_assessment):\n            return self._create_violation(\n                entry,\n                rule,\n                f\"High-risk operation (level={entry.risk_level.value}) performed \"\n                f\"without documented risk prioritization or response\",\n            )\n        return None\n\n    def _check_deployment_decisions(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check NIST-MAN-2: AI system deployment decisions documented.\n\n        Deployment operations must have documented decision rationale.\n        \"\"\"\n        if entry.event_type.lower() != \"deployment\":\n            return None\n\n        has_decision_doc = entry.metadata.get(\"deployment_decision_documented\", False)\n        has_approval = entry.metadata.get(\"deployment_approved\", False)\n\n        if not (has_decision_doc or has_approval or entry.documentation_ref):\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Deployment operation performed without documented \"\n                f\"deployment decision or approval\",\n            )\n        return None\n\n    def _check_post_deployment_monitoring(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check NIST-MAN-3: Post-deployment monitoring in place.\n\n        Production operations should have monitoring documented.\n        \"\"\"\n        production_events = {\n            \"inference\", \"prediction\", \"completion\", \"production_query\",\n            \"user_interaction\"\n        }\n        if entry.event_type.lower() not in production_events:\n            return None\n\n        # Only check for operations that should be monitored\n        has_monitoring = entry.metadata.get(\"monitoring_enabled\", False)\n        has_performance_tracking = entry.metadata.get(\"performance_tracked\", False)\n\n        if not (has_monitoring or has_performance_tracking):\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Production operation (type={entry.event_type}) performed \"\n                f\"without documented post-deployment monitoring\",\n            )\n        return None\n\n    def _check_incident_response(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check NIST-MAN-4: Incident response and recovery procedures.\n\n        Error and incident events must have response procedures.\n        \"\"\"\n        incident_events = {\n            \"incident\", \"error\", \"failure\", \"security_event\",\n            \"safety_incident\", \"model_failure\", \"system_error\"\n        }\n        if entry.event_type.lower() not in incident_events:\n            return None\n\n        has_incident_response = entry.metadata.get(\"incident_response_followed\", False)\n        has_recovery_plan = entry.metadata.get(\"recovery_plan_executed\", False)\n        has_incident_documented = entry.metadata.get(\"incident_documented\", False)\n\n        if not (has_incident_response or has_recovery_plan or has_incident_documented):\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Incident event (type={entry.event_type}) without documented \"\n                f\"incident response or recovery procedure\",\n            )\n        return None\n\n    # ========================================================================\n    # Helper Methods\n    # ========================================================================\n\n    def _create_violation(\n        self, entry: AuditEntry, rule: ComplianceRule, evidence: str\n    ) -&gt; ComplianceViolation:\n        \"\"\"\n        Create a compliance violation object.\n\n        Args:\n            entry: The audit entry that triggered the violation\n            rule: The rule that was violated\n            evidence: Specific evidence describing the violation\n\n        Returns:\n            ComplianceViolation object\n        \"\"\"\n        return ComplianceViolation(\n            rule_id=rule.rule_id,\n            rule_name=rule.name,\n            severity=rule.severity,\n            description=rule.description,\n            evidence=evidence,\n            remediation=rule.remediation,\n            entry_id=entry.entry_id,\n            category=rule.category,\n            framework=self._name,\n        )\n</code></pre>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.nist_ai_rmf.NISTAIRMFFramework.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> <p>Initialize the NIST AI RMF framework with all defined rules.</p> Source code in <code>src/rotalabs_comply/frameworks/nist_ai_rmf.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize the NIST AI RMF framework with all defined rules.\"\"\"\n    rules = self._create_rules()\n    super().__init__(name=\"NIST AI RMF\", version=\"1.0\", rules=rules)\n</code></pre>"},{"location":"api/frameworks/#categories_4","title":"Categories","text":"Category Function Description <code>governance</code> GOVERN Organizational AI governance structures and accountability <code>context</code> MAP AI system context, intended use, and stakeholder analysis <code>risk_identification</code> MAP Identification of risks from AI systems and components <code>measurement</code> MEASURE Metrics, evaluation, and tracking of AI characteristics <code>risk_treatment</code> MANAGE Risk prioritization, response, and post-deployment monitoring"},{"location":"api/frameworks/#rules_4","title":"Rules","text":"Rule ID Name Category Severity <code>NIST-GOV-1</code> AI Risk Management Governance Structure governance HIGH <code>NIST-GOV-2</code> Organizational AI Principles and Values governance MEDIUM <code>NIST-GOV-3</code> Roles and Responsibilities Defined governance HIGH <code>NIST-GOV-4</code> Third-Party AI Risk Management governance HIGH <code>NIST-MAP-1</code> AI System Context Established context MEDIUM <code>NIST-MAP-2</code> AI Categorization and Intended Use Documented context HIGH <code>NIST-MAP-3</code> AI Benefits and Costs Assessed context MEDIUM <code>NIST-MAP-4</code> Risks from Third-Party Components Mapped risk_identification HIGH <code>NIST-MEAS-1</code> Appropriate Metrics Identified measurement MEDIUM <code>NIST-MEAS-2</code> AI Systems Evaluated for Trustworthy Characteristics measurement HIGH <code>NIST-MEAS-3</code> Mechanisms for Tracking Identified Risks measurement MEDIUM <code>NIST-MAN-1</code> AI Risks Prioritized and Responded To risk_treatment HIGH <code>NIST-MAN-2</code> AI System Deployment Decisions Documented risk_treatment HIGH <code>NIST-MAN-3</code> Post-Deployment Monitoring in Place risk_treatment HIGH <code>NIST-MAN-4</code> Incident Response and Recovery Procedures risk_treatment CRITICAL"},{"location":"api/frameworks/#usage_4","title":"Usage","text":"<pre><code>from rotalabs_comply.frameworks.nist_ai_rmf import NISTAIRMFFramework\nfrom rotalabs_comply.frameworks.base import AuditEntry, ComplianceProfile, RiskLevel\nfrom datetime import datetime\n\nframework = NISTAIRMFFramework()\n\nentry = AuditEntry(\n    entry_id=\"nist-001\",\n    timestamp=datetime.utcnow(),\n    event_type=\"deployment\",\n    actor=\"mlops@company.com\",\n    action=\"Deploy production model\",\n    risk_level=RiskLevel.HIGH,\n    documentation_ref=\"DOC-DEPLOY-001\",\n    metadata={\n        \"governance_documented\": True,\n        \"governance_approval\": True,\n        \"system_context_documented\": True,\n        \"ai_categorization_documented\": True,\n        \"intended_use_documented\": True,\n        \"benefit_cost_assessed\": True,\n        \"deployment_decision_documented\": True,\n        \"deployment_approved\": True,\n        \"risk_assessment_documented\": True,\n    },\n)\n\nprofile = ComplianceProfile(\n    profile_id=\"nist-profile\",\n    name=\"NIST AI RMF Compliance\",\n)\n\nresult = await framework.check(entry, profile)\n</code></pre>"},{"location":"api/frameworks/#key-requirements_4","title":"Key Requirements","text":"<p>High-risk operations require: - <code>metadata[\"governance_documented\"]=True</code> or <code>metadata[\"governance_approval\"]=True</code> - <code>metadata[\"risk_assessment_documented\"]=True</code> or <code>metadata[\"risk_prioritized\"]=True</code> - <code>metadata[\"risk_tracked\"]=True</code> or <code>metadata[\"risk_registry_updated\"]=True</code></p> <p>Deployment operations require: - <code>metadata[\"deployment_decision_documented\"]=True</code> or <code>metadata[\"deployment_approved\"]=True</code> - <code>documentation_ref</code> set</p> <p>Third-party AI operations require: - <code>metadata[\"third_party_assessed\"]=True</code> or <code>metadata[\"vendor_agreement_documented\"]=True</code> - <code>metadata[\"third_party_risks_mapped\"]=True</code> or <code>metadata[\"component_inventory_updated\"]=True</code></p> <p>Incident events require: - <code>metadata[\"incident_response_followed\"]=True</code> or <code>metadata[\"recovery_plan_executed\"]=True</code></p>"},{"location":"api/frameworks/#isoiec-42001-framework","title":"ISO/IEC 42001 Framework","text":"<p>ISO/IEC 42001:2023 AI Management System (AIMS) compliance framework.</p>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.iso_42001.ISO42001Framework","title":"ISO42001Framework","text":"<p>ISO/IEC 42001:2023 AI Management System compliance framework.</p> <p>Implements compliance checks based on ISO 42001:2023 requirements for establishing, implementing, maintaining, and continually improving an AI management system. The framework evaluates audit entries against the standard's requirements across seven key areas.</p> <p>ISO 42001 is structured around the Plan-Do-Check-Act (PDCA) cycle: - Plan: Establish AIMS objectives and processes (Clauses 4-6) - Do: Implement the AIMS and its processes (Clauses 7-8) - Check: Monitor and evaluate performance (Clause 9) - Act: Take actions to improve performance (Clause 10)</p> <p>The standard emphasizes: - Risk-based thinking throughout the AI lifecycle - Responsible AI development and deployment - Transparency and accountability - Continual improvement</p> Example <p>framework = ISO42001Framework() result = await framework.check(entry, profile) if not result.is_compliant: ...     for violation in result.violations: ...         print(f\"{violation.rule_id}: {violation.description}\")</p> Source code in <code>src/rotalabs_comply/frameworks/iso_42001.py</code> <pre><code>class ISO42001Framework(BaseFramework):\n    \"\"\"\n    ISO/IEC 42001:2023 AI Management System compliance framework.\n\n    Implements compliance checks based on ISO 42001:2023 requirements for\n    establishing, implementing, maintaining, and continually improving an\n    AI management system. The framework evaluates audit entries against\n    the standard's requirements across seven key areas.\n\n    ISO 42001 is structured around the Plan-Do-Check-Act (PDCA) cycle:\n    - Plan: Establish AIMS objectives and processes (Clauses 4-6)\n    - Do: Implement the AIMS and its processes (Clauses 7-8)\n    - Check: Monitor and evaluate performance (Clause 9)\n    - Act: Take actions to improve performance (Clause 10)\n\n    The standard emphasizes:\n    - Risk-based thinking throughout the AI lifecycle\n    - Responsible AI development and deployment\n    - Transparency and accountability\n    - Continual improvement\n\n    Example:\n        &gt;&gt;&gt; framework = ISO42001Framework()\n        &gt;&gt;&gt; result = await framework.check(entry, profile)\n        &gt;&gt;&gt; if not result.is_compliant:\n        ...     for violation in result.violations:\n        ...         print(f\"{violation.rule_id}: {violation.description}\")\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the ISO 42001 framework with all defined rules.\"\"\"\n        rules = self._create_rules()\n        super().__init__(name=\"ISO/IEC 42001\", version=\"2023\", rules=rules)\n\n    def _create_rules(self) -&gt; List[ComplianceRule]:\n        \"\"\"\n        Create all ISO 42001 compliance rules.\n\n        Returns:\n            List of ComplianceRule objects representing ISO 42001 requirements\n        \"\"\"\n        return [\n            # =================================================================\n            # Clause 4: Context of the Organization\n            # =================================================================\n            ComplianceRule(\n                rule_id=\"ISO42001-4.1\",\n                name=\"Understanding Organization and Context\",\n                description=(\n                    \"The organization shall determine external and internal issues that \"\n                    \"are relevant to its purpose and that affect its ability to achieve \"\n                    \"the intended outcome(s) of its AI management system. This includes \"\n                    \"understanding the organization's role as an AI provider, deployer, \"\n                    \"or other relevant stakeholder, and the applicable legal, regulatory, \"\n                    \"and contractual requirements. (Clause 4.1)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"context\",\n                remediation=(\n                    \"Document the organizational context including: internal factors \"\n                    \"(governance structure, capabilities, culture), external factors \"\n                    \"(legal/regulatory environment, technology trends, stakeholder \"\n                    \"expectations), and the organization's role in the AI value chain.\"\n                ),\n                references=[\"ISO/IEC 42001:2023 Clause 4.1\"],\n            ),\n            ComplianceRule(\n                rule_id=\"ISO42001-4.2\",\n                name=\"Understanding Needs of Interested Parties\",\n                description=(\n                    \"The organization shall determine the interested parties that are \"\n                    \"relevant to the AI management system, the relevant requirements of \"\n                    \"these interested parties, and which of these requirements will be \"\n                    \"addressed through the AIMS. Interested parties may include customers, \"\n                    \"regulators, employees, AI system users, and affected communities. \"\n                    \"(Clause 4.2)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"context\",\n                remediation=(\n                    \"Identify and document all relevant interested parties and their \"\n                    \"requirements. Create a stakeholder register that includes: party \"\n                    \"identification, their needs and expectations, relevance to AIMS, \"\n                    \"and how requirements will be addressed.\"\n                ),\n                references=[\"ISO/IEC 42001:2023 Clause 4.2\"],\n            ),\n            ComplianceRule(\n                rule_id=\"ISO42001-4.3\",\n                name=\"Scope of AIMS Determined\",\n                description=(\n                    \"The organization shall determine the boundaries and applicability \"\n                    \"of the AI management system to establish its scope. The scope shall \"\n                    \"be available as documented information. When determining the scope, \"\n                    \"the organization shall consider the internal and external issues, \"\n                    \"requirements of interested parties, and interfaces with other \"\n                    \"management systems. (Clause 4.3)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"context\",\n                remediation=(\n                    \"Define and document the AIMS scope including: organizational units \"\n                    \"covered, AI systems included, physical locations, processes within \"\n                    \"scope, and any exclusions with justification. Ensure the scope \"\n                    \"statement is available to relevant interested parties.\"\n                ),\n                references=[\"ISO/IEC 42001:2023 Clause 4.3\"],\n            ),\n            # =================================================================\n            # Clause 5: Leadership\n            # =================================================================\n            ComplianceRule(\n                rule_id=\"ISO42001-5.1\",\n                name=\"Leadership Commitment Demonstrated\",\n                description=(\n                    \"Top management shall demonstrate leadership and commitment to the \"\n                    \"AI management system by ensuring the AI policy and objectives are \"\n                    \"established and compatible with strategic direction, ensuring \"\n                    \"integration into business processes, ensuring resources are available, \"\n                    \"communicating importance of effective AIMS, and promoting continual \"\n                    \"improvement. (Clause 5.1)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"leadership\",\n                remediation=(\n                    \"Document evidence of top management commitment including: meeting \"\n                    \"minutes showing AIMS discussions, resource allocation decisions, \"\n                    \"communication materials, and management review participation. \"\n                    \"Leadership must actively champion responsible AI practices.\"\n                ),\n                references=[\"ISO/IEC 42001:2023 Clause 5.1\"],\n            ),\n            ComplianceRule(\n                rule_id=\"ISO42001-5.2\",\n                name=\"AI Policy Established\",\n                description=(\n                    \"Top management shall establish an AI policy that is appropriate to \"\n                    \"the organization's purpose, provides a framework for setting AI \"\n                    \"objectives, includes a commitment to satisfy applicable requirements, \"\n                    \"includes a commitment to continual improvement, and addresses \"\n                    \"responsible AI principles including transparency, fairness, and \"\n                    \"accountability. (Clause 5.2)\"\n                ),\n                severity=RiskLevel.CRITICAL,\n                category=\"leadership\",\n                remediation=(\n                    \"Develop and publish an AI policy that: aligns with organizational \"\n                    \"strategy, establishes responsible AI principles, commits to \"\n                    \"compliance and improvement, is communicated throughout the \"\n                    \"organization, and is available to interested parties as appropriate.\"\n                ),\n                references=[\"ISO/IEC 42001:2023 Clause 5.2\"],\n            ),\n            ComplianceRule(\n                rule_id=\"ISO42001-5.3\",\n                name=\"Roles and Responsibilities Assigned\",\n                description=(\n                    \"Top management shall ensure that the responsibilities and authorities \"\n                    \"for relevant roles are assigned and communicated within the \"\n                    \"organization. This includes assigning responsibility for ensuring \"\n                    \"AIMS conformance to ISO 42001 and reporting on AIMS performance. \"\n                    \"(Clause 5.3)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"leadership\",\n                remediation=(\n                    \"Define and document roles related to AI governance including: AIMS \"\n                    \"owner/manager, AI ethics officer, risk owners, system owners, and \"\n                    \"oversight committees. Create RACI matrices for AI-related processes \"\n                    \"and communicate assignments to all relevant personnel.\"\n                ),\n                references=[\"ISO/IEC 42001:2023 Clause 5.3\"],\n            ),\n            # =================================================================\n            # Clause 6: Planning\n            # =================================================================\n            ComplianceRule(\n                rule_id=\"ISO42001-6.1\",\n                name=\"AI Risk Assessment Conducted\",\n                description=(\n                    \"The organization shall plan and implement a process to identify, \"\n                    \"analyze, and evaluate AI-related risks. The risk assessment shall \"\n                    \"consider risks to the organization, to individuals, to groups, and \"\n                    \"to society arising from AI system development and use. Risk criteria \"\n                    \"shall be established and maintained. (Clause 6.1)\"\n                ),\n                severity=RiskLevel.CRITICAL,\n                category=\"planning\",\n                remediation=(\n                    \"Implement a comprehensive AI risk assessment process that: defines \"\n                    \"risk criteria and acceptance thresholds, identifies AI-specific risks \"\n                    \"(bias, safety, privacy, security), evaluates likelihood and impact, \"\n                    \"documents risk treatment decisions, and maintains a risk register.\"\n                ),\n                references=[\"ISO/IEC 42001:2023 Clause 6.1\", \"Annex A\"],\n            ),\n            ComplianceRule(\n                rule_id=\"ISO42001-6.2\",\n                name=\"AI Objectives Established\",\n                description=(\n                    \"The organization shall establish AI objectives at relevant functions, \"\n                    \"levels, and processes. Objectives shall be consistent with the AI \"\n                    \"policy, measurable, take into account applicable requirements, be \"\n                    \"monitored, communicated, and updated as appropriate. Plans to achieve \"\n                    \"objectives shall define what will be done, resources required, \"\n                    \"responsibilities, timelines, and evaluation methods. (Clause 6.2)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"planning\",\n                remediation=(\n                    \"Define measurable AI objectives that support the AI policy. For each \"\n                    \"objective, document: target metrics, responsible parties, required \"\n                    \"resources, implementation timeline, and progress monitoring approach. \"\n                    \"Review and update objectives regularly.\"\n                ),\n                references=[\"ISO/IEC 42001:2023 Clause 6.2\"],\n            ),\n            ComplianceRule(\n                rule_id=\"ISO42001-6.3\",\n                name=\"AI Impact Assessment Performed\",\n                description=(\n                    \"The organization shall perform AI system impact assessments to \"\n                    \"identify and evaluate the potential impacts of AI systems on \"\n                    \"individuals, groups, and society. The assessment shall consider \"\n                    \"impacts throughout the AI system lifecycle including development, \"\n                    \"deployment, use, and decommissioning. (Clause 6.1.4)\"\n                ),\n                severity=RiskLevel.CRITICAL,\n                category=\"planning\",\n                remediation=(\n                    \"Conduct impact assessments for AI systems covering: intended use \"\n                    \"cases and users, potential beneficial and harmful impacts, effects \"\n                    \"on fundamental rights and freedoms, environmental considerations, \"\n                    \"and cumulative effects. Document assessment results and mitigation \"\n                    \"measures.\"\n                ),\n                references=[\"ISO/IEC 42001:2023 Clause 6.1.4\", \"Annex B\"],\n            ),\n            # =================================================================\n            # Clause 7: Support\n            # =================================================================\n            ComplianceRule(\n                rule_id=\"ISO42001-7.1\",\n                name=\"Resources Provided\",\n                description=(\n                    \"The organization shall determine and provide the resources needed \"\n                    \"for the establishment, implementation, maintenance, and continual \"\n                    \"improvement of the AI management system. This includes human \"\n                    \"resources, infrastructure, technology, and financial resources \"\n                    \"appropriate for the scale and complexity of AI operations. (Clause 7.1)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"support\",\n                remediation=(\n                    \"Document resource requirements for AIMS implementation including: \"\n                    \"personnel allocation, training budgets, technology infrastructure, \"\n                    \"tool procurement, and ongoing operational support. Ensure resource \"\n                    \"planning is part of organizational budgeting processes.\"\n                ),\n                references=[\"ISO/IEC 42001:2023 Clause 7.1\"],\n            ),\n            ComplianceRule(\n                rule_id=\"ISO42001-7.2\",\n                name=\"Competence Ensured\",\n                description=(\n                    \"The organization shall determine the necessary competence of persons \"\n                    \"doing work under its control that affects AI management system \"\n                    \"performance, ensure these persons are competent on the basis of \"\n                    \"appropriate education, training, or experience, take actions to \"\n                    \"acquire the necessary competence, and retain documented evidence \"\n                    \"of competence. (Clause 7.2)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"support\",\n                remediation=(\n                    \"Establish competency requirements for AI-related roles covering: \"\n                    \"technical skills, ethical considerations, risk management, and \"\n                    \"regulatory awareness. Implement training programs, maintain competency \"\n                    \"matrices, and retain evidence of qualifications and training completion.\"\n                ),\n                references=[\"ISO/IEC 42001:2023 Clause 7.2\"],\n            ),\n            ComplianceRule(\n                rule_id=\"ISO42001-7.3\",\n                name=\"Awareness Maintained\",\n                description=(\n                    \"Persons doing work under the organization's control shall be aware \"\n                    \"of the AI policy, their contribution to the AIMS effectiveness, the \"\n                    \"implications of not conforming to AIMS requirements, and the \"\n                    \"importance of responsible AI practices. (Clause 7.3)\"\n                ),\n                severity=RiskLevel.MEDIUM,\n                category=\"support\",\n                remediation=(\n                    \"Implement an awareness program that communicates: the AI policy and \"\n                    \"its relevance, individual responsibilities, consequences of non-\"\n                    \"conformance, and channels for raising concerns. Use multiple formats \"\n                    \"including onboarding, regular communications, and refresher training.\"\n                ),\n                references=[\"ISO/IEC 42001:2023 Clause 7.3\"],\n            ),\n            ComplianceRule(\n                rule_id=\"ISO42001-7.4\",\n                name=\"Communication Processes Established\",\n                description=(\n                    \"The organization shall determine the internal and external \"\n                    \"communications relevant to the AI management system including what \"\n                    \"to communicate, when, with whom, how, and who is responsible. \"\n                    \"Communication shall address both routine and incident-related \"\n                    \"notifications. (Clause 7.4)\"\n                ),\n                severity=RiskLevel.MEDIUM,\n                category=\"support\",\n                remediation=(\n                    \"Define communication processes covering: stakeholder identification, \"\n                    \"communication channels, frequency, content requirements, approval \"\n                    \"workflows, and records retention. Include both internal (employees, \"\n                    \"management) and external (regulators, customers, public) communications.\"\n                ),\n                references=[\"ISO/IEC 42001:2023 Clause 7.4\"],\n            ),\n            ComplianceRule(\n                rule_id=\"ISO42001-7.5\",\n                name=\"Documented Information Controlled\",\n                description=(\n                    \"The AI management system shall include documented information \"\n                    \"required by ISO 42001 and determined by the organization as necessary \"\n                    \"for AIMS effectiveness. Documented information shall be controlled to \"\n                    \"ensure availability, suitability, and adequate protection including \"\n                    \"distribution, access, retrieval, storage, and preservation. (Clause 7.5)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"support\",\n                remediation=(\n                    \"Implement document control procedures covering: identification and \"\n                    \"format requirements, review and approval, version control, access \"\n                    \"controls, retention periods, and disposal. Maintain a document register \"\n                    \"and ensure documents are available to those who need them.\"\n                ),\n                references=[\"ISO/IEC 42001:2023 Clause 7.5\"],\n            ),\n            # =================================================================\n            # Clause 8: Operation\n            # =================================================================\n            ComplianceRule(\n                rule_id=\"ISO42001-8.1\",\n                name=\"Operational Planning and Control\",\n                description=(\n                    \"The organization shall plan, implement, and control the processes \"\n                    \"needed to meet AI management system requirements. This includes \"\n                    \"establishing criteria for processes, implementing control of processes \"\n                    \"in accordance with criteria, maintaining documented information to \"\n                    \"have confidence processes are carried out as planned, and controlling \"\n                    \"planned changes. (Clause 8.1)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"operation\",\n                remediation=(\n                    \"Document operational procedures for AI processes including: process \"\n                    \"objectives and criteria, input/output specifications, roles and \"\n                    \"responsibilities, monitoring requirements, and change control \"\n                    \"procedures. Implement controls appropriate to process criticality.\"\n                ),\n                references=[\"ISO/IEC 42001:2023 Clause 8.1\"],\n            ),\n            ComplianceRule(\n                rule_id=\"ISO42001-8.2\",\n                name=\"AI System Lifecycle Processes\",\n                description=(\n                    \"The organization shall establish, implement, and maintain processes \"\n                    \"for AI system lifecycle management including: design and development, \"\n                    \"verification and validation, deployment, operation and monitoring, \"\n                    \"and retirement/decommissioning. Processes shall address data \"\n                    \"management, model development, and responsible AI considerations \"\n                    \"throughout the lifecycle. (Clause 8.2)\"\n                ),\n                severity=RiskLevel.CRITICAL,\n                category=\"operation\",\n                remediation=(\n                    \"Define lifecycle processes covering: requirements analysis, data \"\n                    \"acquisition and preparation, model development and training, testing \"\n                    \"and validation, deployment and release, monitoring and maintenance, \"\n                    \"and decommissioning. Include stage gates and approval requirements.\"\n                ),\n                references=[\"ISO/IEC 42001:2023 Clause 8.2\", \"Annex A.6\"],\n            ),\n            ComplianceRule(\n                rule_id=\"ISO42001-8.3\",\n                name=\"Third-Party Considerations\",\n                description=(\n                    \"The organization shall determine and apply criteria for the evaluation, \"\n                    \"selection, monitoring, and re-evaluation of external providers of \"\n                    \"AI-related products and services. The organization shall ensure that \"\n                    \"externally provided processes, products, and services conform to \"\n                    \"AIMS requirements. (Clause 8.3)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"operation\",\n                remediation=(\n                    \"Establish third-party management processes including: vendor \"\n                    \"qualification criteria, contractual requirements, due diligence \"\n                    \"procedures, ongoing monitoring, and performance evaluation. Address \"\n                    \"AI-specific considerations such as model provenance and data handling.\"\n                ),\n                references=[\"ISO/IEC 42001:2023 Clause 8.3\", \"Annex A.8\"],\n            ),\n            ComplianceRule(\n                rule_id=\"ISO42001-8.4\",\n                name=\"AI System Impact Assessment\",\n                description=(\n                    \"The organization shall perform and document AI system impact \"\n                    \"assessments prior to deployment and periodically during operation. \"\n                    \"The assessment shall evaluate actual and potential impacts on \"\n                    \"stakeholders, identifying both intended benefits and unintended \"\n                    \"consequences. Assessment results shall inform risk treatment and \"\n                    \"system modifications. (Clause 8.4)\"\n                ),\n                severity=RiskLevel.CRITICAL,\n                category=\"operation\",\n                remediation=(\n                    \"Conduct operational impact assessments that: identify affected \"\n                    \"stakeholders, evaluate impact severity and likelihood, assess \"\n                    \"cumulative effects, compare actual vs. expected outcomes, and \"\n                    \"trigger reviews when significant changes occur. Document findings \"\n                    \"and resulting actions.\"\n                ),\n                references=[\"ISO/IEC 42001:2023 Clause 8.4\", \"Annex B\"],\n            ),\n            # =================================================================\n            # Clause 9: Performance Evaluation\n            # =================================================================\n            ComplianceRule(\n                rule_id=\"ISO42001-9.1\",\n                name=\"Monitoring and Measurement\",\n                description=(\n                    \"The organization shall determine what needs to be monitored and \"\n                    \"measured, the methods for monitoring, measurement, analysis, and \"\n                    \"evaluation, when monitoring and measuring shall be performed, when \"\n                    \"results shall be analyzed and evaluated, and who shall analyze and \"\n                    \"evaluate. The organization shall retain documented evidence of \"\n                    \"monitoring and measurement results. (Clause 9.1)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"performance\",\n                remediation=(\n                    \"Define monitoring and measurement program including: key performance \"\n                    \"indicators for AIMS effectiveness, AI system performance metrics, \"\n                    \"measurement methods and tools, frequency of measurement, analysis \"\n                    \"procedures, and reporting requirements. Establish baselines and targets.\"\n                ),\n                references=[\"ISO/IEC 42001:2023 Clause 9.1\"],\n            ),\n            ComplianceRule(\n                rule_id=\"ISO42001-9.2\",\n                name=\"Internal Audit Conducted\",\n                description=(\n                    \"The organization shall conduct internal audits at planned intervals \"\n                    \"to provide information on whether the AIMS conforms to the \"\n                    \"organization's own requirements and ISO 42001 requirements, and is \"\n                    \"effectively implemented and maintained. The organization shall define \"\n                    \"audit criteria, scope, frequency, and methods, and ensure objectivity \"\n                    \"and impartiality of the audit process. (Clause 9.2)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"performance\",\n                remediation=(\n                    \"Establish an internal audit program that: defines audit scope and \"\n                    \"criteria based on ISO 42001, schedules audits considering process \"\n                    \"importance and previous results, ensures auditor competence and \"\n                    \"independence, documents findings and corrective actions, and reports \"\n                    \"results to management.\"\n                ),\n                references=[\"ISO/IEC 42001:2023 Clause 9.2\"],\n            ),\n            ComplianceRule(\n                rule_id=\"ISO42001-9.3\",\n                name=\"Management Review\",\n                description=(\n                    \"Top management shall review the AI management system at planned \"\n                    \"intervals to ensure its continuing suitability, adequacy, and \"\n                    \"effectiveness. The review shall consider status of actions from \"\n                    \"previous reviews, changes in issues and requirements, AIMS \"\n                    \"performance including nonconformities, monitoring results, audit \"\n                    \"results, and opportunities for improvement. (Clause 9.3)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"performance\",\n                remediation=(\n                    \"Conduct management reviews that address: AIMS performance trends, \"\n                    \"audit findings and corrective actions, stakeholder feedback, \"\n                    \"resource adequacy, risk treatment effectiveness, and improvement \"\n                    \"opportunities. Document review inputs, discussions, and decisions \"\n                    \"including required actions.\"\n                ),\n                references=[\"ISO/IEC 42001:2023 Clause 9.3\"],\n            ),\n            # =================================================================\n            # Clause 10: Improvement\n            # =================================================================\n            ComplianceRule(\n                rule_id=\"ISO42001-10.1\",\n                name=\"Nonconformity and Corrective Action\",\n                description=(\n                    \"When a nonconformity occurs, the organization shall react to the \"\n                    \"nonconformity and take action to control and correct it, evaluate \"\n                    \"the need for action to eliminate causes, implement any action needed, \"\n                    \"review effectiveness of corrective action, and make changes to the \"\n                    \"AIMS if necessary. The organization shall retain documented \"\n                    \"information as evidence. (Clause 10.1)\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"improvement\",\n                remediation=(\n                    \"Implement a corrective action process that: captures nonconformities \"\n                    \"from multiple sources (audits, incidents, feedback), performs root \"\n                    \"cause analysis, defines and implements corrections, verifies \"\n                    \"effectiveness, and updates processes/documentation as needed. \"\n                    \"Maintain a corrective action log.\"\n                ),\n                references=[\"ISO/IEC 42001:2023 Clause 10.1\"],\n            ),\n            ComplianceRule(\n                rule_id=\"ISO42001-10.2\",\n                name=\"Continual Improvement\",\n                description=(\n                    \"The organization shall continually improve the suitability, adequacy, \"\n                    \"and effectiveness of the AI management system. This shall include \"\n                    \"consideration of the results of analysis and evaluation, and outputs \"\n                    \"from management review, to determine opportunities for improvement. \"\n                    \"The organization shall take actions to improve AIMS performance and \"\n                    \"responsible AI practices. (Clause 10.2)\"\n                ),\n                severity=RiskLevel.MEDIUM,\n                category=\"improvement\",\n                remediation=(\n                    \"Establish improvement mechanisms including: systematic collection \"\n                    \"of improvement opportunities, prioritization based on impact and \"\n                    \"feasibility, implementation planning, and tracking of improvement \"\n                    \"initiatives. Promote a culture of continuous improvement in AI \"\n                    \"governance and responsible AI practices.\"\n                ),\n                references=[\"ISO/IEC 42001:2023 Clause 10.2\"],\n            ),\n        ]\n\n    def _check_rule(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check a single ISO 42001 rule against an audit entry.\n\n        Evaluates the audit entry against the specific rule requirements\n        and returns a violation if the entry does not comply.\n\n        Args:\n            entry: The audit entry to check\n            rule: The rule to evaluate\n\n        Returns:\n            ComplianceViolation if the rule is violated, None otherwise\n        \"\"\"\n        # Use custom check function if provided\n        if rule.check_fn is not None:\n            is_compliant = rule.check_fn(entry)\n            if not is_compliant:\n                return self._create_violation(entry, rule, \"Custom check failed\")\n            return None\n\n        # Framework-specific rule checks\n        if rule.rule_id == \"ISO42001-4.1\":\n            return self._check_organizational_context(entry, rule)\n        elif rule.rule_id == \"ISO42001-4.2\":\n            return self._check_interested_parties(entry, rule)\n        elif rule.rule_id == \"ISO42001-4.3\":\n            return self._check_aims_scope(entry, rule)\n        elif rule.rule_id == \"ISO42001-5.1\":\n            return self._check_leadership_commitment(entry, rule)\n        elif rule.rule_id == \"ISO42001-5.2\":\n            return self._check_ai_policy(entry, rule)\n        elif rule.rule_id == \"ISO42001-5.3\":\n            return self._check_roles_responsibilities(entry, rule)\n        elif rule.rule_id == \"ISO42001-6.1\":\n            return self._check_risk_assessment(entry, rule)\n        elif rule.rule_id == \"ISO42001-6.2\":\n            return self._check_ai_objectives(entry, rule)\n        elif rule.rule_id == \"ISO42001-6.3\":\n            return self._check_impact_assessment(entry, rule)\n        elif rule.rule_id == \"ISO42001-7.1\":\n            return self._check_resources(entry, rule)\n        elif rule.rule_id == \"ISO42001-7.2\":\n            return self._check_competence(entry, rule)\n        elif rule.rule_id == \"ISO42001-7.3\":\n            return self._check_awareness(entry, rule)\n        elif rule.rule_id == \"ISO42001-7.4\":\n            return self._check_communication(entry, rule)\n        elif rule.rule_id == \"ISO42001-7.5\":\n            return self._check_documented_information(entry, rule)\n        elif rule.rule_id == \"ISO42001-8.1\":\n            return self._check_operational_planning(entry, rule)\n        elif rule.rule_id == \"ISO42001-8.2\":\n            return self._check_lifecycle_processes(entry, rule)\n        elif rule.rule_id == \"ISO42001-8.3\":\n            return self._check_third_party(entry, rule)\n        elif rule.rule_id == \"ISO42001-8.4\":\n            return self._check_system_impact(entry, rule)\n        elif rule.rule_id == \"ISO42001-9.1\":\n            return self._check_monitoring(entry, rule)\n        elif rule.rule_id == \"ISO42001-9.2\":\n            return self._check_internal_audit(entry, rule)\n        elif rule.rule_id == \"ISO42001-9.3\":\n            return self._check_management_review(entry, rule)\n        elif rule.rule_id == \"ISO42001-10.1\":\n            return self._check_corrective_action(entry, rule)\n        elif rule.rule_id == \"ISO42001-10.2\":\n            return self._check_continual_improvement(entry, rule)\n\n        return None\n\n    # =========================================================================\n    # Clause 4: Context of the Organization\n    # =========================================================================\n\n    def _check_organizational_context(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check ISO42001-4.1: Organizational context must be documented.\n\n        For system-level operations, verify that organizational context\n        documentation exists.\n        \"\"\"\n        system_events = {\"system_registration\", \"deployment\", \"system_update\", \"configuration\"}\n        if entry.event_type.lower() not in system_events:\n            return None\n\n        has_context_documented = entry.metadata.get(\"organizational_context_documented\", False)\n        if not has_context_documented:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"System operation (type={entry.event_type}) performed without \"\n                f\"documented organizational context\",\n            )\n        return None\n\n    def _check_interested_parties(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check ISO42001-4.2: Interested parties must be identified.\n\n        For deployment and external-facing operations, verify stakeholder\n        identification.\n        \"\"\"\n        stakeholder_relevant_events = {\"deployment\", \"release\", \"public_api\", \"data_sharing\"}\n        if entry.event_type.lower() not in stakeholder_relevant_events:\n            return None\n\n        has_stakeholders_identified = entry.metadata.get(\"stakeholders_identified\", False)\n        if not has_stakeholders_identified:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"External-facing operation (type={entry.event_type}) performed \"\n                f\"without documented stakeholder identification\",\n            )\n        return None\n\n    def _check_aims_scope(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check ISO42001-4.3: AIMS scope must be defined.\n\n        For system operations, verify that the system is within defined\n        AIMS scope.\n        \"\"\"\n        scope_relevant_events = {\"system_registration\", \"deployment\", \"new_system\", \"expansion\"}\n        if entry.event_type.lower() not in scope_relevant_events:\n            return None\n\n        has_scope_defined = entry.metadata.get(\"aims_scope_defined\", False)\n        in_scope = entry.metadata.get(\"within_aims_scope\", False)\n\n        if not has_scope_defined or not in_scope:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"System operation (type={entry.event_type}) performed for system \"\n                f\"without verified AIMS scope coverage\",\n            )\n        return None\n\n    # =========================================================================\n    # Clause 5: Leadership\n    # =========================================================================\n\n    def _check_leadership_commitment(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check ISO42001-5.1: Leadership commitment must be demonstrated.\n\n        For significant decisions and resource allocations, verify\n        management approval.\n        \"\"\"\n        leadership_events = {\n            \"policy_change\", \"resource_allocation\", \"strategic_decision\",\n            \"deployment\", \"system_decommission\"\n        }\n        if entry.event_type.lower() not in leadership_events:\n            return None\n\n        has_leadership_approval = entry.metadata.get(\"leadership_approved\", False)\n        if not has_leadership_approval:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Significant operation (type={entry.event_type}) performed \"\n                f\"without documented leadership approval\",\n            )\n        return None\n\n    def _check_ai_policy(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check ISO42001-5.2: AI policy must be established.\n\n        All AI operations should reference compliance with the AI policy.\n        \"\"\"\n        ai_events = {\n            \"inference\", \"training\", \"deployment\", \"model_update\",\n            \"data_processing\", \"prediction\"\n        }\n        if entry.event_type.lower() not in ai_events:\n            return None\n\n        has_policy_reference = entry.metadata.get(\"ai_policy_compliant\", False)\n        if not has_policy_reference:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"AI operation (type={entry.event_type}) performed without \"\n                f\"verified AI policy compliance\",\n            )\n        return None\n\n    def _check_roles_responsibilities(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check ISO42001-5.3: Roles and responsibilities must be assigned.\n\n        Verify that actors performing operations have defined roles.\n        \"\"\"\n        # For critical operations, verify role assignment\n        critical_events = {\n            \"deployment\", \"training\", \"model_update\", \"access_grant\",\n            \"configuration_change\", \"incident_response\"\n        }\n        if entry.event_type.lower() not in critical_events:\n            return None\n\n        has_role_defined = entry.metadata.get(\"role_defined\", False)\n        has_authorization = entry.metadata.get(\"authorized_role\", False)\n\n        if not (has_role_defined and has_authorization):\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Critical operation (type={entry.event_type}) performed by actor \"\n                f\"without defined/authorized role: {entry.actor}\",\n            )\n        return None\n\n    # =========================================================================\n    # Clause 6: Planning\n    # =========================================================================\n\n    def _check_risk_assessment(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check ISO42001-6.1: AI risk assessment must be conducted.\n\n        High-risk operations must have documented risk assessments.\n        \"\"\"\n        if entry.risk_level not in (RiskLevel.HIGH, RiskLevel.CRITICAL):\n            return None\n\n        has_risk_assessment = entry.metadata.get(\"risk_assessment_documented\", False)\n        if not has_risk_assessment:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"High-risk operation (level={entry.risk_level.value}) performed \"\n                f\"without documented AI risk assessment\",\n            )\n        return None\n\n    def _check_ai_objectives(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check ISO42001-6.2: AI objectives must be established.\n\n        Strategic and planning operations should align with AI objectives.\n        \"\"\"\n        objective_relevant_events = {\n            \"project_initiation\", \"planning\", \"deployment\",\n            \"system_design\", \"milestone_review\"\n        }\n        if entry.event_type.lower() not in objective_relevant_events:\n            return None\n\n        has_objectives_alignment = entry.metadata.get(\"ai_objectives_aligned\", False)\n        if not has_objectives_alignment:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Planning operation (type={entry.event_type}) performed without \"\n                f\"documented alignment to AI objectives\",\n            )\n        return None\n\n    def _check_impact_assessment(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check ISO42001-6.3: AI impact assessment must be performed.\n\n        Deployment and high-impact operations require impact assessments.\n        \"\"\"\n        impact_events = {\n            \"deployment\", \"release\", \"model_update\", \"expansion\",\n            \"new_use_case\", \"user_facing_change\"\n        }\n        if entry.event_type.lower() not in impact_events:\n            return None\n\n        has_impact_assessment = entry.metadata.get(\"impact_assessment_documented\", False)\n        if not has_impact_assessment:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Impact-relevant operation (type={entry.event_type}) performed \"\n                f\"without documented AI impact assessment\",\n            )\n        return None\n\n    # =========================================================================\n    # Clause 7: Support\n    # =========================================================================\n\n    def _check_resources(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check ISO42001-7.1: Resources must be provided.\n\n        Resource-intensive operations should have resource allocation documented.\n        \"\"\"\n        resource_events = {\n            \"training\", \"deployment\", \"infrastructure_change\",\n            \"capacity_expansion\", \"project_initiation\"\n        }\n        if entry.event_type.lower() not in resource_events:\n            return None\n\n        has_resources_allocated = entry.metadata.get(\"resources_allocated\", False)\n        if not has_resources_allocated:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Resource-intensive operation (type={entry.event_type}) performed \"\n                f\"without documented resource allocation\",\n            )\n        return None\n\n    def _check_competence(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check ISO42001-7.2: Competence must be ensured.\n\n        Technical operations should be performed by competent personnel.\n        \"\"\"\n        competence_required_events = {\n            \"training\", \"model_development\", \"deployment\", \"incident_response\",\n            \"security_assessment\", \"audit\"\n        }\n        if entry.event_type.lower() not in competence_required_events:\n            return None\n\n        has_competence_verified = entry.metadata.get(\"competence_verified\", False)\n        if not has_competence_verified:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Technical operation (type={entry.event_type}) performed by actor \"\n                f\"without verified competence: {entry.actor}\",\n            )\n        return None\n\n    def _check_awareness(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check ISO42001-7.3: Awareness must be maintained.\n\n        User-initiated operations should have awareness acknowledgment.\n        \"\"\"\n        awareness_events = {\n            \"user_onboarding\", \"access_grant\", \"training_completion\",\n            \"policy_acknowledgment\"\n        }\n        if entry.event_type.lower() not in awareness_events:\n            return None\n\n        has_awareness_confirmed = entry.metadata.get(\"awareness_confirmed\", False)\n        if not has_awareness_confirmed:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Awareness-related operation (type={entry.event_type}) completed \"\n                f\"without confirmed awareness acknowledgment\",\n            )\n        return None\n\n    def _check_communication(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check ISO42001-7.4: Communication processes must be established.\n\n        External and stakeholder communications should follow defined processes.\n        \"\"\"\n        communication_events = {\n            \"external_communication\", \"stakeholder_notification\",\n            \"incident_notification\", \"regulatory_report\", \"public_disclosure\"\n        }\n        if entry.event_type.lower() not in communication_events:\n            return None\n\n        has_communication_process = entry.metadata.get(\"communication_process_followed\", False)\n        if not has_communication_process:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Communication operation (type={entry.event_type}) performed \"\n                f\"without following established communication processes\",\n            )\n        return None\n\n    def _check_documented_information(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check ISO42001-7.5: Documented information must be controlled.\n\n        Document-related operations should follow document control procedures.\n        \"\"\"\n        document_events = {\n            \"document_creation\", \"document_update\", \"policy_change\",\n            \"procedure_change\", \"record_creation\"\n        }\n        if entry.event_type.lower() not in document_events:\n            return None\n\n        has_document_control = entry.metadata.get(\"document_control_applied\", False)\n        if not has_document_control:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Document operation (type={entry.event_type}) performed without \"\n                f\"following document control procedures\",\n            )\n        return None\n\n    # =========================================================================\n    # Clause 8: Operation\n    # =========================================================================\n\n    def _check_operational_planning(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check ISO42001-8.1: Operational planning and control required.\n\n        Significant operations should have documented planning.\n        \"\"\"\n        operational_events = {\n            \"deployment\", \"release\", \"migration\", \"integration\",\n            \"process_change\", \"configuration_change\"\n        }\n        if entry.event_type.lower() not in operational_events:\n            return None\n\n        has_operational_plan = entry.metadata.get(\"operational_plan_documented\", False)\n        if not has_operational_plan:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Operational activity (type={entry.event_type}) performed \"\n                f\"without documented operational planning\",\n            )\n        return None\n\n    def _check_lifecycle_processes(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check ISO42001-8.2: AI system lifecycle processes required.\n\n        Lifecycle events should follow defined processes.\n        \"\"\"\n        lifecycle_events = {\n            \"design\", \"development\", \"training\", \"validation\", \"testing\",\n            \"deployment\", \"monitoring\", \"maintenance\", \"decommission\"\n        }\n        if entry.event_type.lower() not in lifecycle_events:\n            return None\n\n        has_lifecycle_process = entry.metadata.get(\"lifecycle_process_followed\", False)\n        if not has_lifecycle_process:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Lifecycle operation (type={entry.event_type}) performed \"\n                f\"without following defined lifecycle processes\",\n            )\n        return None\n\n    def _check_third_party(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check ISO42001-8.3: Third-party considerations required.\n\n        Operations involving external parties should have due diligence.\n        \"\"\"\n        third_party_events = {\n            \"vendor_engagement\", \"external_api_call\", \"model_import\",\n            \"data_acquisition\", \"outsourcing\", \"third_party_integration\"\n        }\n        if entry.event_type.lower() not in third_party_events:\n            return None\n\n        has_third_party_eval = entry.metadata.get(\"third_party_evaluated\", False)\n        if not has_third_party_eval:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Third-party operation (type={entry.event_type}) performed \"\n                f\"without documented third-party evaluation\",\n            )\n        return None\n\n    def _check_system_impact(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check ISO42001-8.4: AI system impact assessment required.\n\n        Deployment and significant changes require impact assessment.\n        \"\"\"\n        impact_events = {\n            \"deployment\", \"major_update\", \"user_expansion\",\n            \"new_market\", \"feature_release\"\n        }\n        if entry.event_type.lower() not in impact_events:\n            return None\n\n        has_system_impact_assessment = entry.metadata.get(\n            \"system_impact_assessment_documented\", False\n        )\n        if not has_system_impact_assessment:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"System change (type={entry.event_type}) deployed without \"\n                f\"documented system impact assessment\",\n            )\n        return None\n\n    # =========================================================================\n    # Clause 9: Performance Evaluation\n    # =========================================================================\n\n    def _check_monitoring(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check ISO42001-9.1: Monitoring and measurement required.\n\n        Production systems should have monitoring in place.\n        \"\"\"\n        monitoring_events = {\"inference\", \"prediction\", \"production_operation\"}\n        if entry.event_type.lower() not in monitoring_events:\n            return None\n\n        has_monitoring = entry.metadata.get(\"monitoring_enabled\", False)\n        if not has_monitoring:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Production operation (type={entry.event_type}) performed \"\n                f\"without enabled monitoring and measurement\",\n            )\n        return None\n\n    def _check_internal_audit(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check ISO42001-9.2: Internal audit must be conducted.\n\n        Audit-related operations should follow audit procedures.\n        \"\"\"\n        audit_events = {\"audit\", \"audit_finding\", \"compliance_check\"}\n        if entry.event_type.lower() not in audit_events:\n            return None\n\n        has_audit_procedure = entry.metadata.get(\"audit_procedure_followed\", False)\n        if not has_audit_procedure:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Audit operation (type={entry.event_type}) performed \"\n                f\"without following internal audit procedures\",\n            )\n        return None\n\n    def _check_management_review(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check ISO42001-9.3: Management review required.\n\n        Management review operations should be documented.\n        \"\"\"\n        review_events = {\"management_review\", \"executive_briefing\", \"governance_meeting\"}\n        if entry.event_type.lower() not in review_events:\n            return None\n\n        has_review_documentation = entry.metadata.get(\"review_documented\", False)\n        if not has_review_documentation:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Management review (type={entry.event_type}) conducted \"\n                f\"without proper documentation of inputs and outputs\",\n            )\n        return None\n\n    # =========================================================================\n    # Clause 10: Improvement\n    # =========================================================================\n\n    def _check_corrective_action(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check ISO42001-10.1: Nonconformity and corrective action required.\n\n        Nonconformities should have corrective actions documented.\n        \"\"\"\n        nonconformity_events = {\n            \"nonconformity\", \"incident\", \"audit_finding\",\n            \"complaint\", \"failure\", \"error\"\n        }\n        if entry.event_type.lower() not in nonconformity_events:\n            return None\n\n        has_corrective_action = entry.metadata.get(\"corrective_action_documented\", False)\n        if not has_corrective_action:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Nonconformity (type={entry.event_type}) identified without \"\n                f\"documented corrective action plan\",\n            )\n        return None\n\n    def _check_continual_improvement(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check ISO42001-10.2: Continual improvement required.\n\n        Improvement opportunities should be captured and tracked.\n        \"\"\"\n        improvement_events = {\n            \"improvement_opportunity\", \"lessons_learned\",\n            \"process_optimization\", \"enhancement_request\"\n        }\n        if entry.event_type.lower() not in improvement_events:\n            return None\n\n        has_improvement_tracking = entry.metadata.get(\"improvement_tracked\", False)\n        if not has_improvement_tracking:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Improvement opportunity (type={entry.event_type}) identified \"\n                f\"without being tracked in improvement register\",\n            )\n        return None\n\n    def _create_violation(\n        self, entry: AuditEntry, rule: ComplianceRule, evidence: str\n    ) -&gt; ComplianceViolation:\n        \"\"\"\n        Create a compliance violation object.\n\n        Args:\n            entry: The audit entry that triggered the violation\n            rule: The rule that was violated\n            evidence: Specific evidence describing the violation\n\n        Returns:\n            ComplianceViolation object\n        \"\"\"\n        return ComplianceViolation(\n            rule_id=rule.rule_id,\n            rule_name=rule.name,\n            severity=rule.severity,\n            description=rule.description,\n            evidence=evidence,\n            remediation=rule.remediation,\n            entry_id=entry.entry_id,\n            category=rule.category,\n            framework=self._name,\n        )\n</code></pre>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.iso_42001.ISO42001Framework.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> <p>Initialize the ISO 42001 framework with all defined rules.</p> Source code in <code>src/rotalabs_comply/frameworks/iso_42001.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize the ISO 42001 framework with all defined rules.\"\"\"\n    rules = self._create_rules()\n    super().__init__(name=\"ISO/IEC 42001\", version=\"2023\", rules=rules)\n</code></pre>"},{"location":"api/frameworks/#categories_5","title":"Categories","text":"Category Clause Description <code>context</code> 4 Organizational context and AIMS scope <code>leadership</code> 5 Leadership commitment, AI policy, and roles <code>planning</code> 6 Risk assessment, objectives, and impact assessment <code>support</code> 7 Resources, competence, awareness, communication, documentation <code>operation</code> 8 Operational planning, lifecycle, third-party, impact <code>performance</code> 9 Monitoring, internal audit, management review <code>improvement</code> 10 Corrective action and continual improvement"},{"location":"api/frameworks/#rules_5","title":"Rules","text":"Rule ID Name Category Severity <code>ISO42001-4.1</code> Understanding Organization and Context context HIGH <code>ISO42001-4.2</code> Understanding Needs of Interested Parties context HIGH <code>ISO42001-4.3</code> Scope of AIMS Determined context HIGH <code>ISO42001-5.1</code> Leadership Commitment Demonstrated leadership HIGH <code>ISO42001-5.2</code> AI Policy Established leadership CRITICAL <code>ISO42001-5.3</code> Roles and Responsibilities Assigned leadership HIGH <code>ISO42001-6.1</code> AI Risk Assessment Conducted planning CRITICAL <code>ISO42001-6.2</code> AI Objectives Established planning HIGH <code>ISO42001-6.3</code> AI Impact Assessment Performed planning CRITICAL <code>ISO42001-7.1</code> Resources Provided support HIGH <code>ISO42001-7.2</code> Competence Ensured support HIGH <code>ISO42001-7.3</code> Awareness Maintained support MEDIUM <code>ISO42001-7.4</code> Communication Processes Established support MEDIUM <code>ISO42001-7.5</code> Documented Information Controlled support HIGH <code>ISO42001-8.1</code> Operational Planning and Control operation HIGH <code>ISO42001-8.2</code> AI System Lifecycle Processes operation CRITICAL <code>ISO42001-8.3</code> Third-Party Considerations operation HIGH <code>ISO42001-8.4</code> AI System Impact Assessment operation CRITICAL <code>ISO42001-9.1</code> Monitoring and Measurement performance HIGH <code>ISO42001-9.2</code> Internal Audit Conducted performance HIGH <code>ISO42001-9.3</code> Management Review performance HIGH <code>ISO42001-10.1</code> Nonconformity and Corrective Action improvement HIGH <code>ISO42001-10.2</code> Continual Improvement improvement MEDIUM"},{"location":"api/frameworks/#usage_5","title":"Usage","text":"<pre><code>from rotalabs_comply.frameworks.iso_42001 import ISO42001Framework\nfrom rotalabs_comply.frameworks.base import AuditEntry, ComplianceProfile, RiskLevel\nfrom datetime import datetime\n\nframework = ISO42001Framework()\n\nentry = AuditEntry(\n    entry_id=\"iso-001\",\n    timestamp=datetime.utcnow(),\n    event_type=\"deployment\",\n    actor=\"ai-engineer@company.com\",\n    action=\"Deploy AI system\",\n    risk_level=RiskLevel.HIGH,\n    metadata={\n        \"organizational_context_documented\": True,\n        \"stakeholders_identified\": True,\n        \"aims_scope_defined\": True,\n        \"within_aims_scope\": True,\n        \"leadership_approved\": True,\n        \"ai_policy_compliant\": True,\n        \"role_defined\": True,\n        \"authorized_role\": True,\n        \"risk_assessment_documented\": True,\n        \"impact_assessment_documented\": True,\n        \"lifecycle_process_followed\": True,\n        \"operational_plan_documented\": True,\n        \"monitoring_enabled\": True,\n    },\n)\n\nprofile = ComplianceProfile(\n    profile_id=\"iso42001-profile\",\n    name=\"ISO 42001 Compliance\",\n)\n\nresult = await framework.check(entry, profile)\n</code></pre>"},{"location":"api/frameworks/#key-requirements_5","title":"Key Requirements","text":"<p>All AI operations require: - <code>metadata[\"ai_policy_compliant\"]=True</code></p> <p>System deployments require: - <code>metadata[\"organizational_context_documented\"]=True</code> - <code>metadata[\"aims_scope_defined\"]=True</code> and <code>metadata[\"within_aims_scope\"]=True</code> - <code>metadata[\"leadership_approved\"]=True</code> - <code>metadata[\"lifecycle_process_followed\"]=True</code> - <code>metadata[\"operational_plan_documented\"]=True</code></p> <p>High-risk operations require: - <code>metadata[\"risk_assessment_documented\"]=True</code></p> <p>Critical operations require: - <code>metadata[\"role_defined\"]=True</code> and <code>metadata[\"authorized_role\"]=True</code> - <code>metadata[\"competence_verified\"]=True</code></p>"},{"location":"api/frameworks/#mas-feat-framework","title":"MAS FEAT Framework","text":"<p>MAS (Monetary Authority of Singapore) FEAT principles and AI governance framework for financial institutions.</p>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.mas.MASFramework","title":"MASFramework","text":"<p>MAS (Monetary Authority of Singapore) AI governance compliance framework.</p> <p>Implements compliance checks based on MAS FEAT principles and AI governance guidelines for financial institutions operating in Singapore. The framework evaluates audit entries against requirements for fairness, ethics, accountability, transparency, model risk management, data governance, and operational resilience.</p> <p>The FEAT principles establish expectations for financial institutions to: - Ensure AI-driven decisions are fair and do not result in unfair treatment - Use data and AI in an ethical manner aligned with firm values - Maintain clear accountability structures for AI decisions - Provide transparency to customers about AI use and decision-making</p> <p>Additionally, the framework incorporates MAS model risk management requirements and technology risk management guidelines relevant to AI systems.</p> Example <p>framework = MASFramework() result = await framework.check(entry, profile) if not result.is_compliant: ...     for violation in result.violations: ...         print(f\"{violation.rule_id}: {violation.description}\")</p> Note <p>This framework is specifically designed for financial institutions regulated by MAS. Organizations outside MAS jurisdiction should use other appropriate frameworks.</p> Source code in <code>src/rotalabs_comply/frameworks/mas.py</code> <pre><code>class MASFramework(BaseFramework):\n    \"\"\"\n    MAS (Monetary Authority of Singapore) AI governance compliance framework.\n\n    Implements compliance checks based on MAS FEAT principles and AI governance\n    guidelines for financial institutions operating in Singapore. The framework\n    evaluates audit entries against requirements for fairness, ethics, accountability,\n    transparency, model risk management, data governance, and operational resilience.\n\n    The FEAT principles establish expectations for financial institutions to:\n    - Ensure AI-driven decisions are fair and do not result in unfair treatment\n    - Use data and AI in an ethical manner aligned with firm values\n    - Maintain clear accountability structures for AI decisions\n    - Provide transparency to customers about AI use and decision-making\n\n    Additionally, the framework incorporates MAS model risk management requirements\n    and technology risk management guidelines relevant to AI systems.\n\n    Example:\n        &gt;&gt;&gt; framework = MASFramework()\n        &gt;&gt;&gt; result = await framework.check(entry, profile)\n        &gt;&gt;&gt; if not result.is_compliant:\n        ...     for violation in result.violations:\n        ...         print(f\"{violation.rule_id}: {violation.description}\")\n\n    Note:\n        This framework is specifically designed for financial institutions\n        regulated by MAS. Organizations outside MAS jurisdiction should\n        use other appropriate frameworks.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the MAS framework with all defined rules.\"\"\"\n        rules = self._create_rules()\n        super().__init__(name=\"MAS FEAT\", version=\"2022\", rules=rules)\n\n    def _create_rules(self) -&gt; List[ComplianceRule]:\n        \"\"\"\n        Create all MAS compliance rules.\n\n        Returns:\n            List of ComplianceRule objects representing MAS FEAT principles\n            and AI governance requirements\n        \"\"\"\n        return [\n            # ================================================================\n            # FEAT Principles - Fairness\n            # ================================================================\n            ComplianceRule(\n                rule_id=\"MAS-FEAT-F1\",\n                name=\"Fair AI-Driven Decisions\",\n                description=(\n                    \"Financial institutions should ensure that AI-driven decisions are \"\n                    \"fair and do not systematically disadvantage individuals or groups. \"\n                    \"AI systems used in customer-facing decisions (e.g., credit scoring, \"\n                    \"insurance underwriting, fraud detection) must be designed to avoid \"\n                    \"unfair discrimination based on protected attributes such as race, \"\n                    \"gender, age, religion, or nationality, except where such attributes \"\n                    \"are legitimate risk factors permitted by law.\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"fairness\",\n                remediation=(\n                    \"Implement fairness testing procedures that evaluate AI outcomes \"\n                    \"across different demographic groups. Document fairness metrics and \"\n                    \"thresholds, and conduct regular fairness audits. Consider using \"\n                    \"fairness-aware algorithms and establish governance processes for \"\n                    \"reviewing and addressing fairness concerns.\"\n                ),\n                references=[\n                    \"MAS FEAT Principles - Fairness\",\n                    \"MAS Information Paper on FEAT (2018)\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"MAS-FEAT-F2\",\n                name=\"Bias Detection and Mitigation\",\n                description=(\n                    \"Financial institutions must implement measures to detect and mitigate \"\n                    \"biases in AI systems throughout the model lifecycle. This includes \"\n                    \"bias detection during model development, ongoing monitoring for \"\n                    \"emergent biases, and corrective actions when biases are identified. \"\n                    \"Institutions should assess training data for historical biases and \"\n                    \"implement appropriate debiasing techniques where necessary.\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"fairness\",\n                remediation=(\n                    \"Establish bias detection processes including statistical analysis \"\n                    \"of training data and model outputs. Implement bias monitoring \"\n                    \"dashboards that track fairness metrics over time. Document bias \"\n                    \"mitigation strategies and maintain records of debiasing actions \"\n                    \"taken. Conduct periodic bias assessments and reviews.\"\n                ),\n                references=[\n                    \"MAS FEAT Principles - Fairness\",\n                    \"MAS Veritas Framework for Responsible AI\",\n                ],\n            ),\n            # ================================================================\n            # FEAT Principles - Ethics\n            # ================================================================\n            ComplianceRule(\n                rule_id=\"MAS-FEAT-E1\",\n                name=\"Ethical Use of Data and AI\",\n                description=(\n                    \"Financial institutions must ensure that data and AI are used in an \"\n                    \"ethical manner, respecting customer privacy, data protection requirements, \"\n                    \"and legitimate customer expectations. AI systems should not be used \"\n                    \"in ways that manipulate, deceive, or exploit customers. The use of \"\n                    \"alternative data sources must be evaluated for ethical implications \"\n                    \"and potential for unfair discrimination.\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"ethics\",\n                remediation=(\n                    \"Establish an AI ethics review process for new AI use cases. \"\n                    \"Document ethical considerations in AI system design documents. \"\n                    \"Implement data usage policies that ensure ethical data practices. \"\n                    \"Create mechanisms for stakeholders to raise ethical concerns about \"\n                    \"AI systems. Review alternative data sources for ethical implications.\"\n                ),\n                references=[\n                    \"MAS FEAT Principles - Ethics\",\n                    \"MAS Personal Data Protection Guidelines\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"MAS-FEAT-E2\",\n                name=\"AI Alignment with Firm's Ethical Standards\",\n                description=(\n                    \"AI systems must be developed and operated in alignment with the \"\n                    \"financial institution's ethical standards, corporate values, and \"\n                    \"professional codes of conduct. The use of AI should support, not \"\n                    \"undermine, the institution's commitment to treating customers fairly \"\n                    \"and maintaining market integrity.\"\n                ),\n                severity=RiskLevel.MEDIUM,\n                category=\"ethics\",\n                remediation=(\n                    \"Document how AI systems align with the firm's ethical standards \"\n                    \"and corporate values. Include ethics compliance as part of AI \"\n                    \"system design reviews. Ensure AI development teams are trained \"\n                    \"on the firm's ethical standards. Establish escalation procedures \"\n                    \"for ethical concerns related to AI systems.\"\n                ),\n                references=[\n                    \"MAS FEAT Principles - Ethics\",\n                    \"MAS Guidelines on Fair Dealing\",\n                ],\n            ),\n            # ================================================================\n            # FEAT Principles - Accountability\n            # ================================================================\n            ComplianceRule(\n                rule_id=\"MAS-FEAT-A1\",\n                name=\"Clear Accountability for AI Decisions\",\n                description=(\n                    \"Financial institutions must establish clear accountability structures \"\n                    \"for AI-driven decisions. This includes identifying individuals or \"\n                    \"committees responsible for AI system outcomes, ensuring appropriate \"\n                    \"governance oversight, and maintaining documentation of decision-making \"\n                    \"authority and responsibility. Senior management must be accountable \"\n                    \"for material AI systems and their outcomes.\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"accountability\",\n                remediation=(\n                    \"Define and document clear ownership and accountability for each \"\n                    \"AI system, including business owners, model owners, and technical \"\n                    \"owners. Establish AI governance committees with appropriate \"\n                    \"senior management representation. Create RACI matrices for AI \"\n                    \"decision-making processes. Ensure accountability is traceable \"\n                    \"in audit logs.\"\n                ),\n                references=[\n                    \"MAS FEAT Principles - Accountability\",\n                    \"MAS Guidelines on Individual Accountability and Conduct\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"MAS-FEAT-A2\",\n                name=\"Human Oversight for Material AI Decisions\",\n                description=(\n                    \"Material AI-driven decisions must include appropriate human oversight. \"\n                    \"Financial institutions should implement human-in-the-loop or \"\n                    \"human-on-the-loop mechanisms for AI systems that significantly impact \"\n                    \"customers or business operations. Humans must have the ability to \"\n                    \"intervene, override, or stop AI system operations when necessary.\"\n                ),\n                severity=RiskLevel.CRITICAL,\n                category=\"accountability\",\n                remediation=(\n                    \"Implement human oversight mechanisms appropriate to the risk level \"\n                    \"of AI decisions. Define criteria for when human review is mandatory. \"\n                    \"Provide tools and interfaces for humans to review, override, and \"\n                    \"intervene in AI decisions. Document human oversight procedures and \"\n                    \"ensure adequate training for personnel involved in oversight roles.\"\n                ),\n                references=[\n                    \"MAS FEAT Principles - Accountability\",\n                    \"MAS Model Risk Management Guidelines\",\n                ],\n            ),\n            # ================================================================\n            # FEAT Principles - Transparency\n            # ================================================================\n            ComplianceRule(\n                rule_id=\"MAS-FEAT-T1\",\n                name=\"Explainable AI Decisions\",\n                description=(\n                    \"Financial institutions should ensure that AI-driven decisions can be \"\n                    \"explained in a manner appropriate to the context and audience. \"\n                    \"Explanations should be provided for material decisions affecting \"\n                    \"customers, and internal stakeholders should have access to more \"\n                    \"detailed technical explanations. The level of explainability should \"\n                    \"be proportionate to the significance of the decision.\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"transparency\",\n                remediation=(\n                    \"Implement explainability mechanisms appropriate to each AI use case. \"\n                    \"Use interpretable models where possible, or implement post-hoc \"\n                    \"explanation techniques for complex models. Document the explanation \"\n                    \"methodology and ensure explanations are understandable by the \"\n                    \"intended audience. Maintain explanation logs for audit purposes.\"\n                ),\n                references=[\n                    \"MAS FEAT Principles - Transparency\",\n                    \"MAS Information Paper on Responsible AI in Finance\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"MAS-FEAT-T2\",\n                name=\"Customer Notification of AI Use\",\n                description=(\n                    \"Customers should be informed when AI is used to make or significantly \"\n                    \"influence decisions that affect them. Financial institutions should \"\n                    \"communicate the role of AI in decision-making processes, the types \"\n                    \"of data used, and how customers can seek recourse or human review \"\n                    \"of AI-driven decisions. Notification should be clear, timely, and \"\n                    \"accessible.\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"transparency\",\n                remediation=(\n                    \"Implement clear notification mechanisms to inform customers when AI \"\n                    \"is involved in decisions affecting them. Include AI disclosure in \"\n                    \"customer communications and terms of service. Establish processes \"\n                    \"for customers to request human review of AI decisions. Maintain \"\n                    \"records of customer notifications for audit purposes.\"\n                ),\n                references=[\n                    \"MAS FEAT Principles - Transparency\",\n                    \"MAS Guidelines on Fair Dealing\",\n                ],\n            ),\n            # ================================================================\n            # Model Risk Management\n            # ================================================================\n            ComplianceRule(\n                rule_id=\"MAS-MRM-1\",\n                name=\"Model Development Standards\",\n                description=(\n                    \"Financial institutions must establish robust standards for AI/ML \"\n                    \"model development. This includes documented development methodologies, \"\n                    \"data quality requirements, feature engineering standards, model \"\n                    \"selection criteria, and performance benchmarks. Development processes \"\n                    \"should ensure models are fit for purpose and align with business \"\n                    \"requirements.\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"model_risk\",\n                remediation=(\n                    \"Establish and document model development standards and methodologies. \"\n                    \"Define data quality requirements for model development. Implement \"\n                    \"version control for models and code. Document model assumptions, \"\n                    \"limitations, and intended use cases. Ensure development processes \"\n                    \"are reviewed and approved by appropriate stakeholders.\"\n                ),\n                references=[\n                    \"MAS Model Risk Management Guidelines\",\n                    \"MAS Technology Risk Management Guidelines\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"MAS-MRM-2\",\n                name=\"Model Validation Requirements\",\n                description=(\n                    \"All material AI/ML models must undergo independent validation before \"\n                    \"deployment and periodically thereafter. Validation should assess \"\n                    \"model conceptual soundness, data quality, model performance, and \"\n                    \"outcome analysis. The validation function should be independent of \"\n                    \"the model development function.\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"model_risk\",\n                remediation=(\n                    \"Establish an independent model validation function. Define validation \"\n                    \"scope, methodology, and frequency based on model materiality. \"\n                    \"Document validation findings and remediation actions. Ensure \"\n                    \"validation coverage includes conceptual soundness, implementation, \"\n                    \"and ongoing performance monitoring. Maintain validation records.\"\n                ),\n                references=[\n                    \"MAS Model Risk Management Guidelines\",\n                    \"MAS Supervisory Expectations on Model Risk\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"MAS-MRM-3\",\n                name=\"Model Monitoring and Review\",\n                description=(\n                    \"Financial institutions must implement ongoing monitoring of AI/ML \"\n                    \"models to detect performance degradation, data drift, concept drift, \"\n                    \"and unexpected behaviors. Models should be subject to periodic review \"\n                    \"and revalidation. Monitoring should include performance metrics, \"\n                    \"stability metrics, and business outcome tracking.\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"model_risk\",\n                remediation=(\n                    \"Implement comprehensive model monitoring frameworks that track \"\n                    \"performance metrics, input data distributions, and output patterns. \"\n                    \"Define alert thresholds and escalation procedures. Establish \"\n                    \"periodic review schedules based on model materiality. Document \"\n                    \"monitoring results and actions taken in response to issues.\"\n                ),\n                references=[\n                    \"MAS Model Risk Management Guidelines\",\n                    \"MAS Technology Risk Management Guidelines\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"MAS-MRM-4\",\n                name=\"Model Inventory Maintained\",\n                description=(\n                    \"Financial institutions must maintain a comprehensive inventory of \"\n                    \"all AI/ML models in use. The inventory should include model metadata, \"\n                    \"risk classifications, ownership information, validation status, and \"\n                    \"deployment details. The inventory enables effective governance and \"\n                    \"risk management of the model portfolio.\"\n                ),\n                severity=RiskLevel.MEDIUM,\n                category=\"model_risk\",\n                remediation=(\n                    \"Establish and maintain a centralized model inventory. Include \"\n                    \"essential metadata such as model purpose, risk tier, owner, \"\n                    \"validation status, and performance metrics. Implement processes \"\n                    \"to keep the inventory up to date. Use the inventory for portfolio \"\n                    \"risk assessment and resource allocation decisions.\"\n                ),\n                references=[\n                    \"MAS Model Risk Management Guidelines\",\n                    \"MAS Technology Risk Management Guidelines\",\n                ],\n            ),\n            # ================================================================\n            # Data Governance\n            # ================================================================\n            ComplianceRule(\n                rule_id=\"MAS-DATA-1\",\n                name=\"Data Quality Standards\",\n                description=(\n                    \"Financial institutions must establish and maintain data quality \"\n                    \"standards for AI systems. Data used in AI/ML models should be \"\n                    \"accurate, complete, consistent, timely, and relevant. Data quality \"\n                    \"should be assessed and documented, with processes in place to \"\n                    \"address data quality issues.\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"data_governance\",\n                remediation=(\n                    \"Define data quality standards and metrics for AI use cases. \"\n                    \"Implement data quality checks and validation procedures. \"\n                    \"Document data quality assessments and remediation actions. \"\n                    \"Establish data quality monitoring and alerting mechanisms. \"\n                    \"Ensure data quality issues are escalated and resolved promptly.\"\n                ),\n                references=[\n                    \"MAS Data Management Guidelines\",\n                    \"MAS Technology Risk Management Guidelines\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"MAS-DATA-2\",\n                name=\"Data Lineage Documentation\",\n                description=(\n                    \"Financial institutions must maintain documentation of data lineage \"\n                    \"for AI systems. This includes tracking data sources, transformations, \"\n                    \"aggregations, and dependencies throughout the data pipeline. Data \"\n                    \"lineage supports auditability, debugging, and impact analysis.\"\n                ),\n                severity=RiskLevel.MEDIUM,\n                category=\"data_governance\",\n                remediation=(\n                    \"Implement data lineage tracking for AI data pipelines. Document \"\n                    \"data sources, transformations, and dependencies. Use data lineage \"\n                    \"tools or metadata management systems where appropriate. Ensure \"\n                    \"data lineage is available for audit and investigation purposes. \"\n                    \"Maintain lineage documentation for the data retention period.\"\n                ),\n                references=[\n                    \"MAS Data Management Guidelines\",\n                    \"MAS Technology Risk Management Guidelines\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"MAS-DATA-3\",\n                name=\"Data Privacy Compliance\",\n                description=(\n                    \"AI systems must comply with data privacy requirements including \"\n                    \"Singapore's Personal Data Protection Act (PDPA) and MAS-specific \"\n                    \"data protection requirements. This includes obtaining appropriate \"\n                    \"consent, limiting data use to stated purposes, implementing data \"\n                    \"minimization, and ensuring secure data handling.\"\n                ),\n                severity=RiskLevel.CRITICAL,\n                category=\"data_governance\",\n                remediation=(\n                    \"Ensure AI systems comply with PDPA and MAS data protection requirements. \"\n                    \"Implement appropriate consent mechanisms for data collection and use. \"\n                    \"Apply data minimization principles - collect and retain only necessary \"\n                    \"data. Implement access controls and encryption for personal data. \"\n                    \"Conduct privacy impact assessments for AI use cases involving personal data.\"\n                ),\n                references=[\n                    \"Singapore Personal Data Protection Act (PDPA)\",\n                    \"MAS Guidelines on Fair Dealing\",\n                    \"MAS Data Management Guidelines\",\n                ],\n            ),\n            # ================================================================\n            # Operational Resilience\n            # ================================================================\n            ComplianceRule(\n                rule_id=\"MAS-OPS-1\",\n                name=\"AI System Resilience\",\n                description=(\n                    \"AI systems must be designed and operated with appropriate resilience \"\n                    \"measures to ensure continued availability and performance. This \"\n                    \"includes redundancy, failover mechanisms, capacity management, and \"\n                    \"graceful degradation capabilities. Systems should be resilient to \"\n                    \"input anomalies and adversarial inputs.\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"operations\",\n                remediation=(\n                    \"Design AI systems with appropriate redundancy and failover \"\n                    \"capabilities. Implement input validation and anomaly detection. \"\n                    \"Test system resilience through chaos engineering and stress testing. \"\n                    \"Define and implement graceful degradation strategies. Document \"\n                    \"resilience requirements and validate compliance during deployment.\"\n                ),\n                references=[\n                    \"MAS Technology Risk Management Guidelines\",\n                    \"MAS Business Continuity Management Guidelines\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"MAS-OPS-2\",\n                name=\"Incident Management for AI Failures\",\n                description=(\n                    \"Financial institutions must have incident management procedures \"\n                    \"specifically addressing AI system failures. This includes detection \"\n                    \"mechanisms, escalation procedures, impact assessment, root cause \"\n                    \"analysis, and communication protocols. AI-related incidents should \"\n                    \"be reported to MAS where required.\"\n                ),\n                severity=RiskLevel.HIGH,\n                category=\"operations\",\n                remediation=(\n                    \"Establish incident management procedures for AI systems. Define \"\n                    \"AI-specific incident categories and severity classifications. \"\n                    \"Implement monitoring and alerting for AI system failures. \"\n                    \"Document escalation procedures and communication protocols. \"\n                    \"Conduct post-incident reviews and implement lessons learned.\"\n                ),\n                references=[\n                    \"MAS Technology Risk Management Guidelines\",\n                    \"MAS Notice on Cyber Hygiene\",\n                    \"MAS Incident Reporting Requirements\",\n                ],\n            ),\n            ComplianceRule(\n                rule_id=\"MAS-OPS-3\",\n                name=\"Business Continuity for AI Systems\",\n                description=(\n                    \"Financial institutions must include AI systems in their business \"\n                    \"continuity planning. This includes identifying critical AI dependencies, \"\n                    \"establishing recovery procedures, defining backup and fallback options, \"\n                    \"and testing continuity plans. Business continuity plans should address \"\n                    \"scenarios where AI systems are unavailable.\"\n                ),\n                severity=RiskLevel.MEDIUM,\n                category=\"operations\",\n                remediation=(\n                    \"Include AI systems in business continuity planning and testing. \"\n                    \"Identify critical AI system dependencies and recovery requirements. \"\n                    \"Define fallback procedures for AI system unavailability (e.g., \"\n                    \"manual processing, simplified models). Test business continuity \"\n                    \"plans including AI failure scenarios. Document recovery time \"\n                    \"objectives and recovery point objectives for AI systems.\"\n                ),\n                references=[\n                    \"MAS Technology Risk Management Guidelines\",\n                    \"MAS Business Continuity Management Guidelines\",\n                ],\n            ),\n        ]\n\n    def _check_rule(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check a single MAS rule against an audit entry.\n\n        Evaluates the audit entry against the specific rule requirements\n        and returns a violation if the entry does not comply.\n\n        Args:\n            entry: The audit entry to check\n            rule: The rule to evaluate\n\n        Returns:\n            ComplianceViolation if the rule is violated, None otherwise\n        \"\"\"\n        # Use custom check function if provided\n        if rule.check_fn is not None:\n            is_compliant = rule.check_fn(entry)\n            if not is_compliant:\n                return self._create_violation(entry, rule, \"Custom check failed\")\n            return None\n\n        # Framework-specific rule checks\n        if rule.rule_id == \"MAS-FEAT-F1\":\n            return self._check_fair_decisions(entry, rule)\n        elif rule.rule_id == \"MAS-FEAT-F2\":\n            return self._check_bias_mitigation(entry, rule)\n        elif rule.rule_id == \"MAS-FEAT-E1\":\n            return self._check_ethical_data_use(entry, rule)\n        elif rule.rule_id == \"MAS-FEAT-E2\":\n            return self._check_ethical_alignment(entry, rule)\n        elif rule.rule_id == \"MAS-FEAT-A1\":\n            return self._check_accountability(entry, rule)\n        elif rule.rule_id == \"MAS-FEAT-A2\":\n            return self._check_human_oversight(entry, rule)\n        elif rule.rule_id == \"MAS-FEAT-T1\":\n            return self._check_explainability(entry, rule)\n        elif rule.rule_id == \"MAS-FEAT-T2\":\n            return self._check_customer_notification(entry, rule)\n        elif rule.rule_id == \"MAS-MRM-1\":\n            return self._check_development_standards(entry, rule)\n        elif rule.rule_id == \"MAS-MRM-2\":\n            return self._check_model_validation(entry, rule)\n        elif rule.rule_id == \"MAS-MRM-3\":\n            return self._check_model_monitoring(entry, rule)\n        elif rule.rule_id == \"MAS-MRM-4\":\n            return self._check_model_inventory(entry, rule)\n        elif rule.rule_id == \"MAS-DATA-1\":\n            return self._check_data_quality(entry, rule)\n        elif rule.rule_id == \"MAS-DATA-2\":\n            return self._check_data_lineage(entry, rule)\n        elif rule.rule_id == \"MAS-DATA-3\":\n            return self._check_data_privacy(entry, rule)\n        elif rule.rule_id == \"MAS-OPS-1\":\n            return self._check_system_resilience(entry, rule)\n        elif rule.rule_id == \"MAS-OPS-2\":\n            return self._check_incident_management(entry, rule)\n        elif rule.rule_id == \"MAS-OPS-3\":\n            return self._check_business_continuity(entry, rule)\n\n        return None\n\n    # ========================================================================\n    # FEAT Fairness Checks\n    # ========================================================================\n\n    def _check_fair_decisions(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check MAS-FEAT-F1: AI-driven decisions must be fair and unbiased.\n\n        Customer-impacting AI decisions should have fairness assessments documented.\n        \"\"\"\n        # Customer-impacting decision events\n        customer_decision_events = {\n            \"credit_decision\", \"underwriting\", \"pricing\", \"fraud_detection\",\n            \"risk_assessment\", \"loan_approval\", \"insurance_decision\",\n            \"customer_scoring\", \"eligibility_check\"\n        }\n        if entry.event_type.lower() not in customer_decision_events:\n            return None\n\n        has_fairness_assessment = entry.metadata.get(\"fairness_assessed\", False)\n        if not has_fairness_assessment:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Customer-impacting AI decision (type={entry.event_type}) performed \"\n                f\"without documented fairness assessment\",\n            )\n        return None\n\n    def _check_bias_mitigation(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check MAS-FEAT-F2: Bias detection and mitigation measures in place.\n\n        Model training and deployment should include bias mitigation documentation.\n        \"\"\"\n        model_lifecycle_events = {\n            \"training\", \"fine_tuning\", \"deployment\", \"model_update\",\n            \"model_release\", \"model_promotion\"\n        }\n        if entry.event_type.lower() not in model_lifecycle_events:\n            return None\n\n        has_bias_mitigation = entry.metadata.get(\"bias_mitigation_documented\", False)\n        if not has_bias_mitigation:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Model lifecycle event (type={entry.event_type}) performed \"\n                f\"without documented bias detection and mitigation measures\",\n            )\n        return None\n\n    # ========================================================================\n    # FEAT Ethics Checks\n    # ========================================================================\n\n    def _check_ethical_data_use(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check MAS-FEAT-E1: Ethical use of data and AI.\n\n        Data processing and AI operations should comply with ethical data use policies.\n        \"\"\"\n        data_use_events = {\n            \"data_ingestion\", \"data_processing\", \"feature_engineering\",\n            \"training\", \"data_access\", \"data_export\"\n        }\n        if entry.event_type.lower() not in data_use_events:\n            return None\n\n        has_ethics_review = entry.metadata.get(\"ethics_reviewed\", False)\n        if not has_ethics_review:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Data/AI operation (type={entry.event_type}) performed \"\n                f\"without documented ethical review\",\n            )\n        return None\n\n    def _check_ethical_alignment(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check MAS-FEAT-E2: AI aligns with firm's ethical standards.\n\n        AI deployments should document alignment with firm ethical standards.\n        \"\"\"\n        deployment_events = {\"deployment\", \"model_release\", \"go_live\", \"production_release\"}\n        if entry.event_type.lower() not in deployment_events:\n            return None\n\n        has_ethics_alignment = entry.metadata.get(\"ethics_aligned\", False)\n        if not has_ethics_alignment:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"AI deployment (type={entry.event_type}) performed \"\n                f\"without documented alignment with firm's ethical standards\",\n            )\n        return None\n\n    # ========================================================================\n    # FEAT Accountability Checks\n    # ========================================================================\n\n    def _check_accountability(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check MAS-FEAT-A1: Clear accountability for AI decisions.\n\n        AI operations should have documented accountability and ownership.\n        \"\"\"\n        # All material AI events should have accountability\n        material_events = {\n            \"inference\", \"prediction\", \"decision\", \"credit_decision\",\n            \"underwriting\", \"fraud_detection\", \"risk_assessment\",\n            \"deployment\", \"model_update\"\n        }\n        if entry.event_type.lower() not in material_events:\n            return None\n\n        has_accountability = (\n            entry.metadata.get(\"accountable_owner\", \"\") != \"\" or\n            entry.metadata.get(\"accountability_documented\", False)\n        )\n        if not has_accountability:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Material AI operation (type={entry.event_type}) performed \"\n                f\"without documented accountability structure\",\n            )\n        return None\n\n    def _check_human_oversight(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check MAS-FEAT-A2: Human oversight for material AI decisions.\n\n        High-risk and material AI decisions require human oversight.\n        \"\"\"\n        # Only applies to high-risk and critical operations\n        if entry.risk_level not in (RiskLevel.HIGH, RiskLevel.CRITICAL):\n            return None\n\n        if not entry.human_oversight:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Material AI operation (level={entry.risk_level.value}, \"\n                f\"type={entry.event_type}) performed without human oversight\",\n            )\n        return None\n\n    # ========================================================================\n    # FEAT Transparency Checks\n    # ========================================================================\n\n    def _check_explainability(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check MAS-FEAT-T1: AI decisions are explainable.\n\n        Customer-impacting decisions should have explanations available.\n        \"\"\"\n        decision_events = {\n            \"inference\", \"prediction\", \"decision\", \"credit_decision\",\n            \"underwriting\", \"pricing\", \"fraud_detection\", \"risk_assessment\"\n        }\n        if entry.event_type.lower() not in decision_events:\n            return None\n\n        has_explanation = (\n            entry.metadata.get(\"explanation_available\", False) or\n            entry.metadata.get(\"explainability_method\", \"\") != \"\"\n        )\n        if not has_explanation:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"AI decision (type={entry.event_type}) performed \"\n                f\"without explainability mechanism documented\",\n            )\n        return None\n\n    def _check_customer_notification(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check MAS-FEAT-T2: Customers informed of AI use.\n\n        Customer-facing AI interactions should include notification of AI involvement.\n        \"\"\"\n        customer_facing_events = {\n            \"inference\", \"chat\", \"interaction\", \"response\", \"recommendation\",\n            \"credit_decision\", \"underwriting\", \"customer_service\"\n        }\n        if entry.event_type.lower() not in customer_facing_events:\n            return None\n\n        if not entry.user_notified:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Customer-facing AI operation (type={entry.event_type}) performed \"\n                f\"without notifying customer of AI involvement\",\n            )\n        return None\n\n    # ========================================================================\n    # Model Risk Management Checks\n    # ========================================================================\n\n    def _check_development_standards(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check MAS-MRM-1: Model development standards.\n\n        Model development activities should follow documented standards.\n        \"\"\"\n        development_events = {\n            \"training\", \"fine_tuning\", \"model_development\", \"feature_engineering\",\n            \"model_selection\"\n        }\n        if entry.event_type.lower() not in development_events:\n            return None\n\n        has_development_standards = (\n            entry.metadata.get(\"development_standards_followed\", False) or\n            entry.documentation_ref is not None\n        )\n        if not has_development_standards:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Model development activity (type={entry.event_type}) performed \"\n                f\"without reference to development standards documentation\",\n            )\n        return None\n\n    def _check_model_validation(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check MAS-MRM-2: Model validation requirements.\n\n        Model deployments should have validation documentation.\n        \"\"\"\n        deployment_events = {\"deployment\", \"model_release\", \"go_live\", \"production_release\"}\n        if entry.event_type.lower() not in deployment_events:\n            return None\n\n        has_validation = entry.metadata.get(\"validation_completed\", False)\n        if not has_validation:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Model deployment (type={entry.event_type}) performed \"\n                f\"without documented model validation\",\n            )\n        return None\n\n    def _check_model_monitoring(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check MAS-MRM-3: Model monitoring and review.\n\n        Inference operations should have monitoring in place.\n        \"\"\"\n        inference_events = {\"inference\", \"prediction\", \"scoring\", \"decision\"}\n        if entry.event_type.lower() not in inference_events:\n            return None\n\n        has_monitoring = (\n            entry.metadata.get(\"monitoring_enabled\", False) or\n            entry.metadata.get(\"performance_tracked\", False)\n        )\n        if not has_monitoring:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Model inference (type={entry.event_type}) performed \"\n                f\"without documented monitoring configuration\",\n            )\n        return None\n\n    def _check_model_inventory(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check MAS-MRM-4: Model inventory maintained.\n\n        Model operations should reference the model inventory.\n        \"\"\"\n        model_events = {\n            \"deployment\", \"inference\", \"training\", \"model_update\",\n            \"model_release\", \"model_retirement\"\n        }\n        if entry.event_type.lower() not in model_events:\n            return None\n\n        has_inventory_ref = (\n            entry.metadata.get(\"model_inventory_id\", \"\") != \"\" or\n            entry.metadata.get(\"model_registered\", False)\n        )\n        if not has_inventory_ref:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Model operation (type={entry.event_type}) performed \"\n                f\"without reference to model inventory\",\n            )\n        return None\n\n    # ========================================================================\n    # Data Governance Checks\n    # ========================================================================\n\n    def _check_data_quality(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check MAS-DATA-1: Data quality standards.\n\n        Data operations should meet data quality standards.\n        \"\"\"\n        data_events = {\n            \"data_ingestion\", \"data_processing\", \"training\", \"fine_tuning\",\n            \"feature_engineering\", \"data_preparation\"\n        }\n        if entry.event_type.lower() not in data_events:\n            return None\n\n        has_quality_check = entry.metadata.get(\"data_quality_validated\", False)\n        if not has_quality_check:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Data operation (type={entry.event_type}) performed \"\n                f\"without documented data quality validation\",\n            )\n        return None\n\n    def _check_data_lineage(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check MAS-DATA-2: Data lineage documented.\n\n        Data transformations should have lineage documentation.\n        \"\"\"\n        data_transformation_events = {\n            \"data_processing\", \"feature_engineering\", \"data_transformation\",\n            \"data_aggregation\", \"data_preparation\"\n        }\n        if entry.event_type.lower() not in data_transformation_events:\n            return None\n\n        has_lineage = (\n            entry.metadata.get(\"lineage_documented\", False) or\n            entry.metadata.get(\"data_lineage_id\", \"\") != \"\"\n        )\n        if not has_lineage:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Data transformation (type={entry.event_type}) performed \"\n                f\"without documented data lineage\",\n            )\n        return None\n\n    def _check_data_privacy(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check MAS-DATA-3: Data privacy compliance.\n\n        Operations involving personal data should comply with privacy requirements.\n        \"\"\"\n        # Check if personal data is involved\n        personal_data_classifications = {\"pii\", \"personal\", \"customer_data\", \"sensitive\"}\n        if entry.data_classification.lower() not in personal_data_classifications:\n            return None\n\n        has_privacy_compliance = (\n            entry.metadata.get(\"privacy_compliant\", False) or\n            entry.metadata.get(\"consent_obtained\", False)\n        )\n        if not has_privacy_compliance:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Operation involving personal data (classification={entry.data_classification}) \"\n                f\"performed without documented privacy compliance\",\n            )\n        return None\n\n    # ========================================================================\n    # Operational Resilience Checks\n    # ========================================================================\n\n    def _check_system_resilience(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check MAS-OPS-1: AI system resilience.\n\n        AI systems should demonstrate resilience measures.\n        \"\"\"\n        # Check for error handling on all operations\n        if not entry.error_handled:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"AI operation (type={entry.event_type}) indicates error was not \"\n                f\"handled gracefully, suggesting resilience gap\",\n            )\n        return None\n\n    def _check_incident_management(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check MAS-OPS-2: Incident management for AI failures.\n\n        Error events should trigger incident management procedures.\n        \"\"\"\n        error_events = {\"error\", \"failure\", \"exception\", \"timeout\", \"degradation\"}\n        if entry.event_type.lower() not in error_events:\n            return None\n\n        has_incident_management = (\n            entry.metadata.get(\"incident_logged\", False) or\n            entry.metadata.get(\"incident_id\", \"\") != \"\"\n        )\n        if not has_incident_management:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"AI error event (type={entry.event_type}) occurred \"\n                f\"without documented incident management response\",\n            )\n        return None\n\n    def _check_business_continuity(\n        self, entry: AuditEntry, rule: ComplianceRule\n    ) -&gt; Optional[ComplianceViolation]:\n        \"\"\"\n        Check MAS-OPS-3: Business continuity for AI systems.\n\n        Critical AI operations should have business continuity documentation.\n        \"\"\"\n        # Only check critical operations\n        if entry.risk_level != RiskLevel.CRITICAL:\n            return None\n\n        has_bcp = (\n            entry.metadata.get(\"bcp_documented\", False) or\n            entry.metadata.get(\"fallback_available\", False)\n        )\n        if not has_bcp:\n            return self._create_violation(\n                entry,\n                rule,\n                f\"Critical AI operation (type={entry.event_type}) performed \"\n                f\"without documented business continuity provisions\",\n            )\n        return None\n\n    # ========================================================================\n    # Helper Methods\n    # ========================================================================\n\n    def _create_violation(\n        self, entry: AuditEntry, rule: ComplianceRule, evidence: str\n    ) -&gt; ComplianceViolation:\n        \"\"\"\n        Create a compliance violation object.\n\n        Args:\n            entry: The audit entry that triggered the violation\n            rule: The rule that was violated\n            evidence: Specific evidence describing the violation\n\n        Returns:\n            ComplianceViolation object\n        \"\"\"\n        return ComplianceViolation(\n            rule_id=rule.rule_id,\n            rule_name=rule.name,\n            severity=rule.severity,\n            description=rule.description,\n            evidence=evidence,\n            remediation=rule.remediation,\n            entry_id=entry.entry_id,\n            category=rule.category,\n            framework=self._name,\n        )\n</code></pre>"},{"location":"api/frameworks/#rotalabs_comply.frameworks.mas.MASFramework.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> <p>Initialize the MAS framework with all defined rules.</p> Source code in <code>src/rotalabs_comply/frameworks/mas.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize the MAS framework with all defined rules.\"\"\"\n    rules = self._create_rules()\n    super().__init__(name=\"MAS FEAT\", version=\"2022\", rules=rules)\n</code></pre>"},{"location":"api/frameworks/#categories_6","title":"Categories","text":"Category Focus Description <code>fairness</code> FEAT-F Ensuring AI decisions are fair and unbiased <code>ethics</code> FEAT-E Ethical use of data and AI alignment with firm standards <code>accountability</code> FEAT-A Clear accountability and human oversight <code>transparency</code> FEAT-T Explainability and customer notification <code>model_risk</code> MRM Model development, validation, and monitoring <code>data_governance</code> Data Data quality, lineage, and privacy compliance <code>operations</code> Ops System resilience and incident management"},{"location":"api/frameworks/#rules_6","title":"Rules","text":"Rule ID Name Category Severity <code>MAS-FEAT-F1</code> Fair AI-Driven Decisions fairness HIGH <code>MAS-FEAT-F2</code> Bias Detection and Mitigation fairness HIGH <code>MAS-FEAT-E1</code> Ethical Use of Data and AI ethics HIGH <code>MAS-FEAT-E2</code> AI Alignment with Firm's Ethical Standards ethics MEDIUM <code>MAS-FEAT-A1</code> Clear Accountability for AI Decisions accountability HIGH <code>MAS-FEAT-A2</code> Human Oversight for Material AI Decisions accountability CRITICAL <code>MAS-FEAT-T1</code> Explainable AI Decisions transparency HIGH <code>MAS-FEAT-T2</code> Customer Notification of AI Use transparency HIGH <code>MAS-MRM-1</code> Model Development Standards model_risk HIGH <code>MAS-MRM-2</code> Model Validation Requirements model_risk HIGH <code>MAS-MRM-3</code> Model Monitoring and Review model_risk HIGH <code>MAS-MRM-4</code> Model Inventory Maintained model_risk MEDIUM <code>MAS-DATA-1</code> Data Quality Standards data_governance HIGH <code>MAS-DATA-2</code> Data Lineage Documentation data_governance MEDIUM <code>MAS-DATA-3</code> Data Privacy Compliance data_governance CRITICAL <code>MAS-OPS-1</code> AI System Resilience operations HIGH <code>MAS-OPS-2</code> Incident Management for AI Failures operations HIGH <code>MAS-OPS-3</code> Business Continuity for AI Systems operations MEDIUM"},{"location":"api/frameworks/#usage_6","title":"Usage","text":"<pre><code>from rotalabs_comply.frameworks.mas import MASFramework\nfrom rotalabs_comply.frameworks.base import AuditEntry, ComplianceProfile, RiskLevel\nfrom datetime import datetime\n\nframework = MASFramework()\n\nentry = AuditEntry(\n    entry_id=\"mas-001\",\n    timestamp=datetime.utcnow(),\n    event_type=\"credit_decision\",\n    actor=\"credit-officer@bank.sg\",\n    action=\"AI credit scoring\",\n    risk_level=RiskLevel.HIGH,\n    data_classification=\"customer_data\",\n    user_notified=True,\n    human_oversight=True,\n    error_handled=True,\n    metadata={\n        \"fairness_assessed\": True,\n        \"bias_mitigation_documented\": True,\n        \"accountable_owner\": \"credit-risk-team\",\n        \"explanation_available\": True,\n        \"monitoring_enabled\": True,\n        \"model_inventory_id\": \"MODEL-CS-001\",\n        \"privacy_compliant\": True,\n    },\n)\n\nprofile = ComplianceProfile(\n    profile_id=\"mas-profile\",\n    name=\"MAS FEAT Compliance\",\n)\n\nresult = await framework.check(entry, profile)\n</code></pre>"},{"location":"api/frameworks/#key-requirements_6","title":"Key Requirements","text":"<p>Customer-facing AI decisions require: - <code>metadata[\"fairness_assessed\"]=True</code> - <code>metadata[\"explanation_available\"]=True</code> or <code>metadata[\"explainability_method\"]</code> set - <code>user_notified=True</code></p> <p>High-risk operations require: - <code>human_oversight=True</code></p> <p>Model lifecycle events require: - <code>metadata[\"bias_mitigation_documented\"]=True</code> - <code>metadata[\"validation_completed\"]=True</code> (for deployments) - <code>metadata[\"model_inventory_id\"]</code> or <code>metadata[\"model_registered\"]=True</code></p> <p>Personal data operations require: - <code>data_classification</code> set to \"pii\", \"personal\", \"customer_data\", or \"sensitive\" - <code>metadata[\"privacy_compliant\"]=True</code> or <code>metadata[\"consent_obtained\"]=True</code></p> <p>All operations require: - <code>error_handled=True</code> (for resilience)</p>"},{"location":"api/reports/","title":"Reports Module","text":"<p>Report generation and templates for compliance reporting.</p>"},{"location":"api/reports/#reportgenerator","title":"ReportGenerator","text":"<p>Generator for compliance reports from audit data.</p>"},{"location":"api/reports/#rotalabs_comply.reports.generator.ReportGenerator","title":"ReportGenerator","text":"<p>Generator for compliance reports from audit data.</p> <p>ReportGenerator retrieves audit entries from storage, runs compliance checks against configured frameworks, and produces comprehensive reports.</p> <p>Attributes:</p> Name Type Description <code>storage</code> <p>Storage backend for retrieving audit entries.</p> <code>frameworks</code> <p>Dictionary mapping framework names to implementations.</p> Example <p>from rotalabs_comply.audit.storage import MemoryStorage from rotalabs_comply.frameworks.eu_ai_act import EUAIActFramework</p> <p>storage = MemoryStorage() frameworks = { ...     \"eu_ai_act\": EUAIActFramework(), ... } generator = ReportGenerator(storage, frameworks)</p> Source code in <code>src/rotalabs_comply/reports/generator.py</code> <pre><code>class ReportGenerator:\n    \"\"\"\n    Generator for compliance reports from audit data.\n\n    ReportGenerator retrieves audit entries from storage, runs compliance\n    checks against configured frameworks, and produces comprehensive reports.\n\n    Attributes:\n        storage: Storage backend for retrieving audit entries.\n        frameworks: Dictionary mapping framework names to implementations.\n\n    Example:\n        &gt;&gt;&gt; from rotalabs_comply.audit.storage import MemoryStorage\n        &gt;&gt;&gt; from rotalabs_comply.frameworks.eu_ai_act import EUAIActFramework\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; storage = MemoryStorage()\n        &gt;&gt;&gt; frameworks = {\n        ...     \"eu_ai_act\": EUAIActFramework(),\n        ... }\n        &gt;&gt;&gt; generator = ReportGenerator(storage, frameworks)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Generate a report\n        &gt;&gt;&gt; report = await generator.generate(\n        ...     period_start=datetime(2026, 1, 1),\n        ...     period_end=datetime(2026, 1, 31),\n        ...     profile=profile,\n        ...     framework=\"eu_ai_act\",\n        ... )\n    \"\"\"\n\n    def __init__(\n        self,\n        audit_logger: StorageProtocol,\n        frameworks: Optional[Dict[FrameworkName, ComplianceFramework]] = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize the report generator.\n\n        Args:\n            audit_logger: Storage backend implementing list_entries method.\n            frameworks: Optional dict mapping framework names to implementations.\n                If not provided, compliance checks will be skipped.\n\n        Example:\n            &gt;&gt;&gt; generator = ReportGenerator(storage)\n            &gt;&gt;&gt; generator = ReportGenerator(storage, {\"soc2\": SOC2Framework()})\n        \"\"\"\n        self.storage = audit_logger\n        self.frameworks = frameworks or {}\n\n    async def generate(\n        self,\n        period_start: datetime,\n        period_end: datetime,\n        profile: ComplianceProfile,\n        framework: Optional[FrameworkName] = None,\n        format: Literal[\"markdown\", \"json\", \"html\"] = \"markdown\",\n    ) -&gt; ComplianceReport:\n        \"\"\"\n        Generate a comprehensive compliance report.\n\n        Retrieves audit entries for the specified period, runs compliance\n        checks, and generates a full report with all standard sections.\n\n        Args:\n            period_start: Start of the analysis period (inclusive).\n            period_end: End of the analysis period (inclusive).\n            profile: ComplianceProfile defining evaluation parameters.\n            framework: Specific framework to report on (None = all in profile).\n            format: Output format hint (used for template selection).\n\n        Returns:\n            ComplianceReport with all sections populated.\n\n        Example:\n            &gt;&gt;&gt; report = await generator.generate(\n            ...     period_start=datetime(2026, 1, 1),\n            ...     period_end=datetime(2026, 1, 31),\n            ...     profile=profile,\n            ...     format=\"markdown\",\n            ... )\n            &gt;&gt;&gt; print(f\"Generated: {report.title}\")\n            &gt;&gt;&gt; print(f\"Entries: {report.total_entries}\")\n            &gt;&gt;&gt; print(f\"Score: {report.compliance_score:.2%}\")\n        \"\"\"\n        # Retrieve audit entries\n        entries = await self.storage.list_entries(period_start, period_end)\n        total_entries = len(entries)\n\n        # Determine which frameworks to evaluate\n        frameworks_to_check = []\n        if framework:\n            frameworks_to_check = [framework]\n        elif profile.enabled_frameworks:\n            frameworks_to_check = profile.enabled_frameworks\n        else:\n            frameworks_to_check = list(self.frameworks.keys())\n\n        # Run compliance checks\n        all_results: List[ComplianceCheckResult] = []\n        all_violations: List[ComplianceViolation] = []\n\n        for fw_name in frameworks_to_check:\n            if fw_name in self.frameworks:\n                fw_impl = self.frameworks[fw_name]\n                for entry in entries:\n                    # Convert storage entry to AuditEntry if needed\n                    audit_entry = self._convert_to_audit_entry(entry)\n                    result = await fw_impl.check(audit_entry, profile)\n                    all_results.append(result)\n                    all_violations.extend(result.violations)\n\n        # Calculate compliance metrics\n        total_checks = sum(r.rules_checked for r in all_results)\n        violations_count = len(all_violations)\n        critical_violations = sum(\n            1 for v in all_violations\n            if (v.severity.value if hasattr(v.severity, \"value\") else str(v.severity)).lower() == \"critical\"\n        )\n        high_violations = sum(\n            1 for v in all_violations\n            if (v.severity.value if hasattr(v.severity, \"value\") else str(v.severity)).lower() == \"high\"\n        )\n\n        compliance_score = self._calculate_compliance_score(all_violations, total_checks)\n        status = self._determine_status(compliance_score, critical_violations)\n\n        # Prepare statistics for section generators\n        stats = {\n            \"total_entries\": total_entries,\n            \"violations_count\": violations_count,\n            \"compliance_rate\": compliance_score * 100,\n            \"critical_violations\": critical_violations,\n            \"high_violations\": high_violations,\n            \"period_start\": period_start.strftime(\"%Y-%m-%d\"),\n            \"period_end\": period_end.strftime(\"%Y-%m-%d\"),\n            \"frameworks\": frameworks_to_check,\n        }\n\n        # Generate sections\n        sections = [\n            generate_executive_summary(stats),\n            generate_risk_assessment(all_violations),\n            generate_compliance_matrix(all_results),\n            generate_metrics_summary(entries),\n            generate_recommendations(all_violations),\n            generate_audit_summary(\n                entries,\n                f\"{period_start.strftime('%Y-%m-%d')} to {period_end.strftime('%Y-%m-%d')}\",\n            ),\n        ]\n\n        # Select template based on framework\n        if framework == \"eu_ai_act\":\n            template = EU_AI_ACT_TEMPLATE\n        elif framework == \"soc2\":\n            template = SOC2_TEMPLATE\n        elif framework == \"hipaa\":\n            template = HIPAA_TEMPLATE\n        else:\n            template = EXECUTIVE_SUMMARY_TEMPLATE\n\n        title = template.title if framework else f\"Compliance Report - {profile.name}\"\n\n        return ComplianceReport(\n            id=str(uuid.uuid4()),\n            title=title,\n            framework=framework,\n            period_start=period_start,\n            period_end=period_end,\n            generated_at=datetime.utcnow(),\n            profile=profile,\n            summary=stats,\n            sections=sections,\n            total_entries=total_entries,\n            violations_count=violations_count,\n            compliance_score=compliance_score,\n            status=status,\n        )\n\n    async def generate_executive_summary(\n        self,\n        period_start: datetime,\n        period_end: datetime,\n        profile: ComplianceProfile,\n    ) -&gt; ComplianceReport:\n        \"\"\"\n        Generate a high-level executive summary report.\n\n        Creates a condensed report suitable for executive audiences,\n        focusing on key metrics and critical findings without technical details.\n\n        Args:\n            period_start: Start of the analysis period.\n            period_end: End of the analysis period.\n            profile: ComplianceProfile defining evaluation parameters.\n\n        Returns:\n            ComplianceReport with executive-focused sections.\n\n        Example:\n            &gt;&gt;&gt; report = await generator.generate_executive_summary(\n            ...     period_start=datetime(2026, 1, 1),\n            ...     period_end=datetime(2026, 3, 31),\n            ...     profile=profile,\n            ... )\n            &gt;&gt;&gt; print(f\"Status: {report.status}\")\n            &gt;&gt;&gt; print(f\"Score: {report.compliance_score:.2%}\")\n        \"\"\"\n        # Retrieve audit entries\n        entries = await self.storage.list_entries(period_start, period_end)\n        total_entries = len(entries)\n\n        # Run compliance checks for all frameworks in profile\n        frameworks_to_check = profile.enabled_frameworks or list(self.frameworks.keys())\n        all_violations: List[ComplianceViolation] = []\n        all_results: List[ComplianceCheckResult] = []\n\n        for fw_name in frameworks_to_check:\n            if fw_name in self.frameworks:\n                fw_impl = self.frameworks[fw_name]\n                for entry in entries:\n                    audit_entry = self._convert_to_audit_entry(entry)\n                    result = await fw_impl.check(audit_entry, profile)\n                    all_results.append(result)\n                    all_violations.extend(result.violations)\n\n        # Calculate metrics\n        total_checks = sum(r.rules_checked for r in all_results)\n        violations_count = len(all_violations)\n        critical_violations = sum(\n            1 for v in all_violations\n            if (v.severity.value if hasattr(v.severity, \"value\") else str(v.severity)).lower() == \"critical\"\n        )\n        high_violations = sum(\n            1 for v in all_violations\n            if (v.severity.value if hasattr(v.severity, \"value\") else str(v.severity)).lower() == \"high\"\n        )\n\n        compliance_score = self._calculate_compliance_score(all_violations, total_checks)\n        status = self._determine_status(compliance_score, critical_violations)\n\n        # Prepare statistics\n        stats = {\n            \"total_entries\": total_entries,\n            \"violations_count\": violations_count,\n            \"compliance_rate\": compliance_score * 100,\n            \"critical_violations\": critical_violations,\n            \"high_violations\": high_violations,\n            \"period_start\": period_start.strftime(\"%Y-%m-%d\"),\n            \"period_end\": period_end.strftime(\"%Y-%m-%d\"),\n            \"frameworks\": frameworks_to_check,\n        }\n\n        # Generate executive-focused sections only\n        sections = [\n            generate_executive_summary(stats),\n            generate_risk_assessment(all_violations),\n            generate_recommendations(all_violations),\n        ]\n\n        return ComplianceReport(\n            id=str(uuid.uuid4()),\n            title=f\"Executive Summary - {profile.name}\",\n            framework=None,\n            period_start=period_start,\n            period_end=period_end,\n            generated_at=datetime.utcnow(),\n            profile=profile,\n            summary=stats,\n            sections=sections,\n            total_entries=total_entries,\n            violations_count=violations_count,\n            compliance_score=compliance_score,\n            status=status,\n        )\n\n    def _calculate_compliance_score(\n        self,\n        violations: List[ComplianceViolation],\n        total_checks: int,\n    ) -&gt; float:\n        \"\"\"\n        Calculate overall compliance score from violations.\n\n        Uses a weighted scoring system where higher-severity violations\n        have a greater impact on the score.\n\n        Args:\n            violations: List of compliance violations.\n            total_checks: Total number of compliance checks performed.\n\n        Returns:\n            Compliance score from 0.0 (worst) to 1.0 (best).\n\n        Example:\n            &gt;&gt;&gt; score = generator._calculate_compliance_score(violations, 100)\n            &gt;&gt;&gt; print(f\"{score:.2%}\")\n            95.00%\n        \"\"\"\n        if total_checks == 0:\n            return 1.0  # No checks = assume compliant\n\n        if not violations:\n            return 1.0  # No violations = fully compliant\n\n        # Weighted penalty per violation by severity\n        severity_weights = {\n            \"critical\": 10.0,\n            \"high\": 5.0,\n            \"medium\": 2.0,\n            \"low\": 1.0,\n            \"info\": 0.5,\n        }\n\n        total_penalty = 0.0\n        for v in violations:\n            severity = (\n                v.severity.value if hasattr(v.severity, \"value\") else str(v.severity)\n            ).lower()\n            weight = severity_weights.get(severity, 1.0)\n            total_penalty += weight\n\n        # Calculate score (penalty capped at total checks)\n        max_penalty = total_checks * 10.0  # Max if all were critical\n        penalty_ratio = min(total_penalty / max_penalty, 1.0)\n        score = 1.0 - penalty_ratio\n\n        return max(0.0, min(1.0, score))\n\n    def _determine_status(\n        self,\n        score: float,\n        critical_violations: int,\n    ) -&gt; Literal[\"compliant\", \"non_compliant\", \"needs_review\"]:\n        \"\"\"\n        Determine overall compliance status from score and violations.\n\n        Args:\n            score: Compliance score (0.0 to 1.0).\n            critical_violations: Number of critical-severity violations.\n\n        Returns:\n            Status string: \"compliant\", \"non_compliant\", or \"needs_review\".\n\n        Example:\n            &gt;&gt;&gt; status = generator._determine_status(0.95, 0)\n            &gt;&gt;&gt; print(status)\n            'compliant'\n        \"\"\"\n        if critical_violations &gt; 0:\n            return \"non_compliant\"\n        if score &gt;= 0.95:\n            return \"compliant\"\n        if score &gt;= 0.80:\n            return \"needs_review\"\n        return \"non_compliant\"\n\n    def _convert_to_audit_entry(self, entry: Any) -&gt; AuditEntry:\n        \"\"\"\n        Convert a storage entry to the AuditEntry type expected by frameworks.\n\n        Handles both dictionary entries and dataclass/object entries.\n\n        Args:\n            entry: Entry from storage (dict or object).\n\n        Returns:\n            AuditEntry instance.\n        \"\"\"\n        if isinstance(entry, AuditEntry):\n            return entry\n\n        if isinstance(entry, dict):\n            return AuditEntry(\n                entry_id=entry.get(\"id\", str(uuid.uuid4())),\n                timestamp=datetime.fromisoformat(entry[\"timestamp\"])\n                if isinstance(entry.get(\"timestamp\"), str)\n                else entry.get(\"timestamp\", datetime.utcnow()),\n                event_type=entry.get(\"event_type\", \"unknown\"),\n                actor=entry.get(\"actor\", entry.get(\"provider\", \"unknown\")),\n                action=entry.get(\"action\", \"AI interaction\"),\n                resource=entry.get(\"resource\", \"\"),\n                metadata=entry.get(\"metadata\", {}),\n                risk_level=RiskLevel.LOW,\n                system_id=entry.get(\"system_id\", \"\"),\n                data_classification=entry.get(\"data_classification\", \"unclassified\"),\n                user_notified=entry.get(\"user_notified\", False),\n                human_oversight=entry.get(\"human_oversight\", False),\n                error_handled=entry.get(\"error_handled\", True),\n                documentation_ref=entry.get(\"documentation_ref\"),\n            )\n\n        # Handle dataclass or object\n        return AuditEntry(\n            entry_id=getattr(entry, \"id\", str(uuid.uuid4())),\n            timestamp=getattr(entry, \"timestamp\", datetime.utcnow())\n            if isinstance(getattr(entry, \"timestamp\", None), datetime)\n            else datetime.fromisoformat(getattr(entry, \"timestamp\", datetime.utcnow().isoformat())),\n            event_type=getattr(entry, \"event_type\", \"unknown\"),\n            actor=getattr(entry, \"actor\", getattr(entry, \"provider\", \"unknown\")) or \"unknown\",\n            action=getattr(entry, \"action\", \"AI interaction\"),\n            resource=getattr(entry, \"resource\", \"\"),\n            metadata=getattr(entry, \"metadata\", {}),\n            risk_level=RiskLevel.LOW,\n            system_id=getattr(entry, \"system_id\", \"\"),\n            data_classification=getattr(entry, \"data_classification\", \"unclassified\"),\n            user_notified=getattr(entry, \"user_notified\", False),\n            human_oversight=getattr(entry, \"human_oversight\", False),\n            error_handled=getattr(entry, \"error_handled\", True),\n            documentation_ref=getattr(entry, \"documentation_ref\", None),\n        )\n\n    def export_markdown(self, report: ComplianceReport) -&gt; str:\n        \"\"\"\n        Export report to Markdown format.\n\n        Creates a well-formatted Markdown document with proper headings,\n        tables, and structure suitable for documentation or rendering.\n\n        Args:\n            report: ComplianceReport to export.\n\n        Returns:\n            Markdown formatted string.\n\n        Example:\n            &gt;&gt;&gt; md = generator.export_markdown(report)\n            &gt;&gt;&gt; with open(\"report.md\", \"w\") as f:\n            ...     f.write(md)\n        \"\"\"\n        lines = [\n            f\"# {report.title}\",\n            \"\",\n            f\"**Report ID:** {report.id}\",\n            f\"**Generated:** {report.generated_at.strftime('%Y-%m-%d %H:%M:%S UTC')}\",\n            f\"**Period:** {report.period_start.strftime('%Y-%m-%d')} to {report.period_end.strftime('%Y-%m-%d')}\",\n            f\"**Framework:** {report.framework or 'Multiple'}\",\n            f\"**Profile:** {report.profile.name}\",\n            \"\",\n            \"---\",\n            \"\",\n            f\"**Compliance Score:** {report.compliance_score:.2%}\",\n            f\"**Status:** {report.status.upper().replace('_', ' ')}\",\n            f\"**Total Entries:** {report.total_entries:,}\",\n            f\"**Violations:** {report.violations_count:,}\",\n            \"\",\n            \"---\",\n            \"\",\n        ]\n\n        # Add each section\n        for section in report.sections:\n            lines.append(section.to_markdown(level=2))\n            lines.append(\"\")\n\n        # Footer\n        lines.extend([\n            \"---\",\n            \"\",\n            \"*This report was generated by rotalabs-comply.*\",\n        ])\n\n        return \"\\n\".join(lines)\n\n    def export_json(self, report: ComplianceReport) -&gt; str:\n        \"\"\"\n        Export report to JSON format.\n\n        Creates a JSON document with all report data, suitable for\n        programmatic processing or API responses.\n\n        Args:\n            report: ComplianceReport to export.\n\n        Returns:\n            JSON formatted string (pretty-printed).\n\n        Example:\n            &gt;&gt;&gt; json_str = generator.export_json(report)\n            &gt;&gt;&gt; data = json.loads(json_str)\n            &gt;&gt;&gt; print(data[\"compliance_score\"])\n        \"\"\"\n        return json.dumps(\n            report.to_dict(),\n            indent=2,\n            default=self._json_serializer,\n        )\n\n    def export_html(self, report: ComplianceReport) -&gt; str:\n        \"\"\"\n        Export report to HTML format.\n\n        Creates a standalone HTML document with embedded styles,\n        suitable for viewing in a browser or embedding in web applications.\n\n        Args:\n            report: ComplianceReport to export.\n\n        Returns:\n            HTML formatted string.\n\n        Example:\n            &gt;&gt;&gt; html = generator.export_html(report)\n            &gt;&gt;&gt; with open(\"report.html\", \"w\") as f:\n            ...     f.write(html)\n        \"\"\"\n        # Determine status color\n        status_colors = {\n            \"compliant\": \"#28a745\",\n            \"needs_review\": \"#ffc107\",\n            \"non_compliant\": \"#dc3545\",\n        }\n        status_color = status_colors.get(report.status, \"#6c757d\")\n\n        # Convert sections to HTML\n        sections_html = []\n        for section in report.sections:\n            section_html = self._section_to_html(section)\n            sections_html.append(section_html)\n\n        html_content = f\"\"\"&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n    &lt;title&gt;{html.escape(report.title)}&lt;/title&gt;\n    &lt;style&gt;\n        body {{\n            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;\n            line-height: 1.6;\n            max-width: 1200px;\n            margin: 0 auto;\n            padding: 20px;\n            color: #333;\n        }}\n        h1 {{\n            color: #2c3e50;\n            border-bottom: 3px solid #3498db;\n            padding-bottom: 10px;\n        }}\n        h2 {{\n            color: #34495e;\n            border-bottom: 1px solid #bdc3c7;\n            padding-bottom: 5px;\n            margin-top: 30px;\n        }}\n        h3 {{\n            color: #7f8c8d;\n        }}\n        .metadata {{\n            background: #f8f9fa;\n            padding: 15px;\n            border-radius: 5px;\n            margin-bottom: 20px;\n        }}\n        .metadata p {{\n            margin: 5px 0;\n        }}\n        .status-badge {{\n            display: inline-block;\n            padding: 5px 15px;\n            border-radius: 20px;\n            color: white;\n            font-weight: bold;\n            background-color: {status_color};\n        }}\n        .score {{\n            font-size: 2em;\n            font-weight: bold;\n            color: {status_color};\n        }}\n        table {{\n            border-collapse: collapse;\n            width: 100%;\n            margin: 15px 0;\n        }}\n        th, td {{\n            border: 1px solid #ddd;\n            padding: 10px;\n            text-align: left;\n        }}\n        th {{\n            background-color: #f2f2f2;\n        }}\n        tr:nth-child(even) {{\n            background-color: #f9f9f9;\n        }}\n        .section {{\n            margin-bottom: 30px;\n            padding: 20px;\n            background: white;\n            border: 1px solid #e1e4e8;\n            border-radius: 5px;\n        }}\n        .footer {{\n            margin-top: 40px;\n            padding-top: 20px;\n            border-top: 1px solid #e1e4e8;\n            text-align: center;\n            color: #6c757d;\n            font-size: 0.9em;\n        }}\n    &lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;{html.escape(report.title)}&lt;/h1&gt;\n\n    &lt;div class=\"metadata\"&gt;\n        &lt;p&gt;&lt;strong&gt;Report ID:&lt;/strong&gt; {html.escape(report.id)}&lt;/p&gt;\n        &lt;p&gt;&lt;strong&gt;Generated:&lt;/strong&gt; {report.generated_at.strftime('%Y-%m-%d %H:%M:%S UTC')}&lt;/p&gt;\n        &lt;p&gt;&lt;strong&gt;Period:&lt;/strong&gt; {report.period_start.strftime('%Y-%m-%d')} to {report.period_end.strftime('%Y-%m-%d')}&lt;/p&gt;\n        &lt;p&gt;&lt;strong&gt;Framework:&lt;/strong&gt; {html.escape(report.framework or 'Multiple')}&lt;/p&gt;\n        &lt;p&gt;&lt;strong&gt;Profile:&lt;/strong&gt; {html.escape(report.profile.name)}&lt;/p&gt;\n    &lt;/div&gt;\n\n    &lt;div class=\"metadata\" style=\"text-align: center;\"&gt;\n        &lt;p&gt;&lt;span class=\"score\"&gt;{report.compliance_score:.1%}&lt;/span&gt;&lt;/p&gt;\n        &lt;p&gt;&lt;span class=\"status-badge\"&gt;{report.status.upper().replace('_', ' ')}&lt;/span&gt;&lt;/p&gt;\n        &lt;p style=\"margin-top: 15px;\"&gt;\n            &lt;strong&gt;Entries Analyzed:&lt;/strong&gt; {report.total_entries:,} |\n            &lt;strong&gt;Violations:&lt;/strong&gt; {report.violations_count:,}\n        &lt;/p&gt;\n    &lt;/div&gt;\n\n    {''.join(sections_html)}\n\n    &lt;div class=\"footer\"&gt;\n        &lt;p&gt;This report was generated by rotalabs-comply&lt;/p&gt;\n    &lt;/div&gt;\n&lt;/body&gt;\n&lt;/html&gt;\"\"\"\n\n        return html_content\n\n    def _section_to_html(self, section: ReportSection, level: int = 2) -&gt; str:\n        \"\"\"\n        Convert a report section to HTML.\n\n        Args:\n            section: ReportSection to convert.\n            level: Heading level (default 2).\n\n        Returns:\n            HTML string for the section.\n        \"\"\"\n        # Convert markdown-style content to basic HTML\n        content = html.escape(section.content)\n\n        # Convert markdown tables to HTML tables\n        lines = content.split(\"\\n\")\n        in_table = False\n        html_lines = []\n\n        for line in lines:\n            if line.strip().startswith(\"|\") and \"|\" in line[1:]:\n                if not in_table:\n                    html_lines.append(\"&lt;table&gt;\")\n                    in_table = True\n                    # Check if this is a header separator\n                    if \"---\" in line:\n                        continue\n                cells = [c.strip() for c in line.split(\"|\")[1:-1]]\n                if html_lines[-1] == \"&lt;table&gt;\":\n                    # First row is header\n                    html_lines.append(\"&lt;tr&gt;\" + \"\".join(f\"&lt;th&gt;{c}&lt;/th&gt;\" for c in cells) + \"&lt;/tr&gt;\")\n                else:\n                    html_lines.append(\"&lt;tr&gt;\" + \"\".join(f\"&lt;td&gt;{c}&lt;/td&gt;\" for c in cells) + \"&lt;/tr&gt;\")\n            else:\n                if in_table:\n                    html_lines.append(\"&lt;/table&gt;\")\n                    in_table = False\n\n                # Convert markdown formatting\n                line = line.replace(\"**\", \"&lt;strong&gt;\", 1).replace(\"**\", \"&lt;/strong&gt;\", 1)\n                while \"**\" in line:\n                    line = line.replace(\"**\", \"&lt;strong&gt;\", 1).replace(\"**\", \"&lt;/strong&gt;\", 1)\n\n                # Convert headers\n                if line.startswith(\"### \"):\n                    line = f\"&lt;h4&gt;{line[4:]}&lt;/h4&gt;\"\n                elif line.startswith(\"#### \"):\n                    line = f\"&lt;h5&gt;{line[5:]}&lt;/h5&gt;\"\n                elif line.startswith(\"- \"):\n                    line = f\"&lt;li&gt;{line[2:]}&lt;/li&gt;\"\n                elif line.strip():\n                    line = f\"&lt;p&gt;{line}&lt;/p&gt;\"\n\n                html_lines.append(line)\n\n        if in_table:\n            html_lines.append(\"&lt;/table&gt;\")\n\n        content_html = \"\\n\".join(html_lines)\n\n        # Build subsections\n        subsections_html = \"\"\n        for subsection in section.subsections:\n            subsections_html += self._section_to_html(subsection, level + 1)\n\n        return f\"\"\"\n    &lt;div class=\"section\"&gt;\n        &lt;h{level}&gt;{html.escape(section.title)}&lt;/h{level}&gt;\n        {content_html}\n        {subsections_html}\n    &lt;/div&gt;\n\"\"\"\n\n    def _json_serializer(self, obj: Any) -&gt; Any:\n        \"\"\"\n        Custom JSON serializer for non-standard types.\n\n        Args:\n            obj: Object to serialize.\n\n        Returns:\n            JSON-serializable representation.\n        \"\"\"\n        if isinstance(obj, datetime):\n            return obj.isoformat()\n        if hasattr(obj, \"value\"):  # Enum\n            return obj.value\n        if hasattr(obj, \"to_dict\"):\n            return obj.to_dict()\n        if hasattr(obj, \"__dict__\"):\n            return obj.__dict__\n        return str(obj)\n</code></pre>"},{"location":"api/reports/#rotalabs_comply.reports.generator.ReportGenerator--generate-a-report","title":"Generate a report","text":"<p>report = await generator.generate( ...     period_start=datetime(2026, 1, 1), ...     period_end=datetime(2026, 1, 31), ...     profile=profile, ...     framework=\"eu_ai_act\", ... )</p>"},{"location":"api/reports/#rotalabs_comply.reports.generator.ReportGenerator.__init__","title":"__init__","text":"<pre><code>__init__(\n    audit_logger: StorageProtocol,\n    frameworks: Optional[\n        Dict[FrameworkName, ComplianceFramework]\n    ] = None,\n) -&gt; None\n</code></pre> <p>Initialize the report generator.</p> <p>Parameters:</p> Name Type Description Default <code>audit_logger</code> <code>StorageProtocol</code> <p>Storage backend implementing list_entries method.</p> required <code>frameworks</code> <code>Optional[Dict[FrameworkName, ComplianceFramework]]</code> <p>Optional dict mapping framework names to implementations. If not provided, compliance checks will be skipped.</p> <code>None</code> Example <p>generator = ReportGenerator(storage) generator = ReportGenerator(storage, {\"soc2\": SOC2Framework()})</p> Source code in <code>src/rotalabs_comply/reports/generator.py</code> <pre><code>def __init__(\n    self,\n    audit_logger: StorageProtocol,\n    frameworks: Optional[Dict[FrameworkName, ComplianceFramework]] = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the report generator.\n\n    Args:\n        audit_logger: Storage backend implementing list_entries method.\n        frameworks: Optional dict mapping framework names to implementations.\n            If not provided, compliance checks will be skipped.\n\n    Example:\n        &gt;&gt;&gt; generator = ReportGenerator(storage)\n        &gt;&gt;&gt; generator = ReportGenerator(storage, {\"soc2\": SOC2Framework()})\n    \"\"\"\n    self.storage = audit_logger\n    self.frameworks = frameworks or {}\n</code></pre>"},{"location":"api/reports/#rotalabs_comply.reports.generator.ReportGenerator.generate","title":"generate  <code>async</code>","text":"<pre><code>generate(\n    period_start: datetime,\n    period_end: datetime,\n    profile: ComplianceProfile,\n    framework: Optional[FrameworkName] = None,\n    format: Literal[\n        \"markdown\", \"json\", \"html\"\n    ] = \"markdown\",\n) -&gt; ComplianceReport\n</code></pre> <p>Generate a comprehensive compliance report.</p> <p>Retrieves audit entries for the specified period, runs compliance checks, and generates a full report with all standard sections.</p> <p>Parameters:</p> Name Type Description Default <code>period_start</code> <code>datetime</code> <p>Start of the analysis period (inclusive).</p> required <code>period_end</code> <code>datetime</code> <p>End of the analysis period (inclusive).</p> required <code>profile</code> <code>ComplianceProfile</code> <p>ComplianceProfile defining evaluation parameters.</p> required <code>framework</code> <code>Optional[FrameworkName]</code> <p>Specific framework to report on (None = all in profile).</p> <code>None</code> <code>format</code> <code>Literal['markdown', 'json', 'html']</code> <p>Output format hint (used for template selection).</p> <code>'markdown'</code> <p>Returns:</p> Type Description <code>ComplianceReport</code> <p>ComplianceReport with all sections populated.</p> Example <p>report = await generator.generate( ...     period_start=datetime(2026, 1, 1), ...     period_end=datetime(2026, 1, 31), ...     profile=profile, ...     format=\"markdown\", ... ) print(f\"Generated: {report.title}\") print(f\"Entries: {report.total_entries}\") print(f\"Score: {report.compliance_score:.2%}\")</p> Source code in <code>src/rotalabs_comply/reports/generator.py</code> <pre><code>async def generate(\n    self,\n    period_start: datetime,\n    period_end: datetime,\n    profile: ComplianceProfile,\n    framework: Optional[FrameworkName] = None,\n    format: Literal[\"markdown\", \"json\", \"html\"] = \"markdown\",\n) -&gt; ComplianceReport:\n    \"\"\"\n    Generate a comprehensive compliance report.\n\n    Retrieves audit entries for the specified period, runs compliance\n    checks, and generates a full report with all standard sections.\n\n    Args:\n        period_start: Start of the analysis period (inclusive).\n        period_end: End of the analysis period (inclusive).\n        profile: ComplianceProfile defining evaluation parameters.\n        framework: Specific framework to report on (None = all in profile).\n        format: Output format hint (used for template selection).\n\n    Returns:\n        ComplianceReport with all sections populated.\n\n    Example:\n        &gt;&gt;&gt; report = await generator.generate(\n        ...     period_start=datetime(2026, 1, 1),\n        ...     period_end=datetime(2026, 1, 31),\n        ...     profile=profile,\n        ...     format=\"markdown\",\n        ... )\n        &gt;&gt;&gt; print(f\"Generated: {report.title}\")\n        &gt;&gt;&gt; print(f\"Entries: {report.total_entries}\")\n        &gt;&gt;&gt; print(f\"Score: {report.compliance_score:.2%}\")\n    \"\"\"\n    # Retrieve audit entries\n    entries = await self.storage.list_entries(period_start, period_end)\n    total_entries = len(entries)\n\n    # Determine which frameworks to evaluate\n    frameworks_to_check = []\n    if framework:\n        frameworks_to_check = [framework]\n    elif profile.enabled_frameworks:\n        frameworks_to_check = profile.enabled_frameworks\n    else:\n        frameworks_to_check = list(self.frameworks.keys())\n\n    # Run compliance checks\n    all_results: List[ComplianceCheckResult] = []\n    all_violations: List[ComplianceViolation] = []\n\n    for fw_name in frameworks_to_check:\n        if fw_name in self.frameworks:\n            fw_impl = self.frameworks[fw_name]\n            for entry in entries:\n                # Convert storage entry to AuditEntry if needed\n                audit_entry = self._convert_to_audit_entry(entry)\n                result = await fw_impl.check(audit_entry, profile)\n                all_results.append(result)\n                all_violations.extend(result.violations)\n\n    # Calculate compliance metrics\n    total_checks = sum(r.rules_checked for r in all_results)\n    violations_count = len(all_violations)\n    critical_violations = sum(\n        1 for v in all_violations\n        if (v.severity.value if hasattr(v.severity, \"value\") else str(v.severity)).lower() == \"critical\"\n    )\n    high_violations = sum(\n        1 for v in all_violations\n        if (v.severity.value if hasattr(v.severity, \"value\") else str(v.severity)).lower() == \"high\"\n    )\n\n    compliance_score = self._calculate_compliance_score(all_violations, total_checks)\n    status = self._determine_status(compliance_score, critical_violations)\n\n    # Prepare statistics for section generators\n    stats = {\n        \"total_entries\": total_entries,\n        \"violations_count\": violations_count,\n        \"compliance_rate\": compliance_score * 100,\n        \"critical_violations\": critical_violations,\n        \"high_violations\": high_violations,\n        \"period_start\": period_start.strftime(\"%Y-%m-%d\"),\n        \"period_end\": period_end.strftime(\"%Y-%m-%d\"),\n        \"frameworks\": frameworks_to_check,\n    }\n\n    # Generate sections\n    sections = [\n        generate_executive_summary(stats),\n        generate_risk_assessment(all_violations),\n        generate_compliance_matrix(all_results),\n        generate_metrics_summary(entries),\n        generate_recommendations(all_violations),\n        generate_audit_summary(\n            entries,\n            f\"{period_start.strftime('%Y-%m-%d')} to {period_end.strftime('%Y-%m-%d')}\",\n        ),\n    ]\n\n    # Select template based on framework\n    if framework == \"eu_ai_act\":\n        template = EU_AI_ACT_TEMPLATE\n    elif framework == \"soc2\":\n        template = SOC2_TEMPLATE\n    elif framework == \"hipaa\":\n        template = HIPAA_TEMPLATE\n    else:\n        template = EXECUTIVE_SUMMARY_TEMPLATE\n\n    title = template.title if framework else f\"Compliance Report - {profile.name}\"\n\n    return ComplianceReport(\n        id=str(uuid.uuid4()),\n        title=title,\n        framework=framework,\n        period_start=period_start,\n        period_end=period_end,\n        generated_at=datetime.utcnow(),\n        profile=profile,\n        summary=stats,\n        sections=sections,\n        total_entries=total_entries,\n        violations_count=violations_count,\n        compliance_score=compliance_score,\n        status=status,\n    )\n</code></pre>"},{"location":"api/reports/#rotalabs_comply.reports.generator.ReportGenerator.generate_executive_summary","title":"generate_executive_summary  <code>async</code>","text":"<pre><code>generate_executive_summary(\n    period_start: datetime,\n    period_end: datetime,\n    profile: ComplianceProfile,\n) -&gt; ComplianceReport\n</code></pre> <p>Generate a high-level executive summary report.</p> <p>Creates a condensed report suitable for executive audiences, focusing on key metrics and critical findings without technical details.</p> <p>Parameters:</p> Name Type Description Default <code>period_start</code> <code>datetime</code> <p>Start of the analysis period.</p> required <code>period_end</code> <code>datetime</code> <p>End of the analysis period.</p> required <code>profile</code> <code>ComplianceProfile</code> <p>ComplianceProfile defining evaluation parameters.</p> required <p>Returns:</p> Type Description <code>ComplianceReport</code> <p>ComplianceReport with executive-focused sections.</p> Example <p>report = await generator.generate_executive_summary( ...     period_start=datetime(2026, 1, 1), ...     period_end=datetime(2026, 3, 31), ...     profile=profile, ... ) print(f\"Status: {report.status}\") print(f\"Score: {report.compliance_score:.2%}\")</p> Source code in <code>src/rotalabs_comply/reports/generator.py</code> <pre><code>async def generate_executive_summary(\n    self,\n    period_start: datetime,\n    period_end: datetime,\n    profile: ComplianceProfile,\n) -&gt; ComplianceReport:\n    \"\"\"\n    Generate a high-level executive summary report.\n\n    Creates a condensed report suitable for executive audiences,\n    focusing on key metrics and critical findings without technical details.\n\n    Args:\n        period_start: Start of the analysis period.\n        period_end: End of the analysis period.\n        profile: ComplianceProfile defining evaluation parameters.\n\n    Returns:\n        ComplianceReport with executive-focused sections.\n\n    Example:\n        &gt;&gt;&gt; report = await generator.generate_executive_summary(\n        ...     period_start=datetime(2026, 1, 1),\n        ...     period_end=datetime(2026, 3, 31),\n        ...     profile=profile,\n        ... )\n        &gt;&gt;&gt; print(f\"Status: {report.status}\")\n        &gt;&gt;&gt; print(f\"Score: {report.compliance_score:.2%}\")\n    \"\"\"\n    # Retrieve audit entries\n    entries = await self.storage.list_entries(period_start, period_end)\n    total_entries = len(entries)\n\n    # Run compliance checks for all frameworks in profile\n    frameworks_to_check = profile.enabled_frameworks or list(self.frameworks.keys())\n    all_violations: List[ComplianceViolation] = []\n    all_results: List[ComplianceCheckResult] = []\n\n    for fw_name in frameworks_to_check:\n        if fw_name in self.frameworks:\n            fw_impl = self.frameworks[fw_name]\n            for entry in entries:\n                audit_entry = self._convert_to_audit_entry(entry)\n                result = await fw_impl.check(audit_entry, profile)\n                all_results.append(result)\n                all_violations.extend(result.violations)\n\n    # Calculate metrics\n    total_checks = sum(r.rules_checked for r in all_results)\n    violations_count = len(all_violations)\n    critical_violations = sum(\n        1 for v in all_violations\n        if (v.severity.value if hasattr(v.severity, \"value\") else str(v.severity)).lower() == \"critical\"\n    )\n    high_violations = sum(\n        1 for v in all_violations\n        if (v.severity.value if hasattr(v.severity, \"value\") else str(v.severity)).lower() == \"high\"\n    )\n\n    compliance_score = self._calculate_compliance_score(all_violations, total_checks)\n    status = self._determine_status(compliance_score, critical_violations)\n\n    # Prepare statistics\n    stats = {\n        \"total_entries\": total_entries,\n        \"violations_count\": violations_count,\n        \"compliance_rate\": compliance_score * 100,\n        \"critical_violations\": critical_violations,\n        \"high_violations\": high_violations,\n        \"period_start\": period_start.strftime(\"%Y-%m-%d\"),\n        \"period_end\": period_end.strftime(\"%Y-%m-%d\"),\n        \"frameworks\": frameworks_to_check,\n    }\n\n    # Generate executive-focused sections only\n    sections = [\n        generate_executive_summary(stats),\n        generate_risk_assessment(all_violations),\n        generate_recommendations(all_violations),\n    ]\n\n    return ComplianceReport(\n        id=str(uuid.uuid4()),\n        title=f\"Executive Summary - {profile.name}\",\n        framework=None,\n        period_start=period_start,\n        period_end=period_end,\n        generated_at=datetime.utcnow(),\n        profile=profile,\n        summary=stats,\n        sections=sections,\n        total_entries=total_entries,\n        violations_count=violations_count,\n        compliance_score=compliance_score,\n        status=status,\n    )\n</code></pre>"},{"location":"api/reports/#rotalabs_comply.reports.generator.ReportGenerator.export_markdown","title":"export_markdown","text":"<pre><code>export_markdown(report: ComplianceReport) -&gt; str\n</code></pre> <p>Export report to Markdown format.</p> <p>Creates a well-formatted Markdown document with proper headings, tables, and structure suitable for documentation or rendering.</p> <p>Parameters:</p> Name Type Description Default <code>report</code> <code>ComplianceReport</code> <p>ComplianceReport to export.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Markdown formatted string.</p> Example <p>md = generator.export_markdown(report) with open(\"report.md\", \"w\") as f: ...     f.write(md)</p> Source code in <code>src/rotalabs_comply/reports/generator.py</code> <pre><code>def export_markdown(self, report: ComplianceReport) -&gt; str:\n    \"\"\"\n    Export report to Markdown format.\n\n    Creates a well-formatted Markdown document with proper headings,\n    tables, and structure suitable for documentation or rendering.\n\n    Args:\n        report: ComplianceReport to export.\n\n    Returns:\n        Markdown formatted string.\n\n    Example:\n        &gt;&gt;&gt; md = generator.export_markdown(report)\n        &gt;&gt;&gt; with open(\"report.md\", \"w\") as f:\n        ...     f.write(md)\n    \"\"\"\n    lines = [\n        f\"# {report.title}\",\n        \"\",\n        f\"**Report ID:** {report.id}\",\n        f\"**Generated:** {report.generated_at.strftime('%Y-%m-%d %H:%M:%S UTC')}\",\n        f\"**Period:** {report.period_start.strftime('%Y-%m-%d')} to {report.period_end.strftime('%Y-%m-%d')}\",\n        f\"**Framework:** {report.framework or 'Multiple'}\",\n        f\"**Profile:** {report.profile.name}\",\n        \"\",\n        \"---\",\n        \"\",\n        f\"**Compliance Score:** {report.compliance_score:.2%}\",\n        f\"**Status:** {report.status.upper().replace('_', ' ')}\",\n        f\"**Total Entries:** {report.total_entries:,}\",\n        f\"**Violations:** {report.violations_count:,}\",\n        \"\",\n        \"---\",\n        \"\",\n    ]\n\n    # Add each section\n    for section in report.sections:\n        lines.append(section.to_markdown(level=2))\n        lines.append(\"\")\n\n    # Footer\n    lines.extend([\n        \"---\",\n        \"\",\n        \"*This report was generated by rotalabs-comply.*\",\n    ])\n\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"api/reports/#rotalabs_comply.reports.generator.ReportGenerator.export_json","title":"export_json","text":"<pre><code>export_json(report: ComplianceReport) -&gt; str\n</code></pre> <p>Export report to JSON format.</p> <p>Creates a JSON document with all report data, suitable for programmatic processing or API responses.</p> <p>Parameters:</p> Name Type Description Default <code>report</code> <code>ComplianceReport</code> <p>ComplianceReport to export.</p> required <p>Returns:</p> Type Description <code>str</code> <p>JSON formatted string (pretty-printed).</p> Example <p>json_str = generator.export_json(report) data = json.loads(json_str) print(data[\"compliance_score\"])</p> Source code in <code>src/rotalabs_comply/reports/generator.py</code> <pre><code>def export_json(self, report: ComplianceReport) -&gt; str:\n    \"\"\"\n    Export report to JSON format.\n\n    Creates a JSON document with all report data, suitable for\n    programmatic processing or API responses.\n\n    Args:\n        report: ComplianceReport to export.\n\n    Returns:\n        JSON formatted string (pretty-printed).\n\n    Example:\n        &gt;&gt;&gt; json_str = generator.export_json(report)\n        &gt;&gt;&gt; data = json.loads(json_str)\n        &gt;&gt;&gt; print(data[\"compliance_score\"])\n    \"\"\"\n    return json.dumps(\n        report.to_dict(),\n        indent=2,\n        default=self._json_serializer,\n    )\n</code></pre>"},{"location":"api/reports/#rotalabs_comply.reports.generator.ReportGenerator.export_html","title":"export_html","text":"<pre><code>export_html(report: ComplianceReport) -&gt; str\n</code></pre> <p>Export report to HTML format.</p> <p>Creates a standalone HTML document with embedded styles, suitable for viewing in a browser or embedding in web applications.</p> <p>Parameters:</p> Name Type Description Default <code>report</code> <code>ComplianceReport</code> <p>ComplianceReport to export.</p> required <p>Returns:</p> Type Description <code>str</code> <p>HTML formatted string.</p> Example <p>html = generator.export_html(report) with open(\"report.html\", \"w\") as f: ...     f.write(html)</p> Source code in <code>src/rotalabs_comply/reports/generator.py</code> <pre><code>    def export_html(self, report: ComplianceReport) -&gt; str:\n        \"\"\"\n        Export report to HTML format.\n\n        Creates a standalone HTML document with embedded styles,\n        suitable for viewing in a browser or embedding in web applications.\n\n        Args:\n            report: ComplianceReport to export.\n\n        Returns:\n            HTML formatted string.\n\n        Example:\n            &gt;&gt;&gt; html = generator.export_html(report)\n            &gt;&gt;&gt; with open(\"report.html\", \"w\") as f:\n            ...     f.write(html)\n        \"\"\"\n        # Determine status color\n        status_colors = {\n            \"compliant\": \"#28a745\",\n            \"needs_review\": \"#ffc107\",\n            \"non_compliant\": \"#dc3545\",\n        }\n        status_color = status_colors.get(report.status, \"#6c757d\")\n\n        # Convert sections to HTML\n        sections_html = []\n        for section in report.sections:\n            section_html = self._section_to_html(section)\n            sections_html.append(section_html)\n\n        html_content = f\"\"\"&lt;!DOCTYPE html&gt;\n&lt;html lang=\"en\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n    &lt;title&gt;{html.escape(report.title)}&lt;/title&gt;\n    &lt;style&gt;\n        body {{\n            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;\n            line-height: 1.6;\n            max-width: 1200px;\n            margin: 0 auto;\n            padding: 20px;\n            color: #333;\n        }}\n        h1 {{\n            color: #2c3e50;\n            border-bottom: 3px solid #3498db;\n            padding-bottom: 10px;\n        }}\n        h2 {{\n            color: #34495e;\n            border-bottom: 1px solid #bdc3c7;\n            padding-bottom: 5px;\n            margin-top: 30px;\n        }}\n        h3 {{\n            color: #7f8c8d;\n        }}\n        .metadata {{\n            background: #f8f9fa;\n            padding: 15px;\n            border-radius: 5px;\n            margin-bottom: 20px;\n        }}\n        .metadata p {{\n            margin: 5px 0;\n        }}\n        .status-badge {{\n            display: inline-block;\n            padding: 5px 15px;\n            border-radius: 20px;\n            color: white;\n            font-weight: bold;\n            background-color: {status_color};\n        }}\n        .score {{\n            font-size: 2em;\n            font-weight: bold;\n            color: {status_color};\n        }}\n        table {{\n            border-collapse: collapse;\n            width: 100%;\n            margin: 15px 0;\n        }}\n        th, td {{\n            border: 1px solid #ddd;\n            padding: 10px;\n            text-align: left;\n        }}\n        th {{\n            background-color: #f2f2f2;\n        }}\n        tr:nth-child(even) {{\n            background-color: #f9f9f9;\n        }}\n        .section {{\n            margin-bottom: 30px;\n            padding: 20px;\n            background: white;\n            border: 1px solid #e1e4e8;\n            border-radius: 5px;\n        }}\n        .footer {{\n            margin-top: 40px;\n            padding-top: 20px;\n            border-top: 1px solid #e1e4e8;\n            text-align: center;\n            color: #6c757d;\n            font-size: 0.9em;\n        }}\n    &lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;{html.escape(report.title)}&lt;/h1&gt;\n\n    &lt;div class=\"metadata\"&gt;\n        &lt;p&gt;&lt;strong&gt;Report ID:&lt;/strong&gt; {html.escape(report.id)}&lt;/p&gt;\n        &lt;p&gt;&lt;strong&gt;Generated:&lt;/strong&gt; {report.generated_at.strftime('%Y-%m-%d %H:%M:%S UTC')}&lt;/p&gt;\n        &lt;p&gt;&lt;strong&gt;Period:&lt;/strong&gt; {report.period_start.strftime('%Y-%m-%d')} to {report.period_end.strftime('%Y-%m-%d')}&lt;/p&gt;\n        &lt;p&gt;&lt;strong&gt;Framework:&lt;/strong&gt; {html.escape(report.framework or 'Multiple')}&lt;/p&gt;\n        &lt;p&gt;&lt;strong&gt;Profile:&lt;/strong&gt; {html.escape(report.profile.name)}&lt;/p&gt;\n    &lt;/div&gt;\n\n    &lt;div class=\"metadata\" style=\"text-align: center;\"&gt;\n        &lt;p&gt;&lt;span class=\"score\"&gt;{report.compliance_score:.1%}&lt;/span&gt;&lt;/p&gt;\n        &lt;p&gt;&lt;span class=\"status-badge\"&gt;{report.status.upper().replace('_', ' ')}&lt;/span&gt;&lt;/p&gt;\n        &lt;p style=\"margin-top: 15px;\"&gt;\n            &lt;strong&gt;Entries Analyzed:&lt;/strong&gt; {report.total_entries:,} |\n            &lt;strong&gt;Violations:&lt;/strong&gt; {report.violations_count:,}\n        &lt;/p&gt;\n    &lt;/div&gt;\n\n    {''.join(sections_html)}\n\n    &lt;div class=\"footer\"&gt;\n        &lt;p&gt;This report was generated by rotalabs-comply&lt;/p&gt;\n    &lt;/div&gt;\n&lt;/body&gt;\n&lt;/html&gt;\"\"\"\n\n        return html_content\n</code></pre>"},{"location":"api/reports/#constructor","title":"Constructor","text":"<pre><code>ReportGenerator(\n    audit_logger: StorageProtocol,\n    frameworks: Optional[Dict[str, ComplianceFramework]] = None,\n)\n</code></pre> <p>Parameters:</p> Parameter Type Description <code>audit_logger</code> <code>StorageProtocol</code> Storage backend with <code>list_entries</code> method <code>frameworks</code> <code>Optional[Dict]</code> Framework name -&gt; implementation mapping <p>Example:</p> <pre><code>from rotalabs_comply import ReportGenerator\nfrom rotalabs_comply.audit import MemoryStorage\nfrom rotalabs_comply.frameworks.eu_ai_act import EUAIActFramework\nfrom rotalabs_comply.frameworks.soc2 import SOC2Framework\n\nstorage = MemoryStorage()\ngenerator = ReportGenerator(\n    audit_logger=storage,\n    frameworks={\n        \"eu_ai_act\": EUAIActFramework(),\n        \"soc2\": SOC2Framework(),\n    },\n)\n</code></pre>"},{"location":"api/reports/#methods","title":"Methods","text":""},{"location":"api/reports/#generate","title":"generate","text":"<pre><code>async def generate(\n    period_start: datetime,\n    period_end: datetime,\n    profile: ComplianceProfile,\n    framework: Optional[str] = None,\n    format: Literal[\"markdown\", \"json\", \"html\"] = \"markdown\",\n) -&gt; ComplianceReport\n</code></pre> <p>Generate a comprehensive compliance report.</p> <p>Parameters:</p> Parameter Type Default Description <code>period_start</code> <code>datetime</code> Required Analysis start (inclusive) <code>period_end</code> <code>datetime</code> Required Analysis end (inclusive) <code>profile</code> <code>ComplianceProfile</code> Required Evaluation configuration <code>framework</code> <code>Optional[str]</code> <code>None</code> Specific framework (None=all) <code>format</code> <code>str</code> <code>\"markdown\"</code> Output format hint <p>Returns: <code>ComplianceReport</code></p> <p>Example:</p> <pre><code>from datetime import datetime, timedelta\n\nend = datetime.utcnow()\nstart = end - timedelta(days=30)\n\nreport = await generator.generate(\n    period_start=start,\n    period_end=end,\n    profile=profile,\n    framework=\"eu_ai_act\",\n)\n</code></pre>"},{"location":"api/reports/#generate_executive_summary","title":"generate_executive_summary","text":"<pre><code>async def generate_executive_summary(\n    period_start: datetime,\n    period_end: datetime,\n    profile: ComplianceProfile,\n) -&gt; ComplianceReport\n</code></pre> <p>Generate a condensed executive summary report.</p> <p>Example:</p> <pre><code>report = await generator.generate_executive_summary(\n    period_start=start,\n    period_end=end,\n    profile=profile,\n)\n</code></pre>"},{"location":"api/reports/#export_markdown","title":"export_markdown","text":"<pre><code>def export_markdown(report: ComplianceReport) -&gt; str\n</code></pre> <p>Export report to Markdown format.</p> <p>Example:</p> <pre><code>markdown = generator.export_markdown(report)\nwith open(\"report.md\", \"w\") as f:\n    f.write(markdown)\n</code></pre>"},{"location":"api/reports/#export_json","title":"export_json","text":"<pre><code>def export_json(report: ComplianceReport) -&gt; str\n</code></pre> <p>Export report to JSON format (pretty-printed).</p> <p>Example:</p> <pre><code>json_str = generator.export_json(report)\n</code></pre>"},{"location":"api/reports/#export_html","title":"export_html","text":"<pre><code>def export_html(report: ComplianceReport) -&gt; str\n</code></pre> <p>Export report to standalone HTML format.</p> <p>Example:</p> <pre><code>html = generator.export_html(report)\nwith open(\"report.html\", \"w\") as f:\n    f.write(html)\n</code></pre>"},{"location":"api/reports/#compliancereport","title":"ComplianceReport","text":"<p>A complete compliance report with all sections and metadata.</p> <p>Attributes:</p> Attribute Type Description <code>id</code> <code>str</code> Unique report identifier <code>title</code> <code>str</code> Report title <code>framework</code> <code>Optional[str]</code> Framework evaluated (None=multiple) <code>period_start</code> <code>datetime</code> Analysis period start <code>period_end</code> <code>datetime</code> Analysis period end <code>generated_at</code> <code>datetime</code> When report was generated <code>profile</code> <code>ComplianceProfile</code> Profile used for evaluation <code>summary</code> <code>Dict[str, Any]</code> Summary statistics <code>sections</code> <code>List[ReportSection]</code> Report sections <code>total_entries</code> <code>int</code> Entries analyzed <code>violations_count</code> <code>int</code> Violations found <code>compliance_score</code> <code>float</code> Score 0.0-1.0 <code>status</code> <code>str</code> \"compliant\", \"non_compliant\", \"needs_review\" <p>Methods:</p> Method Returns Description <code>to_dict()</code> <code>Dict[str, Any]</code> Convert to dictionary"},{"location":"api/reports/#rotalabs_comply.reports.generator.ComplianceReport","title":"ComplianceReport  <code>dataclass</code>","text":"<p>A complete compliance report with all sections and metadata.</p> <p>ComplianceReport contains the full results of a compliance evaluation, including all sections, summary statistics, and compliance scoring.</p> <p>Attributes:</p> Name Type Description <code>id</code> <code>str</code> <p>Unique identifier for this report.</p> <code>title</code> <code>str</code> <p>Report title.</p> <code>framework</code> <code>Optional[FrameworkName]</code> <p>Framework evaluated (None for multi-framework reports).</p> <code>period_start</code> <code>datetime</code> <p>Start of the analysis period.</p> <code>period_end</code> <code>datetime</code> <p>End of the analysis period.</p> <code>generated_at</code> <code>datetime</code> <p>When the report was generated.</p> <code>profile</code> <code>ComplianceProfile</code> <p>ComplianceProfile used for evaluation.</p> <code>summary</code> <code>Dict[str, Any]</code> <p>Summary statistics dictionary.</p> <code>sections</code> <code>List[ReportSection]</code> <p>List of report sections.</p> <code>total_entries</code> <code>int</code> <p>Total audit entries analyzed.</p> <code>violations_count</code> <code>int</code> <p>Number of violations found.</p> <code>compliance_score</code> <code>float</code> <p>Overall compliance score (0.0 to 1.0).</p> <code>status</code> <code>Literal['compliant', 'non_compliant', 'needs_review']</code> <p>Overall compliance status.</p> Example <p>report = ComplianceReport( ...     id=\"rpt-001\", ...     title=\"Q1 2026 Compliance Report\", ...     framework=None,  # Multi-framework ...     period_start=datetime(2026, 1, 1), ...     period_end=datetime(2026, 3, 31), ...     generated_at=datetime.utcnow(), ...     profile=profile, ...     summary={\"total\": 10000, \"violations\": 5}, ...     sections=[executive_summary, risk_assessment], ...     total_entries=10000, ...     violations_count=5, ...     compliance_score=0.9995, ...     status=\"compliant\", ... ) print(f\"Compliance: {report.compliance_score:.2%}\") Compliance: 99.95%</p> Source code in <code>src/rotalabs_comply/reports/generator.py</code> <pre><code>@dataclass\nclass ComplianceReport:\n    \"\"\"\n    A complete compliance report with all sections and metadata.\n\n    ComplianceReport contains the full results of a compliance evaluation,\n    including all sections, summary statistics, and compliance scoring.\n\n    Attributes:\n        id: Unique identifier for this report.\n        title: Report title.\n        framework: Framework evaluated (None for multi-framework reports).\n        period_start: Start of the analysis period.\n        period_end: End of the analysis period.\n        generated_at: When the report was generated.\n        profile: ComplianceProfile used for evaluation.\n        summary: Summary statistics dictionary.\n        sections: List of report sections.\n        total_entries: Total audit entries analyzed.\n        violations_count: Number of violations found.\n        compliance_score: Overall compliance score (0.0 to 1.0).\n        status: Overall compliance status.\n\n    Example:\n        &gt;&gt;&gt; report = ComplianceReport(\n        ...     id=\"rpt-001\",\n        ...     title=\"Q1 2026 Compliance Report\",\n        ...     framework=None,  # Multi-framework\n        ...     period_start=datetime(2026, 1, 1),\n        ...     period_end=datetime(2026, 3, 31),\n        ...     generated_at=datetime.utcnow(),\n        ...     profile=profile,\n        ...     summary={\"total\": 10000, \"violations\": 5},\n        ...     sections=[executive_summary, risk_assessment],\n        ...     total_entries=10000,\n        ...     violations_count=5,\n        ...     compliance_score=0.9995,\n        ...     status=\"compliant\",\n        ... )\n        &gt;&gt;&gt; print(f\"Compliance: {report.compliance_score:.2%}\")\n        Compliance: 99.95%\n    \"\"\"\n\n    id: str\n    title: str\n    framework: Optional[FrameworkName]\n    period_start: datetime\n    period_end: datetime\n    generated_at: datetime\n    profile: ComplianceProfile\n    summary: Dict[str, Any]\n    sections: List[ReportSection]\n    total_entries: int\n    violations_count: int\n    compliance_score: float\n    status: Literal[\"compliant\", \"non_compliant\", \"needs_review\"]\n\n    def to_dict(self) -&gt; Dict[str, Any]:\n        \"\"\"\n        Convert report to dictionary for serialization.\n\n        Returns:\n            Dict containing all report data.\n\n        Example:\n            &gt;&gt;&gt; data = report.to_dict()\n            &gt;&gt;&gt; print(data[\"status\"])\n            'compliant'\n        \"\"\"\n        return {\n            \"id\": self.id,\n            \"title\": self.title,\n            \"framework\": self.framework,\n            \"period_start\": self.period_start.isoformat(),\n            \"period_end\": self.period_end.isoformat(),\n            \"generated_at\": self.generated_at.isoformat(),\n            \"profile\": {\n                \"profile_id\": self.profile.profile_id,\n                \"name\": self.profile.name,\n                \"enabled_frameworks\": self.profile.enabled_frameworks,\n            },\n            \"summary\": self.summary,\n            \"sections\": [s.to_dict() for s in self.sections],\n            \"total_entries\": self.total_entries,\n            \"violations_count\": self.violations_count,\n            \"compliance_score\": self.compliance_score,\n            \"status\": self.status,\n        }\n</code></pre>"},{"location":"api/reports/#rotalabs_comply.reports.generator.ComplianceReport.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert report to dictionary for serialization.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict containing all report data.</p> Example <p>data = report.to_dict() print(data[\"status\"]) 'compliant'</p> Source code in <code>src/rotalabs_comply/reports/generator.py</code> <pre><code>def to_dict(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Convert report to dictionary for serialization.\n\n    Returns:\n        Dict containing all report data.\n\n    Example:\n        &gt;&gt;&gt; data = report.to_dict()\n        &gt;&gt;&gt; print(data[\"status\"])\n        'compliant'\n    \"\"\"\n    return {\n        \"id\": self.id,\n        \"title\": self.title,\n        \"framework\": self.framework,\n        \"period_start\": self.period_start.isoformat(),\n        \"period_end\": self.period_end.isoformat(),\n        \"generated_at\": self.generated_at.isoformat(),\n        \"profile\": {\n            \"profile_id\": self.profile.profile_id,\n            \"name\": self.profile.name,\n            \"enabled_frameworks\": self.profile.enabled_frameworks,\n        },\n        \"summary\": self.summary,\n        \"sections\": [s.to_dict() for s in self.sections],\n        \"total_entries\": self.total_entries,\n        \"violations_count\": self.violations_count,\n        \"compliance_score\": self.compliance_score,\n        \"status\": self.status,\n    }\n</code></pre>"},{"location":"api/reports/#templates","title":"Templates","text":""},{"location":"api/reports/#reportsection","title":"ReportSection","text":""},{"location":"api/reports/#rotalabs_comply.reports.templates.ReportSection","title":"ReportSection  <code>dataclass</code>","text":"<p>A section within a compliance report.</p> <p>Report sections can contain nested subsections to create hierarchical report structures. Each section has a title, content, and optional metadata for additional context.</p> <p>Attributes:</p> Name Type Description <code>title</code> <code>str</code> <p>Section heading/title.</p> <code>content</code> <code>str</code> <p>Main content of the section (text, markdown, etc.).</p> <code>subsections</code> <code>List['ReportSection']</code> <p>Nested sections within this section.</p> <code>metadata</code> <code>Dict[str, Any]</code> <p>Additional data about the section (charts, tables, etc.).</p> Example <p>section = ReportSection( ...     title=\"Risk Assessment\", ...     content=\"This section analyzes identified compliance risks.\", ...     subsections=[ ...         ReportSection( ...             title=\"Critical Risks\", ...             content=\"No critical risks identified.\", ...         ), ...         ReportSection( ...             title=\"High Risks\", ...             content=\"2 high-risk violations require attention.\", ...         ), ...     ], ...     metadata={\"risk_count\": 2, \"max_severity\": \"high\"}, ... )</p> Source code in <code>src/rotalabs_comply/reports/templates.py</code> <pre><code>@dataclass\nclass ReportSection:\n    \"\"\"\n    A section within a compliance report.\n\n    Report sections can contain nested subsections to create hierarchical\n    report structures. Each section has a title, content, and optional\n    metadata for additional context.\n\n    Attributes:\n        title: Section heading/title.\n        content: Main content of the section (text, markdown, etc.).\n        subsections: Nested sections within this section.\n        metadata: Additional data about the section (charts, tables, etc.).\n\n    Example:\n        &gt;&gt;&gt; section = ReportSection(\n        ...     title=\"Risk Assessment\",\n        ...     content=\"This section analyzes identified compliance risks.\",\n        ...     subsections=[\n        ...         ReportSection(\n        ...             title=\"Critical Risks\",\n        ...             content=\"No critical risks identified.\",\n        ...         ),\n        ...         ReportSection(\n        ...             title=\"High Risks\",\n        ...             content=\"2 high-risk violations require attention.\",\n        ...         ),\n        ...     ],\n        ...     metadata={\"risk_count\": 2, \"max_severity\": \"high\"},\n        ... )\n\n        &gt;&gt;&gt; # Access nested sections\n        &gt;&gt;&gt; for sub in section.subsections:\n        ...     print(f\"- {sub.title}\")\n        - Critical Risks\n        - High Risks\n    \"\"\"\n\n    title: str\n    content: str\n    subsections: List[\"ReportSection\"] = field(default_factory=list)\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n    def to_dict(self) -&gt; Dict[str, Any]:\n        \"\"\"\n        Convert section to dictionary for serialization.\n\n        Returns:\n            Dict containing all section data including nested subsections.\n\n        Example:\n            &gt;&gt;&gt; section = ReportSection(title=\"Test\", content=\"Content\")\n            &gt;&gt;&gt; data = section.to_dict()\n            &gt;&gt;&gt; print(data[\"title\"])\n            'Test'\n        \"\"\"\n        return {\n            \"title\": self.title,\n            \"content\": self.content,\n            \"subsections\": [s.to_dict() for s in self.subsections],\n            \"metadata\": self.metadata,\n        }\n\n    def to_markdown(self, level: int = 2) -&gt; str:\n        \"\"\"\n        Render section as markdown with appropriate heading levels.\n\n        Args:\n            level: Heading level (default 2 = ##). Subsections use level + 1.\n\n        Returns:\n            Markdown formatted string of the section.\n\n        Example:\n            &gt;&gt;&gt; section = ReportSection(title=\"Summary\", content=\"All good.\")\n            &gt;&gt;&gt; print(section.to_markdown())\n            ## Summary\n            &lt;BLANKLINE&gt;\n            All good.\n        \"\"\"\n        heading = \"#\" * level\n        lines = [f\"{heading} {self.title}\", \"\", self.content]\n\n        for subsection in self.subsections:\n            lines.append(\"\")\n            lines.append(subsection.to_markdown(level + 1))\n\n        return \"\\n\".join(lines)\n</code></pre>"},{"location":"api/reports/#rotalabs_comply.reports.templates.ReportSection--access-nested-sections","title":"Access nested sections","text":"<p>for sub in section.subsections: ...     print(f\"- {sub.title}\") - Critical Risks - High Risks</p>"},{"location":"api/reports/#rotalabs_comply.reports.templates.ReportSection.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert section to dictionary for serialization.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict containing all section data including nested subsections.</p> Example <p>section = ReportSection(title=\"Test\", content=\"Content\") data = section.to_dict() print(data[\"title\"]) 'Test'</p> Source code in <code>src/rotalabs_comply/reports/templates.py</code> <pre><code>def to_dict(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Convert section to dictionary for serialization.\n\n    Returns:\n        Dict containing all section data including nested subsections.\n\n    Example:\n        &gt;&gt;&gt; section = ReportSection(title=\"Test\", content=\"Content\")\n        &gt;&gt;&gt; data = section.to_dict()\n        &gt;&gt;&gt; print(data[\"title\"])\n        'Test'\n    \"\"\"\n    return {\n        \"title\": self.title,\n        \"content\": self.content,\n        \"subsections\": [s.to_dict() for s in self.subsections],\n        \"metadata\": self.metadata,\n    }\n</code></pre>"},{"location":"api/reports/#rotalabs_comply.reports.templates.ReportSection.to_markdown","title":"to_markdown","text":"<pre><code>to_markdown(level: int = 2) -&gt; str\n</code></pre> <p>Render section as markdown with appropriate heading levels.</p> <p>Parameters:</p> Name Type Description Default <code>level</code> <code>int</code> <p>Heading level (default 2 = ##). Subsections use level + 1.</p> <code>2</code> <p>Returns:</p> Type Description <code>str</code> <p>Markdown formatted string of the section.</p> Example <p>section = ReportSection(title=\"Summary\", content=\"All good.\") print(section.to_markdown())</p>"},{"location":"api/reports/#rotalabs_comply.reports.templates.ReportSection.to_markdown--summary","title":"Summary","text":"<p> All good. Source code in <code>src/rotalabs_comply/reports/templates.py</code> <pre><code>def to_markdown(self, level: int = 2) -&gt; str:\n    \"\"\"\n    Render section as markdown with appropriate heading levels.\n\n    Args:\n        level: Heading level (default 2 = ##). Subsections use level + 1.\n\n    Returns:\n        Markdown formatted string of the section.\n\n    Example:\n        &gt;&gt;&gt; section = ReportSection(title=\"Summary\", content=\"All good.\")\n        &gt;&gt;&gt; print(section.to_markdown())\n        ## Summary\n        &lt;BLANKLINE&gt;\n        All good.\n    \"\"\"\n    heading = \"#\" * level\n    lines = [f\"{heading} {self.title}\", \"\", self.content]\n\n    for subsection in self.subsections:\n        lines.append(\"\")\n        lines.append(subsection.to_markdown(level + 1))\n\n    return \"\\n\".join(lines)\n</code></pre> <p>A section within a compliance report.</p> <p>Attributes:</p> Attribute Type Description <code>title</code> <code>str</code> Section heading <code>content</code> <code>str</code> Main content (text/markdown) <code>subsections</code> <code>List[ReportSection]</code> Nested sections <code>metadata</code> <code>Dict[str, Any]</code> Additional data <p>Methods:</p> Method Returns Description <code>to_dict()</code> <code>Dict[str, Any]</code> Convert to dictionary <code>to_markdown(level=2)</code> <code>str</code> Render as markdown <p>Example:</p> <pre><code>from rotalabs_comply.reports.templates import ReportSection\n\nsection = ReportSection(\n    title=\"Risk Assessment\",\n    content=\"Analysis of identified risks...\",\n    subsections=[\n        ReportSection(title=\"Critical Risks\", content=\"None found.\"),\n        ReportSection(title=\"High Risks\", content=\"2 issues identified.\"),\n    ],\n    metadata={\"risk_count\": 2},\n)\n\nprint(section.to_markdown())\n</code></pre>"},{"location":"api/reports/#reporttemplate","title":"ReportTemplate","text":"<p>Template defining report structure and format.</p> <p>Attributes:</p> Attribute Type Description <code>framework</code> <code>str</code> Target framework <code>title</code> <code>str</code> Default title <code>sections</code> <code>List[str]</code> Section names to include <code>format</code> <code>str</code> Output format"},{"location":"api/reports/#rotalabs_comply.reports.templates.ReportTemplate","title":"ReportTemplate  <code>dataclass</code>","text":"<p>Template defining the structure and format of a compliance report.</p> <p>Templates specify which framework the report covers, its title, which sections to include, and the output format.</p> <p>Attributes:</p> Name Type Description <code>framework</code> <code>FrameworkType</code> <p>The compliance framework this template is for.</p> <code>title</code> <code>str</code> <p>Default title for reports using this template.</p> <code>sections</code> <code>List[str]</code> <p>List of section names to include in the report.</p> <code>format</code> <code>Literal['markdown', 'json', 'html']</code> <p>Output format for the report (markdown, json, or html).</p> Example <p>template = ReportTemplate( ...     framework=\"eu_ai_act\", ...     title=\"EU AI Act Compliance Report\", ...     sections=[ ...         \"executive_summary\", ...         \"risk_assessment\", ...         \"compliance_matrix\", ...         \"recommendations\", ...     ], ...     format=\"markdown\", ... )</p> Source code in <code>src/rotalabs_comply/reports/templates.py</code> <pre><code>@dataclass\nclass ReportTemplate:\n    \"\"\"\n    Template defining the structure and format of a compliance report.\n\n    Templates specify which framework the report covers, its title,\n    which sections to include, and the output format.\n\n    Attributes:\n        framework: The compliance framework this template is for.\n        title: Default title for reports using this template.\n        sections: List of section names to include in the report.\n        format: Output format for the report (markdown, json, or html).\n\n    Example:\n        &gt;&gt;&gt; template = ReportTemplate(\n        ...     framework=\"eu_ai_act\",\n        ...     title=\"EU AI Act Compliance Report\",\n        ...     sections=[\n        ...         \"executive_summary\",\n        ...         \"risk_assessment\",\n        ...         \"compliance_matrix\",\n        ...         \"recommendations\",\n        ...     ],\n        ...     format=\"markdown\",\n        ... )\n\n        &gt;&gt;&gt; # Check what sections will be included\n        &gt;&gt;&gt; \"risk_assessment\" in template.sections\n        True\n    \"\"\"\n\n    framework: FrameworkType\n    title: str\n    sections: List[str]\n    format: Literal[\"markdown\", \"json\", \"html\"] = \"markdown\"\n\n    def to_dict(self) -&gt; Dict[str, Any]:\n        \"\"\"\n        Convert template to dictionary.\n\n        Returns:\n            Dict containing template configuration.\n        \"\"\"\n        return {\n            \"framework\": self.framework,\n            \"title\": self.title,\n            \"sections\": self.sections,\n            \"format\": self.format,\n        }\n</code></pre>"},{"location":"api/reports/#rotalabs_comply.reports.templates.ReportTemplate--check-what-sections-will-be-included","title":"Check what sections will be included","text":"<p>\"risk_assessment\" in template.sections True</p>"},{"location":"api/reports/#rotalabs_comply.reports.templates.ReportTemplate.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Convert template to dictionary.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict containing template configuration.</p> Source code in <code>src/rotalabs_comply/reports/templates.py</code> <pre><code>def to_dict(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Convert template to dictionary.\n\n    Returns:\n        Dict containing template configuration.\n    \"\"\"\n    return {\n        \"framework\": self.framework,\n        \"title\": self.title,\n        \"sections\": self.sections,\n        \"format\": self.format,\n    }\n</code></pre>"},{"location":"api/reports/#pre-defined-templates","title":"Pre-defined Templates","text":""},{"location":"api/reports/#eu_ai_act_template","title":"EU_AI_ACT_TEMPLATE","text":"<p>Template for EU AI Act compliance reports.</p> <p>Sections: - executive_summary - risk_classification - risk_assessment - transparency_obligations - human_oversight - compliance_matrix - data_governance - technical_documentation - recommendations - audit_summary</p>"},{"location":"api/reports/#rotalabs_comply.reports.templates.EU_AI_ACT_TEMPLATE","title":"EU_AI_ACT_TEMPLATE  <code>module-attribute</code>","text":"<pre><code>EU_AI_ACT_TEMPLATE = ReportTemplate(\n    framework=\"eu_ai_act\",\n    title=\"EU AI Act Compliance Report\",\n    sections=[\n        \"executive_summary\",\n        \"risk_classification\",\n        \"risk_assessment\",\n        \"transparency_obligations\",\n        \"human_oversight\",\n        \"compliance_matrix\",\n        \"data_governance\",\n        \"technical_documentation\",\n        \"recommendations\",\n        \"audit_summary\",\n    ],\n    format=\"markdown\",\n)\n</code></pre> <p>Template for EU AI Act compliance reports.</p> <p>Includes sections required for demonstrating compliance with the European Union's Artificial Intelligence Act, focusing on risk classification, transparency, and human oversight requirements.</p> Example <p>from rotalabs_comply.reports.templates import EU_AI_ACT_TEMPLATE print(EU_AI_ACT_TEMPLATE.title) 'EU AI Act Compliance Report'</p>"},{"location":"api/reports/#soc2_template","title":"SOC2_TEMPLATE","text":"<p>Template for SOC2 Type II compliance reports.</p> <p>Sections: - executive_summary - system_overview - risk_assessment - security_controls - availability_controls - processing_integrity - confidentiality_controls - privacy_controls - compliance_matrix - recommendations - audit_summary</p>"},{"location":"api/reports/#rotalabs_comply.reports.templates.SOC2_TEMPLATE","title":"SOC2_TEMPLATE  <code>module-attribute</code>","text":"<pre><code>SOC2_TEMPLATE = ReportTemplate(\n    framework=\"soc2\",\n    title=\"SOC2 Type II Compliance Report\",\n    sections=[\n        \"executive_summary\",\n        \"system_overview\",\n        \"risk_assessment\",\n        \"security_controls\",\n        \"availability_controls\",\n        \"processing_integrity\",\n        \"confidentiality_controls\",\n        \"privacy_controls\",\n        \"compliance_matrix\",\n        \"recommendations\",\n        \"audit_summary\",\n    ],\n    format=\"markdown\",\n)\n</code></pre> <p>Template for SOC2 Type II compliance reports.</p> <p>Covers the five Trust Service Criteria: Security, Availability, Processing Integrity, Confidentiality, and Privacy.</p> Example <p>from rotalabs_comply.reports.templates import SOC2_TEMPLATE \"security_controls\" in SOC2_TEMPLATE.sections True</p>"},{"location":"api/reports/#hipaa_template","title":"HIPAA_TEMPLATE","text":"<p>Template for HIPAA compliance reports.</p> <p>Sections: - executive_summary - risk_assessment - administrative_safeguards - physical_safeguards - technical_safeguards - breach_notification - phi_handling - compliance_matrix - recommendations - audit_summary</p>"},{"location":"api/reports/#rotalabs_comply.reports.templates.HIPAA_TEMPLATE","title":"HIPAA_TEMPLATE  <code>module-attribute</code>","text":"<pre><code>HIPAA_TEMPLATE = ReportTemplate(\n    framework=\"hipaa\",\n    title=\"HIPAA Compliance Report\",\n    sections=[\n        \"executive_summary\",\n        \"risk_assessment\",\n        \"administrative_safeguards\",\n        \"physical_safeguards\",\n        \"technical_safeguards\",\n        \"breach_notification\",\n        \"phi_handling\",\n        \"compliance_matrix\",\n        \"recommendations\",\n        \"audit_summary\",\n    ],\n    format=\"markdown\",\n)\n</code></pre> <p>Template for HIPAA compliance reports.</p> <p>Covers the Security Rule requirements including Administrative, Physical, and Technical Safeguards for Protected Health Information (PHI).</p> Example <p>from rotalabs_comply.reports.templates import HIPAA_TEMPLATE \"phi_handling\" in HIPAA_TEMPLATE.sections True</p>"},{"location":"api/reports/#executive_summary_template","title":"EXECUTIVE_SUMMARY_TEMPLATE","text":"<p>Template for executive summary reports.</p> <p>Sections: - executive_summary - key_metrics - risk_assessment - critical_findings - recommendations</p>"},{"location":"api/reports/#rotalabs_comply.reports.templates.EXECUTIVE_SUMMARY_TEMPLATE","title":"EXECUTIVE_SUMMARY_TEMPLATE  <code>module-attribute</code>","text":"<pre><code>EXECUTIVE_SUMMARY_TEMPLATE = ReportTemplate(\n    framework=\"any\",\n    title=\"Compliance Executive Summary\",\n    sections=[\n        \"executive_summary\",\n        \"key_metrics\",\n        \"risk_assessment\",\n        \"critical_findings\",\n        \"recommendations\",\n    ],\n    format=\"markdown\",\n)\n</code></pre> <p>Template for high-level executive summary reports.</p> <p>Designed for executive audiences, focusing on key metrics, critical findings, and high-priority recommendations without technical details.</p> Example <p>from rotalabs_comply.reports.templates import EXECUTIVE_SUMMARY_TEMPLATE len(EXECUTIVE_SUMMARY_TEMPLATE.sections) 5</p>"},{"location":"api/reports/#section-generators","title":"Section Generators","text":""},{"location":"api/reports/#generate_executive_summary_1","title":"generate_executive_summary","text":"<pre><code>def generate_executive_summary(stats: Dict[str, Any]) -&gt; ReportSection\n</code></pre> <p>Generate executive summary from statistics.</p> <p>Expected stats keys: - <code>total_entries</code>: int - <code>violations_count</code>: int - <code>compliance_rate</code>: float (0-100) - <code>critical_violations</code>: int - <code>high_violations</code>: int - <code>period_start</code>: str - <code>period_end</code>: str - <code>frameworks</code>: List[str]</p> <p>Example:</p> <pre><code>from rotalabs_comply.reports.templates import generate_executive_summary\n\nstats = {\n    \"total_entries\": 10000,\n    \"violations_count\": 15,\n    \"compliance_rate\": 99.85,\n    \"critical_violations\": 0,\n    \"high_violations\": 2,\n    \"period_start\": \"2026-01-01\",\n    \"period_end\": \"2026-01-31\",\n    \"frameworks\": [\"EU AI Act\", \"SOC2\"],\n}\n\nsection = generate_executive_summary(stats)\nprint(section.metadata[\"status\"])  # \"NEEDS REVIEW\"\n</code></pre>"},{"location":"api/reports/#generate_risk_assessment","title":"generate_risk_assessment","text":"<pre><code>def generate_risk_assessment(violations: Sequence[ComplianceViolation]) -&gt; ReportSection\n</code></pre> <p>Generate risk assessment from violations.</p> <p>Returns section with metadata: - <code>overall_risk</code>: str - <code>severity_counts</code>: Dict[str, int] - <code>category_counts</code>: Dict[str, int] - <code>violation_count</code>: int</p>"},{"location":"api/reports/#generate_compliance_matrix","title":"generate_compliance_matrix","text":"<pre><code>def generate_compliance_matrix(results: Sequence[ComplianceCheckResult]) -&gt; ReportSection\n</code></pre> <p>Generate compliance matrix from check results.</p> <p>Returns section with metadata: - <code>frameworks</code>: List[str] - <code>total_checks</code>: int - <code>total_passed</code>: int - <code>total_violations</code>: int - <code>compliance_rate</code>: float</p>"},{"location":"api/reports/#generate_recommendations","title":"generate_recommendations","text":"<pre><code>def generate_recommendations(violations: Sequence[ComplianceViolation]) -&gt; ReportSection\n</code></pre> <p>Generate prioritized recommendations from violations.</p> <p>Returns section with metadata: - <code>recommendation_count</code>: int - <code>immediate_count</code>: int - <code>short_term_count</code>: int - <code>long_term_count</code>: int</p>"},{"location":"api/reports/#generate_metrics_summary","title":"generate_metrics_summary","text":"<pre><code>def generate_metrics_summary(entries: Sequence[Any]) -&gt; ReportSection\n</code></pre> <p>Generate metrics summary from audit entries.</p> <p>Returns section with metadata: - <code>entry_count</code>: int - <code>safety_rate</code>: float - <code>avg_latency</code>: float - <code>p50_latency</code>: float - <code>p95_latency</code>: float - <code>p99_latency</code>: float</p>"},{"location":"api/reports/#generate_audit_summary","title":"generate_audit_summary","text":"<pre><code>def generate_audit_summary(entries: Sequence[Any], period: str) -&gt; ReportSection\n</code></pre> <p>Generate audit summary for a period.</p> <p>Returns section with metadata: - <code>period</code>: str - <code>entry_count</code>: int - <code>days_active</code>: int - <code>avg_daily</code>: float - <code>peak_daily</code>: int</p>"},{"location":"api/utils/","title":"Utilities Module","text":"<p>Helper functions for date formatting, statistics calculation, and JSON serialization.</p>"},{"location":"api/utils/#period-formatting","title":"Period Formatting","text":""},{"location":"api/utils/#format_period","title":"format_period","text":"<pre><code>def format_period(start: datetime, end: datetime) -&gt; str\n</code></pre> <p>Format a date range as a human-readable period string.</p> <p>Automatically detects the most appropriate format based on the date range.</p> <p>Parameters:</p> Parameter Type Description <code>start</code> <code>datetime</code> Start of period <code>end</code> <code>datetime</code> End of period <p>Returns: Formatted period string</p> <p>Examples:</p> <pre><code>from datetime import datetime\nfrom rotalabs_comply.utils import format_period\n\n# Quarter\nformat_period(datetime(2026, 1, 1), datetime(2026, 3, 31))\n# Returns: '2026-Q1'\n\n# Month\nformat_period(datetime(2026, 1, 1), datetime(2026, 1, 31))\n# Returns: 'Jan 2026'\n\n# Year\nformat_period(datetime(2026, 1, 1), datetime(2026, 12, 31))\n# Returns: '2026'\n\n# Date range\nformat_period(datetime(2026, 1, 15), datetime(2026, 2, 20))\n# Returns: '2026-01-15 to 2026-02-20'\n</code></pre>"},{"location":"api/utils/#parse_period","title":"parse_period","text":"<pre><code>def parse_period(period: str) -&gt; Tuple[datetime, datetime]\n</code></pre> <p>Parse a period string back to start and end datetimes.</p> <p>Parameters:</p> Parameter Type Description <code>period</code> <code>str</code> Period string to parse <p>Returns: Tuple of (start_datetime, end_datetime)</p> <p>Raises: <code>ValueError</code> if the period string cannot be parsed</p> <p>Supported formats: - <code>YYYY-Q#</code> (quarter) - <code>YYYY</code> (year) - <code>Mon YYYY</code> or <code>Month YYYY</code> (month) - <code>YYYY-MM-DD to YYYY-MM-DD</code> (date range) - ISO date format</p> <p>Examples:</p> <pre><code>from rotalabs_comply.utils import parse_period\n\n# Quarter\nstart, end = parse_period(\"2026-Q1\")\n# start: datetime(2026, 1, 1, 0, 0)\n# end: datetime(2026, 3, 31, 23, 59, 59)\n\n# Month\nstart, end = parse_period(\"Jan 2026\")\n# start: datetime(2026, 1, 1, 0, 0)\n# end: datetime(2026, 1, 31, 23, 59, 59)\n\n# Year\nstart, end = parse_period(\"2026\")\n# start: datetime(2026, 1, 1, 0, 0)\n# end: datetime(2026, 12, 31, 23, 59, 59)\n\n# Date range\nstart, end = parse_period(\"2026-01-15 to 2026-02-20\")\n# start: datetime(2026, 1, 15, 0, 0)\n# end: datetime(2026, 2, 20, 23, 59, 59)\n</code></pre>"},{"location":"api/utils/#statistics","title":"Statistics","text":""},{"location":"api/utils/#calculate_statistics","title":"calculate_statistics","text":"<pre><code>def calculate_statistics(entries: Sequence[Any]) -&gt; Dict[str, Any]\n</code></pre> <p>Calculate basic statistics from audit entries.</p> <p>Parameters:</p> Parameter Type Description <code>entries</code> <code>Sequence[Any]</code> List of audit entries (dict or object) <p>Expected entry attributes: - <code>timestamp</code> - <code>safety_passed</code> - <code>latency_ms</code> - <code>provider</code> - <code>model</code> - <code>detectors_triggered</code></p> <p>Returns:</p> Key Type Description <code>total_entries</code> <code>int</code> Total count <code>safety_passed</code> <code>int</code> Entries passing safety <code>safety_failed</code> <code>int</code> Entries failing safety <code>safety_rate</code> <code>float</code> Pass percentage (0-100) <code>avg_latency_ms</code> <code>float</code> Average latency <code>min_latency_ms</code> <code>float</code> Minimum latency <code>max_latency_ms</code> <code>float</code> Maximum latency <code>providers</code> <code>Dict[str, int]</code> Provider counts <code>models</code> <code>Dict[str, int]</code> Model counts <code>detectors</code> <code>Dict[str, int]</code> Detector trigger counts <p>Example:</p> <pre><code>from rotalabs_comply.utils import calculate_statistics\n\nentries = [\n    {\"safety_passed\": True, \"latency_ms\": 100.0, \"provider\": \"openai\"},\n    {\"safety_passed\": True, \"latency_ms\": 150.0, \"provider\": \"openai\"},\n    {\"safety_passed\": False, \"latency_ms\": 200.0, \"provider\": \"anthropic\"},\n]\n\nstats = calculate_statistics(entries)\nprint(stats[\"total_entries\"])  # 3\nprint(stats[\"safety_rate\"])    # 66.67\nprint(stats[\"providers\"])      # {\"openai\": 2, \"anthropic\": 1}\n</code></pre>"},{"location":"api/utils/#group_by_date","title":"group_by_date","text":"<pre><code>def group_by_date(\n    entries: Sequence[Any],\n    granularity: Literal[\"day\", \"week\", \"month\", \"quarter\", \"year\"] = \"day\",\n) -&gt; Dict[str, List[Any]]\n</code></pre> <p>Group audit entries by date with configurable granularity.</p> <p>Parameters:</p> Parameter Type Default Description <code>entries</code> <code>Sequence[Any]</code> Required Entries with timestamp <code>granularity</code> <code>str</code> <code>\"day\"</code> Time granularity <p>Granularity options:</p> Value Key Format Example <code>\"day\"</code> <code>YYYY-MM-DD</code> <code>2026-01-15</code> <code>\"week\"</code> <code>YYYY-WNN</code> <code>2026-W03</code> <code>\"month\"</code> <code>YYYY-MM</code> <code>2026-01</code> <code>\"quarter\"</code> <code>YYYY-Q#</code> <code>2026-Q1</code> <code>\"year\"</code> <code>YYYY</code> <code>2026</code> <p>Returns: Dictionary mapping period keys to lists of entries (sorted by key)</p> <p>Example:</p> <pre><code>from rotalabs_comply.utils import group_by_date\n\nentries = [\n    {\"timestamp\": \"2026-01-15T10:00:00\"},\n    {\"timestamp\": \"2026-01-15T14:00:00\"},\n    {\"timestamp\": \"2026-01-16T09:00:00\"},\n]\n\n# By day\ngrouped = group_by_date(entries, granularity=\"day\")\n# {'2026-01-15': [entry1, entry2], '2026-01-16': [entry3]}\n\n# By month\ngrouped = group_by_date(entries, granularity=\"month\")\n# {'2026-01': [entry1, entry2, entry3]}\n</code></pre>"},{"location":"api/utils/#severity_weight","title":"severity_weight","text":"<pre><code>def severity_weight(severity: Union[str, RiskLevel]) -&gt; int\n</code></pre> <p>Convert a severity level to a numeric weight for scoring.</p> <p>Parameters:</p> Parameter Type Description <code>severity</code> <code>Union[str, RiskLevel]</code> Severity level <p>Returns: Numeric weight (1-10)</p> <p>Weight mapping:</p> Severity Weight <code>critical</code> 10 <code>high</code> 5 <code>medium</code> 2 <code>low</code> 1 <code>info</code> 1 <p>Example:</p> <pre><code>from rotalabs_comply.utils import severity_weight\nfrom rotalabs_comply.frameworks.base import RiskLevel\n\nseverity_weight(\"critical\")        # 10\nseverity_weight(\"high\")            # 5\nseverity_weight(RiskLevel.MEDIUM)  # 2\n</code></pre>"},{"location":"api/utils/#json-serialization","title":"JSON Serialization","text":""},{"location":"api/utils/#json_serializer","title":"json_serializer","text":"<pre><code>def json_serializer(obj: Any) -&gt; Any\n</code></pre> <p>Custom JSON serializer for compliance-specific types.</p> <p>Handles: - <code>datetime</code> -&gt; ISO format string - <code>Enum</code> -&gt; <code>.value</code> - Dataclasses -&gt; dict via <code>asdict()</code> - Pydantic models -&gt; <code>.model_dump()</code> or <code>.dict()</code> - Objects with <code>to_dict()</code> method - Objects with <code>__dict__</code> - <code>bytes</code> -&gt; UTF-8 decoded string - <code>set</code> -&gt; list - <code>timedelta</code> -&gt; total seconds</p> <p>Raises: <code>TypeError</code> if object cannot be serialized</p> <p>Example:</p> <pre><code>import json\nfrom datetime import datetime\nfrom rotalabs_comply.utils import json_serializer\nfrom rotalabs_comply.frameworks.base import RiskLevel\n\ndata = {\n    \"timestamp\": datetime(2026, 1, 15, 10, 30),\n    \"status\": RiskLevel.HIGH,\n}\n\njson.dumps(data, default=json_serializer)\n# '{\"timestamp\": \"2026-01-15T10:30:00\", \"status\": \"high\"}'\n</code></pre>"},{"location":"api/utils/#dump_json","title":"dump_json","text":"<pre><code>def dump_json(obj: Any, **kwargs) -&gt; str\n</code></pre> <p>Serialize object to JSON string with compliance type support.</p> <p>Convenience wrapper around <code>json.dumps</code> with <code>json_serializer</code>.</p> <p>Parameters:</p> Parameter Type Description <code>obj</code> <code>Any</code> Object to serialize <code>**kwargs</code> Arguments passed to <code>json.dumps</code> <p>Example:</p> <pre><code>from datetime import datetime\nfrom rotalabs_comply.utils import dump_json\n\ndata = {\"created\": datetime(2026, 1, 15)}\nprint(dump_json(data))\n# {\"created\": \"2026-01-15T00:00:00\"}\n\nprint(dump_json(data, indent=2))\n# {\n#   \"created\": \"2026-01-15T00:00:00\"\n# }\n</code></pre>"},{"location":"api/utils/#load_json","title":"load_json","text":"<pre><code>def load_json(data: str) -&gt; Any\n</code></pre> <p>Parse JSON string with datetime restoration.</p> <p>Automatically converts ISO format strings back to datetime objects.</p> <p>Parameters:</p> Parameter Type Description <code>data</code> <code>str</code> JSON string to parse <p>Returns: Parsed Python object with datetimes restored</p> <p>Example:</p> <pre><code>from rotalabs_comply.utils import load_json\n\ndata = '{\"timestamp\": \"2026-01-15T10:30:00\"}'\nobj = load_json(data)\nprint(type(obj[\"timestamp\"]))\n# &lt;class 'datetime.datetime'&gt;\n</code></pre>"},{"location":"api/utils/#usage-examples","title":"Usage Examples","text":""},{"location":"api/utils/#complete-statistics-pipeline","title":"Complete Statistics Pipeline","text":"<pre><code>from datetime import datetime, timedelta\nfrom rotalabs_comply.utils import (\n    format_period,\n    calculate_statistics,\n    group_by_date,\n    dump_json,\n)\n\n# Sample entries\nentries = [...]\n\n# Calculate overall statistics\nstats = calculate_statistics(entries)\nprint(f\"Total: {stats['total_entries']}\")\nprint(f\"Safety Rate: {stats['safety_rate']}%\")\n\n# Group by time\ndaily = group_by_date(entries, granularity=\"day\")\nweekly = group_by_date(entries, granularity=\"week\")\n\n# Analyze trends\nfor period, period_entries in daily.items():\n    period_stats = calculate_statistics(period_entries)\n    print(f\"{period}: {period_stats['total_entries']} entries\")\n\n# Export to JSON\nreport = {\n    \"period\": format_period(\n        datetime(2026, 1, 1),\n        datetime(2026, 3, 31)\n    ),\n    \"statistics\": stats,\n    \"daily_breakdown\": {\n        period: calculate_statistics(entries)\n        for period, entries in daily.items()\n    },\n}\n\njson_output = dump_json(report, indent=2)\n</code></pre>"},{"location":"api/utils/#period-based-reporting","title":"Period-Based Reporting","text":"<pre><code>from rotalabs_comply.utils import format_period, parse_period\n\n# Format for display\nperiod_str = format_period(start, end)\nprint(f\"Reporting Period: {period_str}\")\n\n# Parse from user input\nuser_input = \"2026-Q1\"\nstart, end = parse_period(user_input)\n\n# Generate report for parsed period\nreport = await generator.generate(\n    period_start=start,\n    period_end=end,\n    profile=profile,\n)\n</code></pre>"},{"location":"tutorials/audit-logging/","title":"Audit Logging Tutorial","text":"<p>This tutorial walks through setting up comprehensive audit logging for AI systems, including encryption, storage backends, and retention management.</p>"},{"location":"tutorials/audit-logging/#overview","title":"Overview","text":"<p>Audit logging is the foundation of AI compliance. It captures interactions with AI systems in a way that supports:</p> <ul> <li>Accountability -- Track who did what, when, and why</li> <li>Verification -- Prove compliance through documented evidence</li> <li>Investigation -- Analyze incidents and patterns</li> <li>Reporting -- Generate compliance reports from audit data</li> </ul>"},{"location":"tutorials/audit-logging/#basic-audit-logging","title":"Basic Audit Logging","text":""},{"location":"tutorials/audit-logging/#simple-file-based-logging","title":"Simple File-Based Logging","text":"<p>The simplest setup uses file storage with hash-only mode (default):</p> <pre><code>import asyncio\nfrom rotalabs_comply import AuditLogger\n\nasync def main():\n    # Create logger with file storage\n    logger = AuditLogger(\"/var/log/ai-audit\")\n\n    # Log an AI interaction\n    entry_id = await logger.log(\n        input=\"What is the weather today?\",\n        output=\"I don't have access to real-time weather data.\",\n        provider=\"openai\",\n        model=\"gpt-4\",\n        safety_passed=True,\n        latency_ms=150.0,\n    )\n\n    print(f\"Logged entry: {entry_id}\")\n\nasyncio.run(main())\n</code></pre> <p>This creates JSONL files in <code>/var/log/ai-audit/</code> named by date (e.g., <code>audit_20260129.jsonl</code>).</p>"},{"location":"tutorials/audit-logging/#understanding-hash-only-mode","title":"Understanding Hash-Only Mode","text":"<p>By default, only SHA-256 hashes of content are stored:</p> <pre><code># What gets stored in hash-only mode\n{\n    \"id\": \"abc-123-def\",\n    \"timestamp\": \"2026-01-29T10:30:00\",\n    \"input_hash\": \"a0c299...\",  # SHA-256 of input\n    \"output_hash\": \"b1d388...\",  # SHA-256 of output\n    \"input_content\": null,       # Not stored\n    \"output_content\": null,      # Not stored\n    \"provider\": \"openai\",\n    \"model\": \"gpt-4\",\n    \"safety_passed\": true,\n    ...\n}\n</code></pre> <p>Benefits: - No sensitive data stored - Content can be verified later by comparing hashes - Compliant with data minimization principles</p>"},{"location":"tutorials/audit-logging/#encrypted-audit-logging","title":"Encrypted Audit Logging","text":"<p>When you need full audit trails but want to protect content:</p>"},{"location":"tutorials/audit-logging/#setting-up-encryption","title":"Setting Up Encryption","text":"<pre><code>import asyncio\nfrom rotalabs_comply import AuditLogger, EncryptionManager\n\nasync def main():\n    # Create encryption manager (generates key automatically)\n    encryption = EncryptionManager()\n\n    # IMPORTANT: Save the key securely!\n    key = encryption.get_key()\n    print(f\"Save this key: {key.decode()}\")\n\n    # Create logger with encryption\n    logger = AuditLogger(\n        storage=\"/var/log/ai-audit\",\n        encryption=encryption,\n        store_content=True,  # Enable content storage\n    )\n\n    # Log entries (content will be encrypted)\n    entry_id = await logger.log(\n        input=\"Tell me about patient records\",\n        output=\"Patient records are confidential...\",\n        provider=\"anthropic\",\n        model=\"claude-3-opus\",\n        safety_passed=True,\n        latency_ms=200.0,\n    )\n\n    # Later, retrieve and decrypt\n    entry = await logger.get_entry(entry_id)\n    if entry and entry.input_content:\n        original_input = logger.decrypt_content(entry.input_content)\n        print(f\"Original: {original_input}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"tutorials/audit-logging/#key-management-best-practices","title":"Key Management Best Practices","text":"<pre><code>import os\nfrom rotalabs_comply import EncryptionManager\n\n# Option 1: Generate and save to environment\nencryption = EncryptionManager()\nos.environ[\"AUDIT_ENCRYPTION_KEY\"] = encryption.get_key().decode()\n\n# Option 2: Load from environment\nkey = os.environ.get(\"AUDIT_ENCRYPTION_KEY\")\nif key:\n    encryption = EncryptionManager(key.encode())\nelse:\n    raise ValueError(\"Encryption key not configured\")\n\n# Option 3: Load from AWS Secrets Manager\nimport boto3\n\ndef get_encryption_key():\n    client = boto3.client(\"secretsmanager\")\n    response = client.get_secret_value(SecretId=\"audit-encryption-key\")\n    return response[\"SecretString\"].encode()\n\nencryption = EncryptionManager(get_encryption_key())\n</code></pre> <p>Never Commit Keys</p> <p>Never commit encryption keys to version control. Use environment variables, secrets managers, or secure key vaults.</p>"},{"location":"tutorials/audit-logging/#storage-backends","title":"Storage Backends","text":""},{"location":"tutorials/audit-logging/#file-storage","title":"File Storage","text":"<p>Local JSONL files with automatic rotation:</p> <pre><code>from rotalabs_comply import AuditLogger\nfrom rotalabs_comply.audit import FileStorage\n\n# Using path string (FileStorage created automatically)\nlogger = AuditLogger(\"/var/log/ai-audit\")\n\n# Or explicit FileStorage with custom rotation\nstorage = FileStorage(\n    path=\"/var/log/ai-audit\",\n    rotation_size_mb=50,  # Rotate at 50MB (default: 100MB)\n)\nlogger = AuditLogger(storage)\n</code></pre> <p>File structure: <pre><code>/var/log/ai-audit/\n\u251c\u2500\u2500 audit_20260128.jsonl\n\u251c\u2500\u2500 audit_20260128_001.jsonl  # Rotated file\n\u251c\u2500\u2500 audit_20260129.jsonl\n\u2514\u2500\u2500 ...\n</code></pre></p>"},{"location":"tutorials/audit-logging/#s3-storage","title":"S3 Storage","text":"<p>Cloud-native storage with AWS S3:</p> <pre><code>from rotalabs_comply import AuditLogger\nfrom rotalabs_comply.audit import S3Storage\n\n# Create S3 storage backend\nstorage = S3Storage(\n    bucket=\"my-audit-bucket\",\n    prefix=\"prod/ai-audit/\",\n    region=\"us-west-2\",\n)\n\n# Create logger\nlogger = AuditLogger(storage)\n\n# Log entries (stored as individual JSON files in S3)\nentry_id = await logger.log(\n    input=\"Query\",\n    output=\"Response\",\n    provider=\"openai\",\n    model=\"gpt-4\",\n    safety_passed=True,\n    latency_ms=100.0,\n)\n# Stored at: s3://my-audit-bucket/prod/ai-audit/2026-01-29/abc-123.json\n</code></pre> <p>S3 Lifecycle Policy for retention: <pre><code>{\n    \"Rules\": [\n        {\n            \"ID\": \"audit-log-retention\",\n            \"Status\": \"Enabled\",\n            \"Filter\": {\n                \"Prefix\": \"prod/ai-audit/\"\n            },\n            \"Expiration\": {\n                \"Days\": 365\n            }\n        }\n    ]\n}\n</code></pre></p>"},{"location":"tutorials/audit-logging/#memory-storage","title":"Memory Storage","text":"<p>For testing and development:</p> <pre><code>from rotalabs_comply import AuditLogger\nfrom rotalabs_comply.audit import MemoryStorage\n\n# Create memory storage with entry limit\nstorage = MemoryStorage(max_entries=1000)\nlogger = AuditLogger(storage)\n\n# Log entries (stored in memory)\nentry_id = await logger.log(\n    input=\"Test\",\n    output=\"Test response\",\n    provider=\"test\",\n    model=\"test-model\",\n    safety_passed=True,\n    latency_ms=10.0,\n)\n\n# Check entry count\ncount = await storage.count()\nprint(f\"Stored entries: {count}\")\n</code></pre>"},{"location":"tutorials/audit-logging/#comprehensive-metadata","title":"Comprehensive Metadata","text":""},{"location":"tutorials/audit-logging/#capturing-rich-context","title":"Capturing Rich Context","text":"<pre><code>entry_id = await logger.log(\n    # Core content\n    input=\"Summarize the quarterly report\",\n    output=\"Q4 showed 15% revenue growth...\",\n\n    # Provider information\n    provider=\"openai\",\n    model=\"gpt-4-turbo\",\n\n    # Session tracking\n    conversation_id=\"conv-abc-123\",  # Link related interactions\n\n    # Safety information\n    safety_passed=True,\n    detectors_triggered=[],  # Empty if all passed\n    block_reason=None,       # Set if blocked\n    alerts=[],               # Warning messages\n\n    # Performance\n    latency_ms=450.5,\n    input_tokens=150,\n    output_tokens=200,\n\n    # Custom metadata\n    metadata={\n        \"user_id\": \"user-123\",\n        \"session_id\": \"session-456\",\n        \"department\": \"finance\",\n        \"use_case\": \"report_summarization\",\n        \"sensitivity\": \"internal\",\n    },\n)\n</code></pre>"},{"location":"tutorials/audit-logging/#safety-event-logging","title":"Safety Event Logging","text":"<p>When safety checks fail:</p> <pre><code># Log a blocked request\nentry_id = await logger.log(\n    input=\"How to hack a bank?\",\n    output=\"\",  # Empty - request was blocked\n    provider=\"openai\",\n    model=\"gpt-4\",\n    safety_passed=False,\n    detectors_triggered=[\"harmful_content\", \"illegal_activity\"],\n    block_reason=\"Content violates safety policy\",\n    alerts=[\"Harmful request detected\", \"User warned\"],\n    latency_ms=50.0,\n    metadata={\n        \"user_id\": \"user-789\",\n        \"blocked_at\": \"input\",  # Blocked before API call\n    },\n)\n</code></pre>"},{"location":"tutorials/audit-logging/#querying-audit-logs","title":"Querying Audit Logs","text":""},{"location":"tutorials/audit-logging/#retrieve-single-entry","title":"Retrieve Single Entry","text":"<pre><code># Get entry by ID\nentry = await logger.get_entry(\"abc-123-def\")\n\nif entry:\n    print(f\"Provider: {entry.provider}\")\n    print(f\"Model: {entry.model}\")\n    print(f\"Safety passed: {entry.safety_passed}\")\n    print(f\"Latency: {entry.latency_ms}ms\")\n\n    # Decrypt content if encrypted\n    if entry.input_content and logger.encryption:\n        original = logger.decrypt_content(entry.input_content)\n        print(f\"Input: {original}\")\n</code></pre>"},{"location":"tutorials/audit-logging/#query-by-time-range","title":"Query by Time Range","text":"<pre><code>from datetime import datetime, timedelta\n\n# Get entries from the last 7 days\nend = datetime.utcnow()\nstart = end - timedelta(days=7)\n\nentries = await logger.get_entries(start, end)\n\nprint(f\"Found {len(entries)} entries\")\n\n# Analyze entries\nsafety_failures = sum(1 for e in entries if not e.safety_passed)\navg_latency = sum(e.latency_ms for e in entries) / len(entries)\n\nprint(f\"Safety failures: {safety_failures}\")\nprint(f\"Average latency: {avg_latency:.2f}ms\")\n</code></pre>"},{"location":"tutorials/audit-logging/#retention-management","title":"Retention Management","text":""},{"location":"tutorials/audit-logging/#automatic-cleanup","title":"Automatic Cleanup","text":"<pre><code>from rotalabs_comply import AuditLogger\n\n# Set retention period when creating logger\nlogger = AuditLogger(\n    storage=\"/var/log/ai-audit\",\n    retention_days=365,  # Keep for 1 year\n)\n\n# Manually trigger cleanup\ndeleted_count = await logger.cleanup_expired()\nprint(f\"Deleted {deleted_count} expired entries\")\n</code></pre>"},{"location":"tutorials/audit-logging/#scheduled-cleanup","title":"Scheduled Cleanup","text":"<p>For production, schedule cleanup as a background job:</p> <pre><code>import asyncio\nfrom datetime import datetime\n\nasync def cleanup_job():\n    while True:\n        # Run at 2 AM daily\n        now = datetime.now()\n        next_run = now.replace(hour=2, minute=0, second=0)\n        if next_run &lt;= now:\n            next_run = next_run + timedelta(days=1)\n\n        sleep_seconds = (next_run - now).total_seconds()\n        await asyncio.sleep(sleep_seconds)\n\n        # Run cleanup\n        deleted = await logger.cleanup_expired()\n        print(f\"[{datetime.now()}] Cleaned up {deleted} entries\")\n\n# Start as background task\nasyncio.create_task(cleanup_job())\n</code></pre>"},{"location":"tutorials/audit-logging/#integration-with-ai-frameworks","title":"Integration with AI Frameworks","text":""},{"location":"tutorials/audit-logging/#langchain-integration","title":"LangChain Integration","text":"<pre><code>from langchain_openai import ChatOpenAI\nfrom langchain_core.messages import HumanMessage\nfrom rotalabs_comply import AuditLogger, EncryptionManager\nimport time\n\nclass AuditedChatModel:\n    def __init__(self, model_name: str, logger: AuditLogger):\n        self.llm = ChatOpenAI(model=model_name)\n        self.logger = logger\n        self.model_name = model_name\n\n    async def invoke(self, messages, **kwargs):\n        # Extract input\n        input_text = messages[-1].content if messages else \"\"\n\n        # Call LLM and measure latency\n        start = time.perf_counter()\n        response = await self.llm.ainvoke(messages, **kwargs)\n        latency_ms = (time.perf_counter() - start) * 1000\n\n        # Log the interaction\n        await self.logger.log(\n            input=input_text,\n            output=response.content,\n            provider=\"openai\",\n            model=self.model_name,\n            safety_passed=True,\n            latency_ms=latency_ms,\n            metadata=kwargs,\n        )\n\n        return response\n\n# Usage\nencryption = EncryptionManager()\nlogger = AuditLogger(\"/var/log/ai-audit\", encryption=encryption, store_content=True)\nchat = AuditedChatModel(\"gpt-4\", logger)\n\nresponse = await chat.invoke([HumanMessage(content=\"Hello!\")])\n</code></pre>"},{"location":"tutorials/audit-logging/#openai-sdk-integration","title":"OpenAI SDK Integration","text":"<pre><code>import openai\nfrom rotalabs_comply import AuditLogger\nimport time\n\nclass AuditedOpenAI:\n    def __init__(self, logger: AuditLogger):\n        self.client = openai.AsyncOpenAI()\n        self.logger = logger\n\n    async def chat_completion(self, messages, model=\"gpt-4\", **kwargs):\n        # Extract input from last user message\n        input_text = next(\n            (m[\"content\"] for m in reversed(messages) if m[\"role\"] == \"user\"),\n            \"\"\n        )\n\n        start = time.perf_counter()\n        response = await self.client.chat.completions.create(\n            model=model,\n            messages=messages,\n            **kwargs\n        )\n        latency_ms = (time.perf_counter() - start) * 1000\n\n        output_text = response.choices[0].message.content\n\n        await self.logger.log(\n            input=input_text,\n            output=output_text,\n            provider=\"openai\",\n            model=model,\n            safety_passed=True,\n            latency_ms=latency_ms,\n            input_tokens=response.usage.prompt_tokens,\n            output_tokens=response.usage.completion_tokens,\n        )\n\n        return response\n\n# Usage\nlogger = AuditLogger(\"/var/log/ai-audit\")\nclient = AuditedOpenAI(logger)\n\nresponse = await client.chat_completion(\n    messages=[{\"role\": \"user\", \"content\": \"Hello!\"}]\n)\n</code></pre>"},{"location":"tutorials/audit-logging/#best-practices","title":"Best Practices","text":""},{"location":"tutorials/audit-logging/#1-always-log-safety-events","title":"1. Always Log Safety Events","text":"<pre><code># Log even when requests are blocked\ntry:\n    response = await llm.generate(prompt)\n    await logger.log(input=prompt, output=response, safety_passed=True, ...)\nexcept SafetyError as e:\n    await logger.log(\n        input=prompt,\n        output=\"\",\n        safety_passed=False,\n        block_reason=str(e),\n        ...\n    )\n    raise\n</code></pre>"},{"location":"tutorials/audit-logging/#2-use-structured-metadata","title":"2. Use Structured Metadata","text":"<pre><code># Consistent metadata schema\nmetadata = {\n    \"user_id\": str,        # Required\n    \"session_id\": str,     # Required\n    \"department\": str,     # Optional\n    \"use_case\": str,       # Optional\n    \"sensitivity\": str,    # Optional\n}\n</code></pre>"},{"location":"tutorials/audit-logging/#3-handle-encryption-key-rotation","title":"3. Handle Encryption Key Rotation","text":"<pre><code># Store key version with encrypted data\nmetadata = {\n    \"encryption_key_version\": \"v2\",\n}\n\n# Maintain key versions for decryption\nkeys = {\n    \"v1\": old_key,\n    \"v2\": current_key,\n}\n</code></pre>"},{"location":"tutorials/audit-logging/#4-monitor-audit-log-health","title":"4. Monitor Audit Log Health","text":"<pre><code>async def check_audit_health():\n    count = await storage.count()\n    entries = await logger.get_entries(\n        datetime.utcnow() - timedelta(hours=1),\n        datetime.utcnow()\n    )\n\n    metrics = {\n        \"total_entries\": count,\n        \"hourly_volume\": len(entries),\n        \"safety_failures\": sum(1 for e in entries if not e.safety_passed),\n    }\n\n    return metrics\n</code></pre>"},{"location":"tutorials/compliance-checking/","title":"Compliance Checking Tutorial","text":"<p>This tutorial covers using the built-in compliance frameworks (EU AI Act, SOC2, HIPAA, GDPR, NIST AI RMF, ISO 42001, and MAS FEAT) to evaluate AI system operations against regulatory requirements.</p>"},{"location":"tutorials/compliance-checking/#overview","title":"Overview","text":"<p>Compliance checking evaluates audit entries against regulatory frameworks to identify:</p> <ul> <li>Violations -- Specific rules that were not followed</li> <li>Risk levels -- Severity of identified issues</li> <li>Remediation -- Steps to fix violations</li> <li>Gaps -- Areas needing improvement</li> </ul>"},{"location":"tutorials/compliance-checking/#understanding-compliance-frameworks","title":"Understanding Compliance Frameworks","text":""},{"location":"tutorials/compliance-checking/#framework-structure","title":"Framework Structure","text":"<p>Each framework consists of rules organized by category:</p> <pre><code>Framework (e.g., EU AI Act)\n\u251c\u2500\u2500 Category: Transparency\n\u2502   \u251c\u2500\u2500 Rule: User Notification (EUAI-002)\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 Category: Oversight\n\u2502   \u251c\u2500\u2500 Rule: Human Oversight Documentation (EUAI-001)\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 Category: Risk Management\n\u2502   \u251c\u2500\u2500 Rule: Risk Assessment (EUAI-003)\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"tutorials/compliance-checking/#creating-audit-entries-for-compliance","title":"Creating Audit Entries for Compliance","text":"<p>Audit entries need specific fields for compliance checking:</p> <pre><code>from datetime import datetime\nfrom rotalabs_comply.frameworks.base import AuditEntry, RiskLevel\n\nentry = AuditEntry(\n    # Required identifiers\n    entry_id=\"entry-001\",\n    timestamp=datetime.utcnow(),\n\n    # Event classification\n    event_type=\"inference\",       # Type of operation\n    actor=\"user@example.com\",     # Who performed it\n    action=\"AI response generation\",\n\n    # Resource being accessed\n    resource=\"customer_support_model\",\n    system_id=\"prod-ai-001\",\n\n    # Risk and data classification\n    risk_level=RiskLevel.HIGH,\n    data_classification=\"confidential\",\n\n    # Compliance-relevant flags\n    user_notified=True,           # Transparency: user knows about AI\n    human_oversight=True,         # Oversight: human reviewed\n    error_handled=True,           # Robustness: errors handled gracefully\n    documentation_ref=\"DOC-001\",  # Documentation: reference to docs\n\n    # Framework-specific metadata\n    metadata={\n        # EU AI Act\n        \"risk_assessment_documented\": True,\n        \"accuracy_monitored\": True,\n        \"security_validated\": True,\n        \"data_governance_documented\": True,\n\n        # SOC2\n        \"access_controlled\": True,\n        \"monitored\": True,\n        \"change_approved\": True,\n\n        # HIPAA (if PHI involved)\n        \"encryption_enabled\": True,\n        \"authenticated\": True,\n        \"purpose_documented\": True,\n        \"minimum_necessary_applied\": True,\n    },\n)\n</code></pre>"},{"location":"tutorials/compliance-checking/#eu-ai-act-compliance","title":"EU AI Act Compliance","text":"<p>The EU AI Act (2024) regulates AI systems based on risk level. The framework focuses on high-risk system requirements.</p>"},{"location":"tutorials/compliance-checking/#rule-categories","title":"Rule Categories","text":"Category Focus <code>transparency</code> User notification of AI interaction <code>oversight</code> Human oversight documentation <code>risk_management</code> Risk assessment, error handling, accuracy <code>documentation</code> Technical and data governance docs <code>security</code> Cybersecurity measures"},{"location":"tutorials/compliance-checking/#basic-usage","title":"Basic Usage","text":"<pre><code>import asyncio\nfrom datetime import datetime\nfrom rotalabs_comply.frameworks.eu_ai_act import EUAIActFramework\nfrom rotalabs_comply.frameworks.base import AuditEntry, ComplianceProfile, RiskLevel\n\nasync def main():\n    # Create framework\n    framework = EUAIActFramework()\n\n    # List available rules\n    print(\"EU AI Act Rules:\")\n    for rule in framework.rules:\n        print(f\"  {rule.rule_id}: {rule.name} [{rule.severity.value}]\")\n\n    # Create an audit entry\n    entry = AuditEntry(\n        entry_id=\"eu-test-001\",\n        timestamp=datetime.utcnow(),\n        event_type=\"inference\",\n        actor=\"api-user\",\n        action=\"AI chatbot response\",\n        risk_level=RiskLevel.HIGH,\n        user_notified=True,\n        human_oversight=True,\n        metadata={\n            \"risk_assessment_documented\": True,\n            \"security_validated\": True,\n        },\n    )\n\n    # Create profile\n    profile = ComplianceProfile(\n        profile_id=\"eu-ai-profile\",\n        name=\"EU AI Act Compliance\",\n        enabled_frameworks=[\"EU AI Act\"],\n    )\n\n    # Check compliance\n    result = await framework.check(entry, profile)\n\n    print(f\"\\nCompliance Check Result:\")\n    print(f\"  Compliant: {result.is_compliant}\")\n    print(f\"  Rules checked: {result.rules_checked}\")\n    print(f\"  Rules passed: {result.rules_passed}\")\n\n    if result.violations:\n        print(f\"\\nViolations ({len(result.violations)}):\")\n        for v in result.violations:\n            print(f\"  [{v.severity.value.upper()}] {v.rule_name}\")\n            print(f\"    Evidence: {v.evidence}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"tutorials/compliance-checking/#key-requirements","title":"Key Requirements","text":"<p>EUAI-001: Human Oversight <pre><code># For high-risk operations, human_oversight must be True\nentry = AuditEntry(\n    ...,\n    risk_level=RiskLevel.HIGH,\n    human_oversight=True,  # Required for high-risk\n)\n</code></pre></p> <p>EUAI-002: Transparency <pre><code># For user-facing interactions, user must be notified\nentry = AuditEntry(\n    ...,\n    event_type=\"inference\",  # User-facing event\n    user_notified=True,      # User knows it's AI\n)\n</code></pre></p> <p>EUAI-003: Risk Assessment <pre><code># High-risk operations need documented risk assessment\nentry = AuditEntry(\n    ...,\n    risk_level=RiskLevel.HIGH,\n    metadata={\"risk_assessment_documented\": True},\n)\n</code></pre></p>"},{"location":"tutorials/compliance-checking/#soc2-compliance","title":"SOC2 Compliance","text":"<p>SOC2 Type II evaluates operational effectiveness of security controls based on AICPA Trust Service Criteria.</p>"},{"location":"tutorials/compliance-checking/#trust-service-categories","title":"Trust Service Categories","text":"Category Code Focus Security CC Access controls, monitoring, incident response Availability A SLA monitoring, recovery objectives Processing Integrity PI Input validation, data accuracy Confidentiality C Data classification Privacy P Privacy notices for personal data"},{"location":"tutorials/compliance-checking/#basic-usage_1","title":"Basic Usage","text":"<pre><code>import asyncio\nfrom datetime import datetime\nfrom rotalabs_comply.frameworks.soc2 import SOC2Framework\nfrom rotalabs_comply.frameworks.base import AuditEntry, ComplianceProfile, RiskLevel\n\nasync def main():\n    framework = SOC2Framework()\n\n    # List categories\n    categories = framework.list_categories()\n    print(f\"SOC2 Categories: {categories}\")\n\n    # Create audit entry with SOC2-relevant metadata\n    entry = AuditEntry(\n        entry_id=\"soc2-test-001\",\n        timestamp=datetime.utcnow(),\n        event_type=\"data_access\",\n        actor=\"admin@company.com\",  # Authenticated user\n        action=\"Query customer database\",\n        system_id=\"prod-db-001\",\n        data_classification=\"confidential\",\n        metadata={\n            \"access_controlled\": True,\n            \"monitored\": True,\n            \"change_approved\": True,\n        },\n    )\n\n    profile = ComplianceProfile(\n        profile_id=\"soc2-profile\",\n        name=\"SOC2 Compliance\",\n        enabled_frameworks=[\"SOC2 Type II\"],\n    )\n\n    result = await framework.check(entry, profile)\n\n    print(f\"\\nSOC2 Check Result:\")\n    print(f\"  Compliant: {result.is_compliant}\")\n    print(f\"  Violations: {len(result.violations)}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"tutorials/compliance-checking/#key-requirements_1","title":"Key Requirements","text":"<p>CC6.1: Logical Access Controls <pre><code># All access events need authentication and authorization\nentry = AuditEntry(\n    ...,\n    event_type=\"data_access\",\n    actor=\"user@company.com\",  # Must be authenticated (not \"anonymous\")\n    metadata={\"access_controlled\": True},\n)\n</code></pre></p> <p>CC6.3: Change Management <pre><code># Changes need approval and documentation\nentry = AuditEntry(\n    ...,\n    event_type=\"deployment\",\n    documentation_ref=\"CHG-001\",  # Change ticket\n    metadata={\"change_approved\": True},\n)\n</code></pre></p> <p>C1.1: Confidentiality Classification <pre><code># Data must be classified\nentry = AuditEntry(\n    ...,\n    event_type=\"data_access\",\n    data_classification=\"confidential\",  # Not \"unclassified\"\n)\n</code></pre></p>"},{"location":"tutorials/compliance-checking/#hipaa-compliance","title":"HIPAA Compliance","text":"<p>HIPAA applies to systems processing Protected Health Information (PHI). Rules are only evaluated for PHI-related entries.</p>"},{"location":"tutorials/compliance-checking/#phi-detection","title":"PHI Detection","text":"<p>The framework identifies PHI-related entries by data classification:</p> <pre><code># These classifications trigger HIPAA evaluation\nphi_classifications = {\n    \"PHI\", \"ePHI\", \"protected_health_information\",\n    \"health_data\", \"medical\", \"clinical\"\n}\n</code></pre>"},{"location":"tutorials/compliance-checking/#basic-usage_2","title":"Basic Usage","text":"<pre><code>import asyncio\nfrom datetime import datetime\nfrom rotalabs_comply.frameworks.hipaa import HIPAAFramework\nfrom rotalabs_comply.frameworks.base import AuditEntry, ComplianceProfile, RiskLevel\n\nasync def main():\n    framework = HIPAAFramework()\n\n    # PHI-related entry (HIPAA rules apply)\n    phi_entry = AuditEntry(\n        entry_id=\"hipaa-test-001\",\n        timestamp=datetime.utcnow(),\n        event_type=\"inference\",\n        actor=\"doctor@hospital.com\",\n        action=\"AI diagnostic assistance\",\n        data_classification=\"PHI\",  # Triggers HIPAA\n        metadata={\n            \"access_controlled\": True,\n            \"encryption_enabled\": True,\n            \"authenticated\": True,\n            \"purpose_documented\": True,\n            \"minimum_necessary_applied\": True,\n        },\n    )\n\n    # Non-PHI entry (HIPAA rules don't apply)\n    non_phi_entry = AuditEntry(\n        entry_id=\"hipaa-test-002\",\n        timestamp=datetime.utcnow(),\n        event_type=\"inference\",\n        actor=\"user@company.com\",\n        action=\"General AI query\",\n        data_classification=\"internal\",  # Not PHI\n    )\n\n    profile = ComplianceProfile(\n        profile_id=\"hipaa-profile\",\n        name=\"HIPAA Compliance\",\n        enabled_frameworks=[\"HIPAA\"],\n    )\n\n    # Check PHI entry\n    result1 = await framework.check(phi_entry, profile)\n    print(f\"PHI Entry - Rules checked: {result1.rules_checked}\")\n\n    # Check non-PHI entry\n    result2 = await framework.check(non_phi_entry, profile)\n    print(f\"Non-PHI Entry - Rules checked: {result2.rules_checked}\")  # 0\n\nasyncio.run(main())\n</code></pre>"},{"location":"tutorials/compliance-checking/#key-requirements_2","title":"Key Requirements","text":"<p>164.312(a): Access Control <pre><code># PHI access requires authentication, authorization, and encryption\nentry = AuditEntry(\n    ...,\n    data_classification=\"PHI\",\n    actor=\"nurse@hospital.com\",  # Authenticated\n    metadata={\n        \"access_controlled\": True,\n        \"encryption_enabled\": True,\n    },\n)\n</code></pre></p> <p>164.312(d): Authentication <pre><code># Strong authentication required, MFA for high-risk\nentry = AuditEntry(\n    ...,\n    event_type=\"bulk_access\",  # High-risk operation\n    data_classification=\"PHI\",\n    metadata={\n        \"authenticated\": True,\n        \"mfa_verified\": True,  # Required for high-risk\n    },\n)\n</code></pre></p> <p>164.502: Minimum Necessary <pre><code># PHI use must be limited to minimum necessary\nentry = AuditEntry(\n    ...,\n    data_classification=\"PHI\",\n    metadata={\n        \"purpose_documented\": True,\n        \"minimum_necessary_applied\": True,\n    },\n)\n</code></pre></p>"},{"location":"tutorials/compliance-checking/#multi-framework-compliance","title":"Multi-Framework Compliance","text":"<p>Check against multiple frameworks simultaneously:</p> <pre><code>import asyncio\nfrom datetime import datetime\nfrom rotalabs_comply.frameworks.eu_ai_act import EUAIActFramework\nfrom rotalabs_comply.frameworks.soc2 import SOC2Framework\nfrom rotalabs_comply.frameworks.hipaa import HIPAAFramework\nfrom rotalabs_comply.frameworks.base import AuditEntry, ComplianceProfile, RiskLevel\n\nasync def main():\n    # Initialize all frameworks\n    frameworks = {\n        \"eu_ai_act\": EUAIActFramework(),\n        \"soc2\": SOC2Framework(),\n        \"hipaa\": HIPAAFramework(),\n    }\n\n    # Create comprehensive entry\n    entry = AuditEntry(\n        entry_id=\"multi-test-001\",\n        timestamp=datetime.utcnow(),\n        event_type=\"inference\",\n        actor=\"clinician@hospital.eu\",\n        action=\"AI-assisted diagnosis\",\n        system_id=\"diag-ai-001\",\n        risk_level=RiskLevel.HIGH,\n        data_classification=\"PHI\",  # HIPAA relevant\n        user_notified=True,\n        human_oversight=True,\n        documentation_ref=\"DOC-DIAG-001\",\n        metadata={\n            # EU AI Act\n            \"risk_assessment_documented\": True,\n            \"accuracy_monitored\": True,\n            \"security_validated\": True,\n\n            # SOC2\n            \"access_controlled\": True,\n            \"monitored\": True,\n\n            # HIPAA\n            \"encryption_enabled\": True,\n            \"authenticated\": True,\n            \"purpose_documented\": True,\n            \"minimum_necessary_applied\": True,\n        },\n    )\n\n    profile = ComplianceProfile(\n        profile_id=\"multi-framework\",\n        name=\"Multi-Framework Compliance\",\n        enabled_frameworks=[\"EU AI Act\", \"SOC2 Type II\", \"HIPAA\"],\n    )\n\n    # Check against all frameworks\n    all_violations = []\n    for name, framework in frameworks.items():\n        result = await framework.check(entry, profile)\n        all_violations.extend(result.violations)\n        print(f\"\\n{name}:\")\n        print(f\"  Compliant: {result.is_compliant}\")\n        print(f\"  Violations: {len(result.violations)}\")\n\n    # Overall summary\n    print(f\"\\n=== Overall Summary ===\")\n    print(f\"Total violations: {len(all_violations)}\")\n\n    # Group by severity\n    for severity in [\"critical\", \"high\", \"medium\", \"low\"]:\n        count = sum(\n            1 for v in all_violations\n            if v.severity.value.lower() == severity\n        )\n        if count &gt; 0:\n            print(f\"  {severity.upper()}: {count}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"tutorials/compliance-checking/#gdpr-compliance","title":"GDPR Compliance","text":"<p>The GDPR framework enforces data protection requirements for processing personal data of EU residents.</p>"},{"location":"tutorials/compliance-checking/#basic-usage_3","title":"Basic Usage","text":"<pre><code>import asyncio\nfrom datetime import datetime\nfrom rotalabs_comply.frameworks.gdpr import GDPRFramework\nfrom rotalabs_comply.frameworks.base import AuditEntry, ComplianceProfile, RiskLevel\n\nasync def main():\n    framework = GDPRFramework()\n\n    # List categories\n    categories = framework.list_categories()\n    print(f\"GDPR Categories: {categories}\")\n\n    # Create audit entry for personal data processing\n    entry = AuditEntry(\n        entry_id=\"gdpr-test-001\",\n        timestamp=datetime.utcnow(),\n        event_type=\"data_processing\",\n        actor=\"analyst@company.eu\",\n        action=\"Process customer profiles\",\n        data_classification=\"pii\",  # Triggers GDPR rules\n        metadata={\n            # Article 5 &amp; 6: Lawful basis\n            \"lawful_basis_documented\": True,\n            \"lawful_basis\": \"consent\",\n            \"purpose_documented\": True,\n\n            # Article 7: Consent conditions\n            \"consent_recorded\": True,\n            \"consent_specific\": True,\n            \"consent_informed\": True,\n\n            # Article 32: Security\n            \"encryption_applied\": True,\n            \"access_controlled\": True,\n        },\n    )\n\n    profile = ComplianceProfile(\n        profile_id=\"gdpr-profile\",\n        name=\"GDPR Compliance\",\n        enabled_frameworks=[\"GDPR\"],\n    )\n\n    result = await framework.check(entry, profile)\n\n    print(f\"\\nGDPR Check Result:\")\n    print(f\"  Compliant: {result.is_compliant}\")\n    print(f\"  Violations: {len(result.violations)}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"tutorials/compliance-checking/#automated-decision-making-article-22","title":"Automated Decision-Making (Article 22)","text":"<pre><code># Entry for AI-driven automated decision with significant effects\nentry = AuditEntry(\n    entry_id=\"gdpr-ai-001\",\n    timestamp=datetime.utcnow(),\n    event_type=\"automated_decision\",\n    actor=\"ai-system@company.eu\",\n    action=\"Credit eligibility determination\",\n    data_classification=\"personal\",\n    metadata={\n        \"significant_effect\": True,  # Triggers Article 22\n        \"human_intervention_available\": True,\n        \"right_to_contest_enabled\": True,\n        \"logic_explained\": True,\n    },\n)\n</code></pre>"},{"location":"tutorials/compliance-checking/#nist-ai-rmf-compliance","title":"NIST AI RMF Compliance","text":"<p>The NIST AI Risk Management Framework provides voluntary guidance for managing AI risks across the lifecycle.</p>"},{"location":"tutorials/compliance-checking/#basic-usage_4","title":"Basic Usage","text":"<pre><code>import asyncio\nfrom datetime import datetime\nfrom rotalabs_comply.frameworks.nist_ai_rmf import NISTAIRMFFramework\nfrom rotalabs_comply.frameworks.base import AuditEntry, ComplianceProfile, RiskLevel\n\nasync def main():\n    framework = NISTAIRMFFramework()\n\n    # Create entry for high-risk AI deployment\n    entry = AuditEntry(\n        entry_id=\"nist-test-001\",\n        timestamp=datetime.utcnow(),\n        event_type=\"deployment\",\n        actor=\"mlops@company.com\",\n        action=\"Deploy production model\",\n        risk_level=RiskLevel.HIGH,\n        documentation_ref=\"DOC-DEPLOY-001\",\n        metadata={\n            # GOVERN function\n            \"governance_documented\": True,\n            \"governance_approval\": True,\n            \"accountability_documented\": True,\n\n            # MAP function\n            \"system_context_documented\": True,\n            \"ai_categorization_documented\": True,\n            \"intended_use_documented\": True,\n            \"benefit_cost_assessed\": True,\n\n            # MEASURE function\n            \"trustworthiness_evaluated\": True,\n            \"risk_tracked\": True,\n\n            # MANAGE function\n            \"deployment_decision_documented\": True,\n            \"deployment_approved\": True,\n            \"risk_assessment_documented\": True,\n        },\n    )\n\n    profile = ComplianceProfile(\n        profile_id=\"nist-profile\",\n        name=\"NIST AI RMF Compliance\",\n    )\n\n    result = await framework.check(entry, profile)\n\n    print(f\"\\nNIST AI RMF Check Result:\")\n    print(f\"  Compliant: {result.is_compliant}\")\n    print(f\"  Rules checked: {result.rules_checked}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"tutorials/compliance-checking/#third-party-ai-risk-management","title":"Third-Party AI Risk Management","text":"<pre><code># Entry for third-party AI service integration\nentry = AuditEntry(\n    entry_id=\"nist-3p-001\",\n    timestamp=datetime.utcnow(),\n    event_type=\"api_call\",\n    actor=\"integration@company.com\",\n    action=\"Call external AI API\",\n    metadata={\n        \"third_party_assessed\": True,\n        \"vendor_agreement_documented\": True,\n        \"third_party_risks_mapped\": True,\n        \"component_inventory_updated\": True,\n    },\n)\n</code></pre>"},{"location":"tutorials/compliance-checking/#iso-42001-compliance","title":"ISO 42001 Compliance","text":"<p>ISO/IEC 42001:2023 establishes requirements for AI Management Systems (AIMS).</p>"},{"location":"tutorials/compliance-checking/#basic-usage_5","title":"Basic Usage","text":"<pre><code>import asyncio\nfrom datetime import datetime\nfrom rotalabs_comply.frameworks.iso_42001 import ISO42001Framework\nfrom rotalabs_comply.frameworks.base import AuditEntry, ComplianceProfile, RiskLevel\n\nasync def main():\n    framework = ISO42001Framework()\n\n    # Create entry for AI system deployment\n    entry = AuditEntry(\n        entry_id=\"iso-test-001\",\n        timestamp=datetime.utcnow(),\n        event_type=\"deployment\",\n        actor=\"ai-engineer@company.com\",\n        action=\"Deploy AI system\",\n        risk_level=RiskLevel.HIGH,\n        metadata={\n            # Clause 4: Context\n            \"organizational_context_documented\": True,\n            \"stakeholders_identified\": True,\n            \"aims_scope_defined\": True,\n            \"within_aims_scope\": True,\n\n            # Clause 5: Leadership\n            \"leadership_approved\": True,\n            \"ai_policy_compliant\": True,\n            \"role_defined\": True,\n            \"authorized_role\": True,\n\n            # Clause 6: Planning\n            \"risk_assessment_documented\": True,\n            \"ai_objectives_aligned\": True,\n            \"impact_assessment_documented\": True,\n\n            # Clause 7: Support\n            \"resources_allocated\": True,\n            \"competence_verified\": True,\n\n            # Clause 8: Operation\n            \"operational_plan_documented\": True,\n            \"lifecycle_process_followed\": True,\n        },\n    )\n\n    profile = ComplianceProfile(\n        profile_id=\"iso-profile\",\n        name=\"ISO 42001 Compliance\",\n    )\n\n    result = await framework.check(entry, profile)\n\n    print(f\"\\nISO 42001 Check Result:\")\n    print(f\"  Compliant: {result.is_compliant}\")\n    print(f\"  Rules checked: {result.rules_checked}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"tutorials/compliance-checking/#continual-improvement-clause-10","title":"Continual Improvement (Clause 10)","text":"<pre><code># Entry for handling nonconformity\nentry = AuditEntry(\n    entry_id=\"iso-nc-001\",\n    timestamp=datetime.utcnow(),\n    event_type=\"nonconformity\",\n    actor=\"quality@company.com\",\n    action=\"Address audit finding\",\n    metadata={\n        \"corrective_action_documented\": True,\n    },\n)\n</code></pre>"},{"location":"tutorials/compliance-checking/#mas-feat-compliance","title":"MAS FEAT Compliance","text":"<p>The MAS FEAT framework provides AI governance requirements for financial institutions in Singapore.</p>"},{"location":"tutorials/compliance-checking/#basic-usage_6","title":"Basic Usage","text":"<pre><code>import asyncio\nfrom datetime import datetime\nfrom rotalabs_comply.frameworks.mas import MASFramework\nfrom rotalabs_comply.frameworks.base import AuditEntry, ComplianceProfile, RiskLevel\n\nasync def main():\n    framework = MASFramework()\n\n    # Create entry for customer-facing AI decision\n    entry = AuditEntry(\n        entry_id=\"mas-test-001\",\n        timestamp=datetime.utcnow(),\n        event_type=\"credit_decision\",\n        actor=\"credit-analyst@bank.sg\",\n        action=\"AI credit scoring\",\n        risk_level=RiskLevel.HIGH,\n        data_classification=\"customer_data\",\n        user_notified=True,\n        human_oversight=True,\n        error_handled=True,\n        metadata={\n            # Fairness\n            \"fairness_assessed\": True,\n            \"bias_mitigation_documented\": True,\n\n            # Ethics\n            \"ethics_reviewed\": True,\n            \"ethics_aligned\": True,\n\n            # Accountability\n            \"accountable_owner\": \"credit-risk-team\",\n            \"accountability_documented\": True,\n\n            # Transparency\n            \"explanation_available\": True,\n\n            # Model Risk Management\n            \"development_standards_followed\": True,\n            \"validation_completed\": True,\n            \"monitoring_enabled\": True,\n            \"model_inventory_id\": \"MODEL-CS-001\",\n\n            # Data Governance\n            \"data_quality_validated\": True,\n            \"privacy_compliant\": True,\n        },\n    )\n\n    profile = ComplianceProfile(\n        profile_id=\"mas-profile\",\n        name=\"MAS FEAT Compliance\",\n    )\n\n    result = await framework.check(entry, profile)\n\n    print(f\"\\nMAS FEAT Check Result:\")\n    print(f\"  Compliant: {result.is_compliant}\")\n    print(f\"  Rules checked: {result.rules_checked}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"tutorials/compliance-checking/#model-development-standards","title":"Model Development Standards","text":"<pre><code># Entry for model training\nentry = AuditEntry(\n    entry_id=\"mas-train-001\",\n    timestamp=datetime.utcnow(),\n    event_type=\"training\",\n    actor=\"data-scientist@bank.sg\",\n    action=\"Train credit scoring model\",\n    documentation_ref=\"DOC-MODEL-001\",\n    metadata={\n        \"development_standards_followed\": True,\n        \"bias_mitigation_documented\": True,\n        \"data_quality_validated\": True,\n        \"lineage_documented\": True,\n    },\n)\n</code></pre>"},{"location":"tutorials/compliance-checking/#comprehensive-multi-framework-compliance","title":"Comprehensive Multi-Framework Compliance","text":"<p>For organizations subject to multiple regulations, check against all relevant frameworks:</p> <pre><code>import asyncio\nfrom datetime import datetime\nfrom rotalabs_comply.frameworks.eu_ai_act import EUAIActFramework\nfrom rotalabs_comply.frameworks.soc2 import SOC2Framework\nfrom rotalabs_comply.frameworks.hipaa import HIPAAFramework\nfrom rotalabs_comply.frameworks.gdpr import GDPRFramework\nfrom rotalabs_comply.frameworks.nist_ai_rmf import NISTAIRMFFramework\nfrom rotalabs_comply.frameworks.iso_42001 import ISO42001Framework\nfrom rotalabs_comply.frameworks.mas import MASFramework\nfrom rotalabs_comply.frameworks.base import AuditEntry, ComplianceProfile, RiskLevel\n\nasync def comprehensive_compliance_check():\n    # Initialize all frameworks\n    frameworks = {\n        \"EU AI Act\": EUAIActFramework(),\n        \"SOC2\": SOC2Framework(),\n        \"HIPAA\": HIPAAFramework(),\n        \"GDPR\": GDPRFramework(),\n        \"NIST AI RMF\": NISTAIRMFFramework(),\n        \"ISO 42001\": ISO42001Framework(),\n        \"MAS FEAT\": MASFramework(),\n    }\n\n    # Create a comprehensive audit entry with metadata for all frameworks\n    entry = AuditEntry(\n        entry_id=\"comprehensive-001\",\n        timestamp=datetime.utcnow(),\n        event_type=\"inference\",\n        actor=\"system-user@global-bank.com\",\n        action=\"AI-driven customer service\",\n        system_id=\"cs-ai-001\",\n        risk_level=RiskLevel.HIGH,\n        data_classification=\"pii\",\n        user_notified=True,\n        human_oversight=True,\n        error_handled=True,\n        documentation_ref=\"DOC-CS-001\",\n        metadata={\n            # EU AI Act\n            \"risk_assessment_documented\": True,\n            \"accuracy_monitored\": True,\n            \"security_validated\": True,\n\n            # SOC2\n            \"access_controlled\": True,\n            \"monitored\": True,\n\n            # HIPAA (if PHI involved)\n            \"encryption_enabled\": True,\n            \"authenticated\": True,\n            \"purpose_documented\": True,\n            \"minimum_necessary_applied\": True,\n\n            # GDPR\n            \"lawful_basis_documented\": True,\n            \"lawful_basis\": \"legitimate_interests\",\n\n            # NIST AI RMF\n            \"governance_documented\": True,\n            \"trustworthiness_evaluated\": True,\n            \"risk_tracked\": True,\n\n            # ISO 42001\n            \"ai_policy_compliant\": True,\n            \"lifecycle_process_followed\": True,\n\n            # MAS FEAT\n            \"fairness_assessed\": True,\n            \"explanation_available\": True,\n            \"monitoring_enabled\": True,\n            \"model_inventory_id\": \"MODEL-001\",\n            \"privacy_compliant\": True,\n        },\n    )\n\n    profile = ComplianceProfile(\n        profile_id=\"comprehensive-profile\",\n        name=\"Comprehensive Compliance\",\n    )\n\n    # Check against all frameworks\n    results = {}\n    all_violations = []\n\n    for name, framework in frameworks.items():\n        result = await framework.check(entry, profile)\n        results[name] = result\n        all_violations.extend(result.violations)\n\n    # Summary report\n    print(\"=\" * 60)\n    print(\"COMPREHENSIVE COMPLIANCE REPORT\")\n    print(\"=\" * 60)\n\n    for name, result in results.items():\n        status = \"PASS\" if result.is_compliant else \"FAIL\"\n        print(f\"\\n{name}: {status}\")\n        print(f\"  Rules checked: {result.rules_checked}\")\n        print(f\"  Rules passed: {result.rules_passed}\")\n        if result.violations:\n            print(f\"  Violations:\")\n            for v in result.violations:\n                print(f\"    - [{v.severity.value.upper()}] {v.rule_id}: {v.rule_name}\")\n\n    print(\"\\n\" + \"=\" * 60)\n    print(f\"TOTAL VIOLATIONS: {len(all_violations)}\")\n    print(\"=\" * 60)\n\nasyncio.run(comprehensive_compliance_check())\n</code></pre>"},{"location":"tutorials/compliance-checking/#filtering-compliance-checks","title":"Filtering Compliance Checks","text":""},{"location":"tutorials/compliance-checking/#by-category","title":"By Category","text":"<pre><code># Only check security-related rules\nprofile = ComplianceProfile(\n    profile_id=\"security-only\",\n    name=\"Security Focus\",\n    enabled_categories=[\"security\", \"access_control\"],\n)\n</code></pre>"},{"location":"tutorials/compliance-checking/#by-severity","title":"By Severity","text":"<pre><code># Only report medium severity and above\nprofile = ComplianceProfile(\n    profile_id=\"high-priority\",\n    name=\"High Priority Only\",\n    min_severity=RiskLevel.MEDIUM,\n)\n</code></pre>"},{"location":"tutorials/compliance-checking/#exclude-specific-rules","title":"Exclude Specific Rules","text":"<pre><code># Skip specific rules\nprofile = ComplianceProfile(\n    profile_id=\"customized\",\n    name=\"Custom Profile\",\n    excluded_rules=[\"EUAI-007\", \"SOC2-CC8.1\"],\n)\n</code></pre>"},{"location":"tutorials/compliance-checking/#handling-violations","title":"Handling Violations","text":""},{"location":"tutorials/compliance-checking/#analyzing-violations","title":"Analyzing Violations","text":"<pre><code>from collections import defaultdict\n\n# Group violations by framework\nby_framework = defaultdict(list)\nfor v in all_violations:\n    by_framework[v.framework].append(v)\n\n# Group by severity\nby_severity = defaultdict(list)\nfor v in all_violations:\n    by_severity[v.severity.value].append(v)\n\n# Group by category\nby_category = defaultdict(list)\nfor v in all_violations:\n    by_category[v.category].append(v)\n</code></pre>"},{"location":"tutorials/compliance-checking/#remediation-tracking","title":"Remediation Tracking","text":"<pre><code># Track remediation progress\nremediations = {}\n\nfor violation in all_violations:\n    remediations[violation.rule_id] = {\n        \"rule_name\": violation.rule_name,\n        \"severity\": violation.severity.value,\n        \"remediation\": violation.remediation,\n        \"status\": \"pending\",\n        \"assigned_to\": None,\n        \"due_date\": None,\n    }\n\n# Assign and track\nremediations[\"EUAI-001\"][\"assigned_to\"] = \"compliance-team\"\nremediations[\"EUAI-001\"][\"due_date\"] = \"2026-02-15\"\nremediations[\"EUAI-001\"][\"status\"] = \"in_progress\"\n</code></pre>"},{"location":"tutorials/compliance-checking/#custom-rule-checks","title":"Custom Rule Checks","text":"<p>Add custom validation logic to rules:</p> <pre><code>from rotalabs_comply.frameworks.base import ComplianceRule, RiskLevel\n\ndef check_custom_requirement(entry):\n    \"\"\"Custom check: require specific metadata field.\"\"\"\n    return entry.metadata.get(\"custom_approval\", False)\n\ncustom_rule = ComplianceRule(\n    rule_id=\"CUSTOM-001\",\n    name=\"Custom Approval Required\",\n    description=\"All AI operations require custom approval flag\",\n    severity=RiskLevel.MEDIUM,\n    category=\"custom\",\n    check_fn=check_custom_requirement,  # Custom check function\n    remediation=\"Set custom_approval=True in metadata\",\n)\n</code></pre>"},{"location":"tutorials/compliance-checking/#best-practices","title":"Best Practices","text":""},{"location":"tutorials/compliance-checking/#1-document-everything","title":"1. Document Everything","text":"<pre><code># Ensure documentation references exist for significant events\nsignificant_events = [\"deployment\", \"training\", \"model_update\"]\nif entry.event_type in significant_events:\n    assert entry.documentation_ref, \"Documentation required\"\n</code></pre>"},{"location":"tutorials/compliance-checking/#2-consistent-metadata-schema","title":"2. Consistent Metadata Schema","text":"<pre><code># Define required metadata by framework\nrequired_metadata = {\n    \"eu_ai_act\": [\"risk_assessment_documented\"],\n    \"soc2\": [\"access_controlled\", \"monitored\"],\n    \"hipaa\": [\"encryption_enabled\", \"authenticated\"],\n}\n\n# Validate before logging\ndef validate_metadata(entry, frameworks):\n    for fw in frameworks:\n        for field in required_metadata.get(fw, []):\n            if field not in entry.metadata:\n                raise ValueError(f\"Missing {field} for {fw}\")\n</code></pre>"},{"location":"tutorials/compliance-checking/#3-regular-compliance-scans","title":"3. Regular Compliance Scans","text":"<pre><code>async def daily_compliance_scan(logger, frameworks, profile):\n    \"\"\"Run daily compliance scan on recent entries.\"\"\"\n    from datetime import datetime, timedelta\n\n    end = datetime.utcnow()\n    start = end - timedelta(days=1)\n\n    entries = await logger.get_entries(start, end)\n\n    all_violations = []\n    for entry in entries:\n        for fw in frameworks.values():\n            result = await fw.check(entry, profile)\n            all_violations.extend(result.violations)\n\n    return {\n        \"entries_checked\": len(entries),\n        \"total_violations\": len(all_violations),\n        \"critical\": sum(1 for v in all_violations if v.severity.value == \"critical\"),\n        \"high\": sum(1 for v in all_violations if v.severity.value == \"high\"),\n    }\n</code></pre>"},{"location":"tutorials/report-generation/","title":"Report Generation Tutorial","text":"<p>This tutorial covers generating and exporting compliance reports from audit data, including customization and scheduling for automated reporting.</p>"},{"location":"tutorials/report-generation/#overview","title":"Overview","text":"<p>Compliance reports summarize audit data and compliance check results for stakeholders:</p> <ul> <li>Executive summaries for leadership</li> <li>Risk assessments for security teams</li> <li>Compliance matrices for auditors</li> <li>Recommendations for operations teams</li> </ul>"},{"location":"tutorials/report-generation/#basic-report-generation","title":"Basic Report Generation","text":""},{"location":"tutorials/report-generation/#setup","title":"Setup","text":"<pre><code>import asyncio\nfrom datetime import datetime, timedelta\nfrom rotalabs_comply import AuditLogger, ReportGenerator\nfrom rotalabs_comply.audit import MemoryStorage\nfrom rotalabs_comply.frameworks.base import ComplianceProfile\nfrom rotalabs_comply.frameworks.eu_ai_act import EUAIActFramework\nfrom rotalabs_comply.frameworks.soc2 import SOC2Framework\nfrom rotalabs_comply.frameworks.hipaa import HIPAAFramework\n\n# Set up storage and logger\nstorage = MemoryStorage()\nlogger = AuditLogger(storage)\n\n# Create report generator with frameworks\ngenerator = ReportGenerator(\n    audit_logger=storage,\n    frameworks={\n        \"eu_ai_act\": EUAIActFramework(),\n        \"soc2\": SOC2Framework(),\n        \"hipaa\": HIPAAFramework(),\n    },\n)\n\n# Create compliance profile\nprofile = ComplianceProfile(\n    profile_id=\"production\",\n    name=\"Production AI System\",\n    enabled_frameworks=[\"eu_ai_act\", \"soc2\"],\n)\n</code></pre>"},{"location":"tutorials/report-generation/#generate-full-report","title":"Generate Full Report","text":"<pre><code>async def main():\n    # First, log some entries\n    for i in range(100):\n        await logger.log(\n            input=f\"Query {i}\",\n            output=f\"Response {i}\",\n            provider=\"openai\",\n            model=\"gpt-4\",\n            safety_passed=i % 10 != 0,  # 10% failure rate\n            latency_ms=100 + i,\n        )\n\n    # Define reporting period\n    end = datetime.utcnow()\n    start = end - timedelta(days=30)\n\n    # Generate report\n    report = await generator.generate(\n        period_start=start,\n        period_end=end,\n        profile=profile,\n    )\n\n    print(f\"Report: {report.title}\")\n    print(f\"ID: {report.id}\")\n    print(f\"Period: {report.period_start} to {report.period_end}\")\n    print(f\"Entries analyzed: {report.total_entries}\")\n    print(f\"Violations found: {report.violations_count}\")\n    print(f\"Compliance score: {report.compliance_score:.2%}\")\n    print(f\"Status: {report.status}\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"tutorials/report-generation/#export-formats","title":"Export Formats","text":""},{"location":"tutorials/report-generation/#markdown-export","title":"Markdown Export","text":"<p>Perfect for documentation systems and README files:</p> <pre><code># Export to Markdown\nmarkdown = generator.export_markdown(report)\n\n# Save to file\nwith open(\"compliance_report.md\", \"w\") as f:\n    f.write(markdown)\n\n# Preview\nprint(markdown[:1000])\n</code></pre> <p>Output structure: <pre><code># Compliance Report - Production AI System\n\n**Report ID:** abc-123-def\n**Generated:** 2026-01-29 10:30:00 UTC\n**Period:** 2026-01-01 to 2026-01-29\n**Framework:** Multiple\n**Profile:** Production AI System\n\n---\n\n**Compliance Score:** 95.50%\n**Status:** COMPLIANT\n**Total Entries:** 10,000\n**Violations:** 45\n\n---\n\n## Executive Summary\n\n**Compliance Status: COMPLIANT**\n...\n</code></pre></p>"},{"location":"tutorials/report-generation/#json-export","title":"JSON Export","text":"<p>For programmatic processing and API integration:</p> <pre><code>import json\n\n# Export to JSON\njson_str = generator.export_json(report)\n\n# Save to file\nwith open(\"compliance_report.json\", \"w\") as f:\n    f.write(json_str)\n\n# Load and process\ndata = json.loads(json_str)\nprint(f\"Score: {data['compliance_score']}\")\nprint(f\"Sections: {len(data['sections'])}\")\n</code></pre>"},{"location":"tutorials/report-generation/#html-export","title":"HTML Export","text":"<p>Standalone reports for stakeholders:</p> <pre><code># Export to HTML\nhtml = generator.export_html(report)\n\n# Save to file\nwith open(\"compliance_report.html\", \"w\") as f:\n    f.write(html)\n\n# Open in browser (optional)\nimport webbrowser\nwebbrowser.open(\"compliance_report.html\")\n</code></pre> <p>The HTML export includes: - Embedded CSS styling - Color-coded status badges - Responsive layout - Tables with alternating row colors - Professional formatting</p>"},{"location":"tutorials/report-generation/#report-sections","title":"Report Sections","text":""},{"location":"tutorials/report-generation/#executive-summary","title":"Executive Summary","text":"<p>High-level overview for leadership:</p> <pre><code># Access executive summary section\nfor section in report.sections:\n    if section.title == \"Executive Summary\":\n        print(section.content)\n        print(f\"Status: {section.metadata.get('status')}\")\n        print(f\"Rate: {section.metadata.get('compliance_rate')}%\")\n</code></pre> <p>Content includes: - Overall compliance status - Key metrics table - Frameworks evaluated - Summary interpretation</p>"},{"location":"tutorials/report-generation/#risk-assessment","title":"Risk Assessment","text":"<p>Security-focused analysis:</p> <pre><code>for section in report.sections:\n    if section.title == \"Risk Assessment\":\n        print(f\"Overall risk: {section.metadata.get('overall_risk')}\")\n        print(f\"Severity counts: {section.metadata.get('severity_counts')}\")\n</code></pre> <p>Content includes: - Overall risk level - Severity distribution table - Findings by category - Priority findings list - Risk-based recommendations</p>"},{"location":"tutorials/report-generation/#compliance-matrix","title":"Compliance Matrix","text":"<p>Auditor-friendly rule-by-rule breakdown:</p> <pre><code>for section in report.sections:\n    if section.title == \"Compliance Matrix\":\n        print(f\"Frameworks: {section.metadata.get('frameworks')}\")\n        print(f\"Total checks: {section.metadata.get('total_checks')}\")\n        print(f\"Overall rate: {section.metadata.get('compliance_rate')}%\")\n</code></pre> <p>Content includes: - Framework summary table - Pass/fail counts per framework - Detailed violation list - Overall statistics</p>"},{"location":"tutorials/report-generation/#metrics-summary","title":"Metrics Summary","text":"<p>Performance and safety metrics:</p> <pre><code>for section in report.sections:\n    if section.title == \"Metrics Summary\":\n        print(f\"Safety rate: {section.metadata.get('safety_rate')}%\")\n        print(f\"Avg latency: {section.metadata.get('avg_latency')}ms\")\n        print(f\"P95 latency: {section.metadata.get('p95_latency')}ms\")\n</code></pre> <p>Content includes: - Volume metrics - Safety pass rates - Latency percentiles (P50, P95, P99) - Provider distribution</p>"},{"location":"tutorials/report-generation/#recommendations","title":"Recommendations","text":"<p>Prioritized action items:</p> <pre><code>for section in report.sections:\n    if section.title == \"Recommendations\":\n        print(f\"Total: {section.metadata.get('recommendation_count')}\")\n        print(f\"Immediate: {section.metadata.get('immediate_count')}\")\n        print(f\"Short-term: {section.metadata.get('short_term_count')}\")\n</code></pre> <p>Content includes: - Immediate actions (24-48 hours) - Short-term actions (1-2 weeks) - Long-term improvements - General best practices</p>"},{"location":"tutorials/report-generation/#audit-summary","title":"Audit Summary","text":"<p>Volume and activity analysis:</p> <pre><code>for section in report.sections:\n    if section.title == \"Audit Summary\":\n        print(f\"Period: {section.metadata.get('period')}\")\n        print(f\"Daily average: {section.metadata.get('avg_daily')}\")\n        print(f\"Peak volume: {section.metadata.get('peak_daily')}\")\n</code></pre> <p>Content includes: - Volume summary - Peak activity days - Failure patterns - Retention notes</p>"},{"location":"tutorials/report-generation/#framework-specific-reports","title":"Framework-Specific Reports","text":""},{"location":"tutorials/report-generation/#eu-ai-act-report","title":"EU AI Act Report","text":"<pre><code>report = await generator.generate(\n    period_start=start,\n    period_end=end,\n    profile=profile,\n    framework=\"eu_ai_act\",\n)\n\nprint(report.title)  # \"EU AI Act Compliance Report\"\n</code></pre> <p>Template includes sections for: - Risk classification - Transparency obligations - Human oversight - Data governance - Technical documentation</p>"},{"location":"tutorials/report-generation/#soc2-report","title":"SOC2 Report","text":"<pre><code>report = await generator.generate(\n    period_start=start,\n    period_end=end,\n    profile=profile,\n    framework=\"soc2\",\n)\n\nprint(report.title)  # \"SOC2 Type II Compliance Report\"\n</code></pre> <p>Template includes sections for: - System overview - Security controls (CC) - Availability controls (A) - Processing integrity (PI) - Confidentiality controls (C) - Privacy controls (P)</p>"},{"location":"tutorials/report-generation/#hipaa-report","title":"HIPAA Report","text":"<pre><code>report = await generator.generate(\n    period_start=start,\n    period_end=end,\n    profile=profile,\n    framework=\"hipaa\",\n)\n\nprint(report.title)  # \"HIPAA Compliance Report\"\n</code></pre> <p>Template includes sections for: - Administrative safeguards - Physical safeguards - Technical safeguards - Breach notification - PHI handling</p>"},{"location":"tutorials/report-generation/#executive-summary-report","title":"Executive Summary Report","text":"<p>Generate a condensed report for executives:</p> <pre><code>report = await generator.generate_executive_summary(\n    period_start=start,\n    period_end=end,\n    profile=profile,\n)\n\nprint(f\"Title: {report.title}\")  # \"Executive Summary - Production AI System\"\nprint(f\"Sections: {len(report.sections)}\")  # Fewer sections\n</code></pre> <p>Executive summary includes only: - Executive summary - Risk assessment - Recommendations</p>"},{"location":"tutorials/report-generation/#scheduled-reporting","title":"Scheduled Reporting","text":""},{"location":"tutorials/report-generation/#daily-reports","title":"Daily Reports","text":"<pre><code>import asyncio\nfrom datetime import datetime, timedelta\n\nasync def generate_daily_report():\n    end = datetime.utcnow().replace(hour=0, minute=0, second=0)\n    start = end - timedelta(days=1)\n\n    report = await generator.generate(\n        period_start=start,\n        period_end=end,\n        profile=profile,\n    )\n\n    # Save reports\n    date_str = start.strftime(\"%Y%m%d\")\n    generator.export_markdown(report)\n    with open(f\"reports/daily_{date_str}.md\", \"w\") as f:\n        f.write(generator.export_markdown(report))\n\n    return report\n\nasync def daily_report_scheduler():\n    while True:\n        now = datetime.now()\n        # Run at 6 AM\n        next_run = now.replace(hour=6, minute=0, second=0)\n        if next_run &lt;= now:\n            next_run += timedelta(days=1)\n\n        await asyncio.sleep((next_run - now).total_seconds())\n\n        try:\n            report = await generate_daily_report()\n            print(f\"[{datetime.now()}] Generated daily report: {report.status}\")\n        except Exception as e:\n            print(f\"[{datetime.now()}] Report generation failed: {e}\")\n</code></pre>"},{"location":"tutorials/report-generation/#weekly-reports","title":"Weekly Reports","text":"<pre><code>async def generate_weekly_report():\n    end = datetime.utcnow()\n    start = end - timedelta(days=7)\n\n    report = await generator.generate(\n        period_start=start,\n        period_end=end,\n        profile=profile,\n    )\n\n    # Generate all formats\n    week_str = start.strftime(\"%Y-W%V\")\n\n    with open(f\"reports/weekly_{week_str}.md\", \"w\") as f:\n        f.write(generator.export_markdown(report))\n\n    with open(f\"reports/weekly_{week_str}.html\", \"w\") as f:\n        f.write(generator.export_html(report))\n\n    with open(f\"reports/weekly_{week_str}.json\", \"w\") as f:\n        f.write(generator.export_json(report))\n\n    return report\n</code></pre>"},{"location":"tutorials/report-generation/#monthly-reports","title":"Monthly Reports","text":"<pre><code>import calendar\n\nasync def generate_monthly_report(year: int, month: int):\n    # Calculate month boundaries\n    _, last_day = calendar.monthrange(year, month)\n    start = datetime(year, month, 1)\n    end = datetime(year, month, last_day, 23, 59, 59)\n\n    report = await generator.generate(\n        period_start=start,\n        period_end=end,\n        profile=profile,\n    )\n\n    month_str = start.strftime(\"%Y-%m\")\n\n    with open(f\"reports/monthly_{month_str}.html\", \"w\") as f:\n        f.write(generator.export_html(report))\n\n    return report\n</code></pre>"},{"location":"tutorials/report-generation/#quarterly-reports","title":"Quarterly Reports","text":"<pre><code>async def generate_quarterly_report(year: int, quarter: int):\n    # Q1: Jan-Mar, Q2: Apr-Jun, Q3: Jul-Sep, Q4: Oct-Dec\n    start_month = (quarter - 1) * 3 + 1\n    end_month = start_month + 2\n    _, last_day = calendar.monthrange(year, end_month)\n\n    start = datetime(year, start_month, 1)\n    end = datetime(year, end_month, last_day, 23, 59, 59)\n\n    report = await generator.generate(\n        period_start=start,\n        period_end=end,\n        profile=profile,\n    )\n\n    quarter_str = f\"{year}-Q{quarter}\"\n\n    with open(f\"reports/quarterly_{quarter_str}.html\", \"w\") as f:\n        f.write(generator.export_html(report))\n\n    return report\n</code></pre>"},{"location":"tutorials/report-generation/#email-distribution","title":"Email Distribution","text":""},{"location":"tutorials/report-generation/#send-report-via-email","title":"Send Report via Email","text":"<pre><code>import smtplib\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.text import MIMEText\nfrom email.mime.application import MIMEApplication\n\nasync def send_compliance_report(report, recipients):\n    # Generate HTML report\n    html_content = generator.export_html(report)\n\n    # Create email\n    msg = MIMEMultipart()\n    msg[\"Subject\"] = f\"Compliance Report: {report.title} - {report.status.upper()}\"\n    msg[\"From\"] = \"compliance@company.com\"\n    msg[\"To\"] = \", \".join(recipients)\n\n    # Add summary in body\n    body = f\"\"\"\n    Compliance Report Summary\n    ========================\n    Period: {report.period_start.strftime('%Y-%m-%d')} to {report.period_end.strftime('%Y-%m-%d')}\n    Status: {report.status.upper()}\n    Compliance Score: {report.compliance_score:.2%}\n    Entries Analyzed: {report.total_entries:,}\n    Violations Found: {report.violations_count:,}\n\n    Full report attached.\n    \"\"\"\n    msg.attach(MIMEText(body, \"plain\"))\n\n    # Attach HTML report\n    attachment = MIMEApplication(html_content.encode(), Name=\"compliance_report.html\")\n    attachment[\"Content-Disposition\"] = 'attachment; filename=\"compliance_report.html\"'\n    msg.attach(attachment)\n\n    # Send\n    with smtplib.SMTP(\"smtp.company.com\", 587) as server:\n        server.starttls()\n        server.login(\"compliance@company.com\", \"password\")\n        server.send_message(msg)\n\n    print(f\"Report sent to {recipients}\")\n</code></pre>"},{"location":"tutorials/report-generation/#slack-integration","title":"Slack Integration","text":""},{"location":"tutorials/report-generation/#post-report-summary","title":"Post Report Summary","text":"<pre><code>import httpx\n\nasync def post_to_slack(report, webhook_url):\n    # Determine emoji based on status\n    emoji = {\n        \"compliant\": \":white_check_mark:\",\n        \"needs_review\": \":warning:\",\n        \"non_compliant\": \":x:\",\n    }.get(report.status, \":question:\")\n\n    # Create message\n    message = {\n        \"text\": f\"{emoji} Compliance Report Generated\",\n        \"blocks\": [\n            {\n                \"type\": \"header\",\n                \"text\": {\n                    \"type\": \"plain_text\",\n                    \"text\": f\"{emoji} {report.title}\",\n                },\n            },\n            {\n                \"type\": \"section\",\n                \"fields\": [\n                    {\n                        \"type\": \"mrkdwn\",\n                        \"text\": f\"*Status:*\\n{report.status.upper()}\",\n                    },\n                    {\n                        \"type\": \"mrkdwn\",\n                        \"text\": f\"*Score:*\\n{report.compliance_score:.2%}\",\n                    },\n                    {\n                        \"type\": \"mrkdwn\",\n                        \"text\": f\"*Entries:*\\n{report.total_entries:,}\",\n                    },\n                    {\n                        \"type\": \"mrkdwn\",\n                        \"text\": f\"*Violations:*\\n{report.violations_count:,}\",\n                    },\n                ],\n            },\n            {\n                \"type\": \"section\",\n                \"text\": {\n                    \"type\": \"mrkdwn\",\n                    \"text\": f\"Period: {report.period_start.strftime('%Y-%m-%d')} to {report.period_end.strftime('%Y-%m-%d')}\",\n                },\n            },\n        ],\n    }\n\n    # Send to Slack\n    async with httpx.AsyncClient() as client:\n        response = await client.post(webhook_url, json=message)\n        response.raise_for_status()\n</code></pre>"},{"location":"tutorials/report-generation/#custom-report-templates","title":"Custom Report Templates","text":""},{"location":"tutorials/report-generation/#using-pre-defined-templates","title":"Using Pre-defined Templates","text":"<pre><code>from rotalabs_comply.reports.templates import (\n    EU_AI_ACT_TEMPLATE,\n    SOC2_TEMPLATE,\n    HIPAA_TEMPLATE,\n    EXECUTIVE_SUMMARY_TEMPLATE,\n)\n\nprint(EU_AI_ACT_TEMPLATE.title)     # \"EU AI Act Compliance Report\"\nprint(EU_AI_ACT_TEMPLATE.sections)  # List of section names\nprint(EU_AI_ACT_TEMPLATE.format)    # \"markdown\"\n</code></pre>"},{"location":"tutorials/report-generation/#creating-custom-templates","title":"Creating Custom Templates","text":"<pre><code>from rotalabs_comply.reports.templates import ReportTemplate\n\ncustom_template = ReportTemplate(\n    framework=\"custom\",\n    title=\"Custom Compliance Report\",\n    sections=[\n        \"executive_summary\",\n        \"risk_assessment\",\n        \"custom_section\",\n        \"recommendations\",\n    ],\n    format=\"html\",\n)\n</code></pre>"},{"location":"tutorials/report-generation/#best-practices","title":"Best Practices","text":""},{"location":"tutorials/report-generation/#1-archive-reports","title":"1. Archive Reports","text":"<pre><code>import os\nfrom datetime import datetime\n\ndef archive_report(report, base_path=\"/var/reports\"):\n    # Create archive structure\n    year = report.period_end.strftime(\"%Y\")\n    month = report.period_end.strftime(\"%m\")\n    archive_dir = os.path.join(base_path, year, month)\n    os.makedirs(archive_dir, exist_ok=True)\n\n    # Save in all formats\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    base_name = f\"compliance_{timestamp}\"\n\n    with open(os.path.join(archive_dir, f\"{base_name}.md\"), \"w\") as f:\n        f.write(generator.export_markdown(report))\n\n    with open(os.path.join(archive_dir, f\"{base_name}.html\"), \"w\") as f:\n        f.write(generator.export_html(report))\n\n    with open(os.path.join(archive_dir, f\"{base_name}.json\"), \"w\") as f:\n        f.write(generator.export_json(report))\n\n    return archive_dir\n</code></pre>"},{"location":"tutorials/report-generation/#2-track-report-metrics","title":"2. Track Report Metrics","text":"<pre><code>report_metrics = []\n\nasync def generate_and_track(period_start, period_end, profile):\n    report = await generator.generate(\n        period_start=period_start,\n        period_end=period_end,\n        profile=profile,\n    )\n\n    # Track metrics over time\n    report_metrics.append({\n        \"generated_at\": datetime.now().isoformat(),\n        \"period\": f\"{period_start.date()} to {period_end.date()}\",\n        \"score\": report.compliance_score,\n        \"status\": report.status,\n        \"violations\": report.violations_count,\n        \"entries\": report.total_entries,\n    })\n\n    return report\n\n# Analyze trends\nimport pandas as pd\ndf = pd.DataFrame(report_metrics)\nprint(df.describe())\n</code></pre>"},{"location":"tutorials/report-generation/#3-alert-on-critical-status","title":"3. Alert on Critical Status","text":"<pre><code>async def generate_with_alerts(period_start, period_end, profile):\n    report = await generator.generate(\n        period_start=period_start,\n        period_end=period_end,\n        profile=profile,\n    )\n\n    # Alert on non-compliant status\n    if report.status == \"non_compliant\":\n        # Send immediate alert\n        await send_alert(\n            level=\"critical\",\n            message=f\"Non-compliant report generated: {report.violations_count} violations\",\n            report_id=report.id,\n        )\n\n    # Alert on score drops\n    previous_score = get_previous_score()\n    if previous_score and report.compliance_score &lt; previous_score - 0.05:\n        await send_alert(\n            level=\"warning\",\n            message=f\"Compliance score dropped from {previous_score:.2%} to {report.compliance_score:.2%}\",\n            report_id=report.id,\n        )\n\n    return report\n</code></pre>"}]}